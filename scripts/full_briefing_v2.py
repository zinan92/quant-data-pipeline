#!/usr/bin/env python3
"""
å…¨å¸‚åœºç®€æŠ¥ v2 â€” Parkæ¡†æ¶ + å°ç™»/ä¸­ç™»/è€ç™»åˆ†ç±»
=============================================
ç”¨æ³•: python scripts/full_briefing_v2.py [--closing]
  --closing: æ”¶ç›˜ç®€æŠ¥æ¨¡å¼ï¼ˆå«ç›˜åæ€»ç»“ï¼‰

æ¨¡å—:
1. å¤§ç›˜ä¸€å¥è¯      â€” æŒ‡æ•°/æˆäº¤é‡/èµ°åŠ¿/æ¶¨è·Œåœæ¯”
2. èµ›é“ä½“æ£€        â€” 16èµ›é“å®æ—¶è¡¨ç° + å°ç™»/ä¸­ç™»/è€ç™»é£æ ¼åˆ¤æ–­
3. è‡ªé€‰ vs å¤§ç›˜    â€” ç›¸å¯¹è¡¨ç° + alpha
4. å…³é”®ä¿¡å·        â€” æŠ¤ç›˜/è¶‹åŠ¿/é¿é™© + æ¦‚å¿µèµ„é‡‘æµäº®ç‚¹
5. å¿«è®¯ç²¾é€‰        â€” 3-5æ¡æœ‰ä»·å€¼çš„
6. æ“ä½œå»ºè®®        â€” ä¸€å¥è¯
"""

import sys
import json
import time
import traceback
import requests
import sqlite3
from datetime import datetime
from pathlib import Path

# â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ROOT = Path(__file__).parent.parent
DB_PATH = PROJECT_ROOT / "data" / "market.db"
SNAPSHOT_FILE = PROJECT_ROOT / "data" / "snapshots" / "intraday" / "today_index_snapshots.json"
SNAPSHOT_FILE.parent.mkdir(parents=True, exist_ok=True)

API_BASE = "http://127.0.0.1:8000"
SINA_HEADERS = {"Referer": "https://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}

INDEX_CODES = [
    ("000001.SH", "ä¸Šè¯"),
    ("399001.SZ", "æ·±è¯"),
    ("399006.SZ", "åˆ›ä¸šæ¿"),
    ("000688.SH", "ç§‘åˆ›50"),
]

# â”€â”€ å°ç™»/ä¸­ç™»/è€ç™» åˆ†ç±» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DENG_MAP = {
    "å°ç™»": ["AIåº”ç”¨", "èŠ¯ç‰‡", "PCB", "æœºå™¨äºº", "åŠå¯¼ä½“", "è„‘æœºæ¥å£", "å¯æ§æ ¸èšå˜"],
    "ä¸­ç™»": ["æ–°èƒ½æºæ±½è½¦", "å…‰ä¼", "å‘ç”µ", "åˆ›æ–°è¯", "è´µé‡‘å±", "é‡‘å±", "å†›å·¥"],
    "è€ç™»": ["æ¶ˆè´¹"],
}

# Reverse map: sector â†’ deng category
SECTOR_TO_DENG = {}
for deng_cat, sectors in DENG_MAP.items():
    for s in sectors:
        SECTOR_TO_DENG[s] = deng_cat

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Helpers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def safe_section(name):
    """Decorator: if a section fails, print error and continue."""
    def decorator(fn):
        def wrapper(*args, **kwargs):
            try:
                return fn(*args, **kwargs)
            except Exception as e:
                traceback.print_exc(file=sys.stderr)
                return [f"âš ï¸ [{name}] è·å–å¤±è´¥: {e}"]
        return wrapper
    return decorator


def fetch_sina_batch(tickers: list[str]) -> dict:
    """Fetch realtime quotes from Sina for a list of tickers.
    Returns {ticker: {name, price, prev_close, pct, volume, amount}}
    """
    results = {}
    for i in range(0, len(tickers), 50):
        batch = tickers[i:i + 50]
        codes = ",".join([
            f"sh{t}" if t.startswith("6") or t.startswith("9")
            else f"sz{t}"
            for t in batch
        ])
        try:
            r = requests.get(
                f"http://hq.sinajs.cn/list={codes}",
                headers=SINA_HEADERS, timeout=10,
            )
            for line in r.text.strip().split("\n"):
                if "hq_str_" not in line or '"' not in line:
                    continue
                code_part = line.split("hq_str_")[1].split("=")[0]
                ticker = code_part[2:]  # Remove sh/sz prefix
                data = line.split('"')[1].split(",")
                if len(data) < 9:
                    continue
                try:
                    name = data[0]
                    prev_close = float(data[2]) if data[2] else 0
                    cur = float(data[3]) if data[3] else 0
                    high = float(data[4]) if data[4] else 0
                    low = float(data[5]) if data[5] else 0
                    volume = float(data[8]) if data[8] else 0  # æˆäº¤é¢(å…ƒ)
                    if prev_close > 0 and cur > 0:
                        pct = (cur - prev_close) / prev_close * 100
                        # Detect limit up/down (æ¶¨è·Œåœ: â‰¥9.8% for main board, â‰¥19.8% for åˆ›ä¸šæ¿/ç§‘åˆ›æ¿)
                        is_cyb = ticker.startswith("3")
                        is_kcb = ticker.startswith("68")
                        limit_threshold = 19.8 if (is_cyb or is_kcb) else 9.8
                        is_limit_up = pct >= limit_threshold
                        is_limit_down = pct <= -limit_threshold
                        results[ticker] = {
                            "name": name,
                            "price": cur,
                            "prev_close": prev_close,
                            "pct": pct,
                            "high": high,
                            "low": low,
                            "amount": volume,
                            "is_limit_up": is_limit_up,
                            "is_limit_down": is_limit_down,
                        }
                except (ValueError, ZeroDivisionError, IndexError):
                    pass
        except Exception:
            pass
        if i + 50 < len(tickers):
            time.sleep(0.3)
    return results


def load_sector_stocks() -> dict:
    """Load sectors and their stocks from market.db.
    Returns {sector: [ticker1, ticker2, ...]}
    """
    conn = sqlite3.connect(str(DB_PATH))
    c = conn.cursor()
    c.execute("SELECT ticker, sector FROM stock_sectors")
    rows = c.fetchall()
    conn.close()

    sectors = {}
    for ticker, sector in rows:
        sectors.setdefault(sector, []).append(ticker)
    return sectors


def load_watchlist() -> list[dict]:
    """Load watchlist from market.db.
    Returns [{ticker, category, is_focus}, ...]
    """
    conn = sqlite3.connect(str(DB_PATH))
    c = conn.cursor()
    c.execute("SELECT ticker, category, is_focus FROM watchlist")
    rows = c.fetchall()
    conn.close()
    return [{"ticker": r[0], "category": r[1], "is_focus": r[2]} for r in rows]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 0. Index data + snapshot
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def fetch_indices() -> dict:
    """Fetch index data from local API."""
    result = {}
    for code, name in INDEX_CODES:
        try:
            r = requests.get(f"{API_BASE}/api/index/realtime/{code}", timeout=5)
            if r.ok:
                d = r.json()
                result[code] = {
                    "name": d.get("name", name),
                    "price": d.get("price", 0),
                    "pct": d.get("change_pct", 0),
                    "amount": d.get("amount", 0),
                }
        except Exception:
            pass
    return result


def save_index_snapshot(index_data: dict):
    """Save current index data as a snapshot point."""
    try:
        if SNAPSHOT_FILE.exists():
            snapshots = json.loads(SNAPSHOT_FILE.read_text())
            if snapshots.get("date") != datetime.now().strftime("%Y-%m-%d"):
                snapshots = {"date": datetime.now().strftime("%Y-%m-%d"), "snapshots": []}
        else:
            snapshots = {"date": datetime.now().strftime("%Y-%m-%d"), "snapshots": []}

        now_time = datetime.now().strftime("%H:%M")
        existing_times = {s["time"] for s in snapshots["snapshots"]}
        if now_time in existing_times:
            return

        snapshot_entry = {"time": now_time, "indexes": {}}
        for code, info in index_data.items():
            snapshot_entry["indexes"][code] = {
                "name": info["name"],
                "price": info["price"],
                "pct": info["pct"],
            }
        snapshots["snapshots"].append(snapshot_entry)
        SNAPSHOT_FILE.write_text(json.dumps(snapshots, ensure_ascii=False, indent=2))
    except Exception:
        pass


def get_intraday_walk(index_data: dict) -> str:
    """Describe intraday walk from snapshots: 2-3 key turning points."""
    if not SNAPSHOT_FILE.exists():
        return ""
    try:
        data = json.loads(SNAPSHOT_FILE.read_text())
        snaps = data.get("snapshots", [])
        if len(snaps) < 2:
            return ""
        
        # Use ä¸Šè¯ as reference
        sh_code = "000001.SH"
        points = []
        for s in snaps:
            idx = s.get("indexes", {}).get(sh_code, {})
            if idx.get("pct") is not None:
                points.append((s["time"], idx["pct"]))
        
        if len(points) < 2:
            return ""
        
        # Find key turning points: open, high, low, latest
        open_pt = points[0]
        latest_pt = points[-1]
        high_pt = max(points, key=lambda x: x[1])
        low_pt = min(points, key=lambda x: x[1])
        
        # Build narrative: 2-3 nodes
        segments = []
        
        # Opening move
        if open_pt[1] > 0.1:
            segments.append(f"é«˜å¼€({open_pt[1]:+.1f}%)")
        elif open_pt[1] < -0.1:
            segments.append(f"ä½å¼€({open_pt[1]:+.1f}%)")
        else:
            segments.append("å¹³å¼€")
        
        # If there's a meaningful swing, describe it
        key_events = sorted(set([open_pt, high_pt, low_pt, latest_pt]), key=lambda x: x[0])
        
        prev_pct = open_pt[1]
        for pt in key_events[1:]:
            delta = pt[1] - prev_pct
            if abs(delta) < 0.15:
                continue
            if delta > 0:
                segments.append(f"{pt[0]}åå¼¹è‡³{pt[1]:+.1f}%")
            else:
                segments.append(f"{pt[0]}å›è½è‡³{pt[1]:+.1f}%")
            prev_pct = pt[1]
        
        if len(segments) <= 1:
            # Simple day
            if latest_pt[1] > open_pt[1] + 0.3:
                segments.append("éœ‡è¡èµ°é«˜")
            elif latest_pt[1] < open_pt[1] - 0.3:
                segments.append("éœ‡è¡èµ°ä½")
            else:
                segments.append("çª„å¹…éœ‡è¡")
        
        return " â†’ ".join(segments[:4])  # Max 4 nodes
    except Exception:
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. å¤§ç›˜ä¸€å¥è¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¤§ç›˜ä¸€å¥è¯")
def section_headline(index_data: dict, alert_data: dict = None) -> list[str]:
    lines = ["â”â” 1. å¤§ç›˜ä¸€å¥è¯ â”â”"]
    
    # Index row
    idx_parts = []
    for code, _ in INDEX_CODES:
        d = index_data.get(code)
        if d:
            idx_parts.append(f"{d['name']} {d['pct']:+.2f}%")
    lines.append(" | ".join(idx_parts))
    
    # Volume
    sh_data = index_data.get("000001.SH", {})
    amount_yi = sh_data.get("amount", 0) / 1e4 if sh_data.get("amount") else 0
    if amount_yi > 0:
        # TODO: compare to yesterday for ç¼©é‡/æ”¾é‡
        lines.append(f"æˆäº¤ {amount_yi:.0f}äº¿")
    
    # Intraday walk
    walk = get_intraday_walk(index_data)
    if walk:
        lines.append(f"èµ°åŠ¿: {walk}")
    
    # Limit up/down
    up_count = 0
    down_count = 0
    if alert_data:
        up_count = alert_data.get("å°æ¶¨åœæ¿", {}).get("count", 0)
        down_count = alert_data.get("å°è·Œåœæ¿", {}).get("count", 0)
    
    if up_count + down_count > 0:
        ratio = up_count / down_count if down_count > 0 else float("inf")
        if ratio > 1.5:
            comment = "æ¶¨åœå¤š = å¤šå¤´æ´»è·ƒ"
        elif ratio < 0.67:
            comment = "è·Œåœå¤š = å¼±"
        else:
            comment = "å¹³è¡¡"
        lines.append(f"æ¶¨åœ {up_count} / è·Œåœ {down_count} ({ratio:.1f}x â† {comment})")
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. èµ›é“ä½“æ£€ (16 sectors + å°ç™»/ä¸­ç™»/è€ç™»)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("èµ›é“ä½“æ£€")
def section_sectors(sector_stocks: dict, all_quotes: dict) -> tuple[list[str], dict]:
    """Returns (lines, sector_stats) where sector_stats = {sector: {avg_pct, up, down, total, limit_up, limit_down, best, worst}}"""
    lines = ["â”â” 2. èµ›é“ä½“æ£€ â”â”"]
    
    sector_stats = {}
    
    for sector, tickers in sorted(sector_stocks.items()):
        if sector == "å…¶ä»–":
            continue  # Skip "å…¶ä»–"
        
        pcts = []
        up = 0
        down = 0
        flat = 0
        limit_up = 0
        limit_down = 0
        best_stock = None
        worst_stock = None
        
        for t in tickers:
            q = all_quotes.get(t)
            if not q:
                continue
            pct = q["pct"]
            pcts.append(pct)
            
            if pct > 0.05:
                up += 1
            elif pct < -0.05:
                down += 1
            else:
                flat += 1
            
            if q["is_limit_up"]:
                limit_up += 1
            if q["is_limit_down"]:
                limit_down += 1
            
            if best_stock is None or pct > best_stock[1]:
                best_stock = (q["name"], pct)
            if worst_stock is None or pct < worst_stock[1]:
                worst_stock = (q["name"], pct)
        
        if not pcts:
            sector_stats[sector] = None
            continue
        
        avg_pct = sum(pcts) / len(pcts)
        total = len(pcts)
        
        sector_stats[sector] = {
            "avg_pct": avg_pct,
            "up": up,
            "down": down,
            "flat": flat,
            "total": total,
            "limit_up": limit_up,
            "limit_down": limit_down,
            "best": best_stock,
            "worst": worst_stock,
        }
    
    # Sort sectors by avg_pct descending
    sorted_sectors = sorted(
        [(s, d) for s, d in sector_stats.items() if d is not None],
        key=lambda x: x[1]["avg_pct"],
        reverse=True,
    )
    
    # Display
    green_count = 0
    red_count = 0
    
    for sector, stats in sorted_sectors:
        avg = stats["avg_pct"]
        emoji = "ğŸŸ¢" if avg >= 0 else "ğŸ”´"
        if avg >= 0:
            green_count += 1
        else:
            red_count += 1
        
        total = stats["total"]
        up = stats["up"]
        down = stats["down"]
        
        # Build detail string
        detail = f"{total}åª: {up}æ¶¨{down}è·Œ"
        if stats["limit_up"] > 0:
            detail += f", {stats['limit_up']}æ¶¨åœ"
        if stats["limit_down"] > 0:
            detail += f", {stats['limit_down']}è·Œåœ"
        
        # Comment based on severity
        comment = ""
        if down > 0 and up == 0 and down >= 3:
            comment = " â† å…¨ç­"
        elif total > 5 and down / total > 0.85:
            comment = " â† å‡ ä¹å…¨ç­"
        elif total > 5 and up / total > 0.85:
            comment = " â† å…¨çº¿é£˜çº¢"
        elif avg > 3:
            comment = " â† çˆ†å‘"
        elif avg < -3:
            comment = " â† æš´è·Œ"
        
        # Show best/worst for extreme sectors
        extra = ""
        if avg > 2 and stats["best"]:
            extra = f" æœ€å¼º:{stats['best'][0]}{stats['best'][1]:+.1f}%"
        elif avg < -2 and stats["worst"]:
            extra = f" æœ€å¼±:{stats['worst'][0]}{stats['worst'][1]:+.1f}%"
        
        lines.append(f"{emoji} {sector} {avg:+.1f}% ({detail}){comment}{extra}")
    
    # Summary line
    total_sectors = green_count + red_count
    lines.append(f"ğŸ“Š ç»“è®º: {green_count}/{total_sectors}èµ›é“èµšé’±ï¼Œ{red_count}ä¸ªäºé’±")
    
    # å°ç™»/ä¸­ç™»/è€ç™» é£æ ¼åˆ¤æ–­
    deng_avgs = {}
    for deng_cat in ["å°ç™»", "ä¸­ç™»", "è€ç™»"]:
        cat_sectors = DENG_MAP[deng_cat]
        cat_pcts = []
        for s in cat_sectors:
            if s in sector_stats and sector_stats[s] is not None:
                cat_pcts.append(sector_stats[s]["avg_pct"])
        if cat_pcts:
            deng_avgs[deng_cat] = sum(cat_pcts) / len(cat_pcts)
        else:
            deng_avgs[deng_cat] = 0
    
    # Determine style
    style_parts = []
    for cat in ["å°ç™»", "ä¸­ç™»", "è€ç™»"]:
        avg = deng_avgs.get(cat, 0)
        emoji = "ğŸŸ¢" if avg >= 0 else "ğŸ”´"
        style_parts.append(f"{emoji}{cat} {avg:+.1f}%")
    
    lines.append(f"âš¡ é£æ ¼: {' | '.join(style_parts)}")
    
    # Narrative
    xd = deng_avgs.get("å°ç™»", 0)
    zd = deng_avgs.get("ä¸­ç™»", 0)
    ld = deng_avgs.get("è€ç™»", 0)
    
    if xd < -1 and ld > xd + 1:
        lines.append("ğŸ’¡ å°ç™»æºƒè´¥ â†’ è€ç™»é˜²å¾¡ï¼ŒRisk OFF")
    elif xd > 1 and ld < xd - 1:
        lines.append("ğŸ’¡ å°ç™»é¢†æ¶¨ â†’ ç§‘æŠ€è¿›æ”»ï¼ŒRisk ON")
    elif xd > 0.5 and zd > 0.5 and ld > 0.5:
        lines.append("ğŸ’¡ å…¨çº¿é£˜çº¢ï¼Œæ™®æ¶¨æ ¼å±€")
    elif xd < -0.5 and zd < -0.5 and ld < -0.5:
        lines.append("ğŸ’¡ å…¨çº¿æºƒè´¥ï¼Œæ™®è·Œæ ¼å±€")
    elif abs(xd - ld) < 0.5:
        lines.append("ğŸ’¡ é£æ ¼å¹³è¡¡ï¼Œæ— æ˜æ˜¾åå‘")
    else:
        if xd > zd > ld:
            lines.append("ğŸ’¡ ç§‘æŠ€>å‘¨æœŸ>é˜²å¾¡ï¼Œæˆé•¿é£æ ¼å ä¼˜")
        elif ld > zd > xd:
            lines.append("ğŸ’¡ é˜²å¾¡>å‘¨æœŸ>ç§‘æŠ€ï¼Œä»·å€¼é£æ ¼å ä¼˜")
        else:
            lines.append("ğŸ’¡ é£æ ¼è½®åŠ¨ä¸­")
    
    return lines, sector_stats


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. è‡ªé€‰ vs å¤§ç›˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("è‡ªé€‰ vs å¤§ç›˜")
def section_watchlist_vs_index(watchlist: list[dict], all_quotes: dict, index_data: dict) -> list[str]:
    lines = ["â”â” 3. è‡ªé€‰ vs å¤§ç›˜ â”â”"]
    
    # Compute watchlist average
    wl_pcts = []
    wl_stocks = []
    
    for item in watchlist:
        t = item["ticker"]
        q = all_quotes.get(t)
        if q:
            wl_pcts.append(q["pct"])
            wl_stocks.append((q["name"], t, q["pct"]))
    
    if not wl_pcts:
        lines.append("  æ— æ³•è·å–è‡ªé€‰è‚¡è¡Œæƒ…")
        return lines
    
    wl_avg = sum(wl_pcts) / len(wl_pcts)
    sh_pct = index_data.get("000001.SH", {}).get("pct", 0)
    alpha = wl_avg - sh_pct
    
    emoji = "ğŸŸ¢" if alpha >= 0 else "ğŸ”´"
    verb = "è·‘èµ¢" if alpha >= 0 else "è·‘è¾“"
    lines.append(f"è‡ªé€‰å‡å€¼: {wl_avg:+.2f}% vs ä¸Šè¯: {sh_pct:+.2f}% â†’ {emoji} {verb}{abs(alpha):.2f}%")
    
    # Determine reason based on sector distribution
    # Count sector composition
    sector_counts = {}
    for item in watchlist:
        cat = item.get("category", "æœªåˆ†ç±»")
        if cat:
            sector_counts[cat] = sector_counts.get(cat, 0) + 1
    top_sector = max(sector_counts, key=sector_counts.get) if sector_counts else "æœªåˆ†ç±»"
    deng_cat = SECTOR_TO_DENG.get(top_sector, "æœªåˆ†ç±»")
    lines.append(f"æŒä»“å{deng_cat}({top_sector}ä¸ºä¸»)")
    
    # Best and worst
    wl_stocks.sort(key=lambda x: x[2], reverse=True)
    top3 = wl_stocks[:3]
    bot3 = wl_stocks[-3:]
    
    top_str = ", ".join([f"{n}{p:+.1f}%" for n, _, p in top3])
    bot_str = ", ".join([f"{n}{p:+.1f}%" for n, _, p in bot3])
    
    lines.append(f"ğŸ“ˆ æœ€å¼º: {top_str}")
    lines.append(f"ğŸ“‰ æœ€å¼±: {bot_str}")
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. å…³é”®ä¿¡å·
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def fetch_concept_flow():
    """Fetch realtime concept flow via akshare."""
    import akshare as ak
    df = ak.stock_fund_flow_concept(symbol="å³æ—¶")
    return df


@safe_section("å…³é”®ä¿¡å·")
def section_signals(index_data: dict) -> tuple[list[str], dict]:
    """Returns (lines, signal_data)"""
    lines = ["â”â” 4. å…³é”®ä¿¡å· â”â”"]
    signal_data = {}
    
    flow_df = fetch_concept_flow()
    
    # â”€â”€ 4a. æ¦‚å¿µèµ„é‡‘æµäº®ç‚¹ (top 3 in, top 3 out â€” theme only) â”€â”€
    BROAD_CONCEPTS = [
        "è¯é‡‘æŒè‚¡", "åŒèŠ±é¡ºæ¼‚äº®", "åŒèŠ±é¡ºä¸­ç‰¹ä¼°", "èèµ„èåˆ¸", "æ·±è‚¡é€š",
        "æ²ªè‚¡é€š", "è¶…çº§å“ç‰Œ", "å‚è‚¡é“¶è¡Œ", "å‚è‚¡ä¿é™©", "å‚è‚¡åˆ¸å•†",
    ]
    theme_df = flow_df[~flow_df["è¡Œä¸š"].apply(
        lambda x: any(b in x for b in BROAD_CONCEPTS)
    )].reset_index(drop=True)
    
    if len(theme_df) == 0:
        theme_df = flow_df
    
    top3_in = theme_df.head(3)
    top3_out = theme_df.tail(3).iloc[::-1]
    
    in_parts = []
    for _, r in top3_in.iterrows():
        in_parts.append(f"{r['è¡Œä¸š']} {r['å‡€é¢']:+.1f}äº¿")
    
    out_parts = []
    for _, r in top3_out.iterrows():
        out_parts.append(f"{r['è¡Œä¸š']} {r['å‡€é¢']:.1f}äº¿")
    
    lines.append(f"â€¢ èµ„é‡‘æ¶Œå…¥: {' / '.join(in_parts)}")
    lines.append(f"â€¢ èµ„é‡‘æ’¤é€€: {' / '.join(out_parts)}")
    
    # â”€â”€ 4b. æŠ¤ç›˜æŒ‡æ ‡ â”€â”€
    hp_sectors = {"é“¶è¡Œ": "å‚è‚¡é“¶è¡Œ", "ä¿é™©": "å‚è‚¡ä¿é™©", "è¯åˆ¸": "å‚è‚¡åˆ¸å•†"}
    hp_data = {}
    hp_total = 0
    hp_count = 0
    
    for display_name, search_key in hp_sectors.items():
        match = flow_df[flow_df["è¡Œä¸š"] == search_key]
        if len(match) == 0:
            match = flow_df[flow_df["è¡Œä¸š"].str.contains(search_key, na=False)]
        if len(match) > 0:
            row = match.iloc[0]
            net = row["å‡€é¢"]
            hp_data[display_name] = net
            hp_total += net
            if net > 0:
                hp_count += 1
    
    hp_parts = []
    for name in ["é“¶è¡Œ", "ä¿é™©", "è¯åˆ¸"]:
        net = hp_data.get(name)
        if net is not None:
            emoji = "ğŸŸ¢" if net > 0 else "ğŸ”´"
            hp_parts.append(f"{emoji}{name}{net:+.1f}äº¿")
    
    if hp_count == 3:
        hp_verdict = "âš ï¸ ä¸‰å¤§é‡‘èå…¨æµå…¥ â†’ å›½å®¶æŠ¤ç›˜ï¼Œç§‘æŠ€æ‰¿å‹"
    elif hp_count >= 2:
        hp_verdict = f"ğŸŸ¡ {hp_count}/3é‡‘èæµå…¥ â†’ æœ‰æŠ¤ç›˜è¿¹è±¡"
    elif hp_total < -10:
        hp_verdict = "ğŸŸ¢ é‡‘èæµå‡º â†’ æ— éœ€æŠ¤ç›˜ï¼Œèµ„é‡‘åœ¨è¿›æ”»"
    else:
        hp_verdict = "âš–ï¸ é‡‘èä¸­æ€§"
    
    lines.append(f"â€¢ æŠ¤ç›˜: {' '.join(hp_parts)} â†’ {hp_verdict}")
    
    # â”€â”€ 4c. è¶‹åŠ¿å¼ºåº¦ â”€â”€
    top1 = theme_df.iloc[0]
    top1_net = abs(top1["å‡€é¢"])
    top1_name = top1["è¡Œä¸š"]
    
    if top1_net >= 200:
        trend_verdict = f"ğŸ”¥ å¼ºä¸»çº¿ {top1_name}({top1['å‡€é¢']:+.0f}äº¿)"
    elif top1_net >= 100:
        trend_verdict = f"ğŸ“Š æœ‰æ–¹å‘ {top1_name}({top1['å‡€é¢']:+.0f}äº¿) åŠ›åº¦ä¸€èˆ¬"
    else:
        trend_verdict = f"ğŸ˜¶ æ— ä¸»çº¿ (æœ€é«˜ä»…{top1_name} {top1['å‡€é¢']:+.0f}äº¿)"
    
    lines.append(f"â€¢ è¶‹åŠ¿: {trend_verdict}")
    
    # â”€â”€ 4d. ç™½é…’é¿é™© â”€â”€
    baijiu_net = None
    baijiu_match = flow_df[flow_df["è¡Œä¸š"].str.contains("ç™½é…’", na=False)]
    if len(baijiu_match) > 0:
        baijiu_net = baijiu_match.iloc[0]["å‡€é¢"]
        if baijiu_net > 10 and è­·ç›¤_count >= 2:
            lines.append(f"â€¢ é¿é™©: ğŸš¨ ç™½é…’{baijiu_net:+.1f}äº¿ + é‡‘èæŠ¤ç›˜ = æç«¯Risk OFF")
        elif baijiu_net > 10:
            lines.append(f"â€¢ é¿é™©: âš ï¸ ç™½é…’{baijiu_net:+.1f}äº¿æµå…¥ â†’ é˜²å¾¡é…ç½®")
        elif baijiu_net < -10:
            lines.append(f"â€¢ é¿é™©: ğŸŸ¢ ç™½é…’{baijiu_net:+.1f}äº¿æµå‡º â†’ éé¿é™©ï¼Œåè¿›æ”»")
        else:
            lines.append(f"â€¢ é¿é™©: âš–ï¸ ç™½é…’{baijiu_net:+.1f}äº¿ ä¸­æ€§")
    
    # Collect signal data
    signal_data = {
        "flow_df": flow_df,
        "theme_df": theme_df,
        "è­·ç›˜_count": è­·ç›¤_count,
        "è­·ç›¤_total": è­·ç›¤_total,
        "è­·ç›¤_data": è­·ç›¤_data,
        "top1_net": top1_net,
        "top1_name": top1_name,
        "baijiu_net": baijiu_net or 0,
    }
    
    return lines, signal_data


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. å¿«è®¯ç²¾é€‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¿«è®¯ç²¾é€‰")
def section_news_filtered() -> list[str]:
    """Fetch and filter news to 3-5 meaningful items."""
    r = requests.get(f"{API_BASE}/api/news/latest", params={"limit": 30}, timeout=10)
    data = r.json()
    news_list = data.get("news", [])
    
    if not news_list:
        return ["â”â” 5. å¿«è®¯ç²¾é€‰ â”â”", "  æš‚æ— "]
    
    # Filter: prefer news with market-moving keywords
    HIGH_VALUE_KEYWORDS = [
        "æ¶¨åœ", "è·Œåœ", "çªç ´", "æš´æ¶¨", "æš´è·Œ", "åˆ©å¥½", "åˆ©ç©º",
        "æ”¿ç­–", "å¤®è¡Œ", "é™å‡†", "é™æ¯", "ç›‘ç®¡", "åˆ¶è£", "å…³ç¨",
        "ä¸šç»©", "è¶…é¢„æœŸ", "é¢„å¢", "é¢„å‡", "å›è´­", "å¢æŒ", "å‡æŒ",
        "IPO", "é€€å¸‚", "åœç‰Œ", "å¤ç‰Œ", "é‡ç»„", "å¹¶è´­",
        "èŠ¯ç‰‡", "AI", "æœºå™¨äºº", "æ–°èƒ½æº", "å…‰ä¼", "åŠå¯¼ä½“",
    ]
    NOISE_KEYWORDS = [
        "ç›˜é¢ä¸Š", "æ—©çŸ¥é“", "å¼‚åŠ¨", "å¿«è®¯", "æ’­æŠ¥",
    ]
    
    scored = []
    for item in news_list:
        title = item.get("title", "")
        content = item.get("content", title)
        text = title + " " + content
        
        # Skip noise
        if any(nk in title for nk in NOISE_KEYWORDS):
            continue
        
        score = 0
        for kw in HIGH_VALUE_KEYWORDS:
            if kw in text:
                score += 1
        
        # Boost if mentions specific stock names or numbers
        if any(c.isdigit() for c in title):
            score += 0.5
        
        scored.append((score, item))
    
    # Sort by score, take top 5
    scored.sort(key=lambda x: x[0], reverse=True)
    top_news = [item for _, item in scored[:5]]
    
    if not top_news:
        top_news = news_list[:5]  # Fallback
    
    lines = ["â”â” 5. å¿«è®¯ç²¾é€‰ â”â”"]
    for item in top_news:
        title = item.get("title", "")[:80]
        t = item.get("time", "")
        if t and len(t) >= 16:
            t = t[11:16]
        lines.append(f"â€¢ [{t}] {title}")
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. æ“ä½œå»ºè®® (one line)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def section_advice(index_data: dict, signal_data: dict, sector_stats: dict, alert_data: dict = None) -> list[str]:
    """One-line actionable advice based on all signals."""
    sh_pct = index_data.get("000001.SH", {}).get("pct", 0)
    cy_pct = index_data.get("399006.SZ", {}).get("pct", 0)
    
    è­·ç›˜_count = signal_data.get("è­·ç›˜_count", 0)
    top1_net = signal_data.get("top1_net", 0)
    baijiu_net = signal_data.get("baijiu_net", 0)
    
    # Scoring
    bull = 0
    bear = 0
    
    if sh_pct > 0.3: bull += 1
    if sh_pct < -0.3: bear += 1
    if cy_pct > 0.3: bull += 1
    if cy_pct < -0.3: bear += 1
    if top1_net >= 200: bull += 1
    if top1_net < 100: bear += 1
    if è­·ç›˜_count == 3: bear += 1
    if baijiu_net > 10 and è­·ç›˜_count >= 2: bear += 2
    if baijiu_net < -10: bull += 1
    
    # Limit up/down
    up_count = alert_data.get("å°æ¶¨åœæ¿", {}).get("count", 0) if alert_data else 0
    down_count = alert_data.get("å°è·Œåœæ¿", {}).get("count", 0) if alert_data else 0
    if up_count > down_count * 1.5: bull += 1
    if down_count > up_count * 1.5: bear += 1
    
    # Sector breadth
    green_sectors = sum(1 for s, d in sector_stats.items() if d and d["avg_pct"] >= 0)
    total_sectors = sum(1 for s, d in sector_stats.items() if d)
    if total_sectors > 0:
        if green_sectors / total_sectors > 0.7: bull += 1
        if green_sectors / total_sectors < 0.3: bear += 1
    
    # Generate advice
    if bear >= 5:
        advice = "ğŸ›‘ æç«¯å¼±åŠ¿ï¼Œå»ºè®®ç©ºä»“è§‚æœ›ï¼Œä¸æŠ„åº•"
    elif bear >= 4:
        advice = "ğŸ›‘ ç©ºå¤´å ä¼˜ï¼Œå‡ä»“æ§é™©ï¼Œåªåšç¡®å®šæ€§æœºä¼š"
    elif bull >= 4:
        advice = "âœ… å¤šå¤´å ä¼˜ï¼Œå¯ç§¯æå‚ä¸å¼ºåŠ¿èµ›é“"
    elif bear >= 3 and bull <= 1:
        advice = "ğŸŸ¡ åå¼±ï¼Œè½»ä»“æ“ä½œï¼Œå…³æ³¨é˜²å¾¡æ¿å—"
    elif bull >= 3 and bear <= 1:
        advice = "ğŸŸ¢ åå¼ºï¼Œé€‚å½“å‚ä¸é¢†æ¶¨æ¿å—"
    else:
        advice = "âš–ï¸ éœ‡è¡æ ¼å±€ï¼Œä¿æŒçµæ´»ï¼Œç­‰æ–¹å‘ç¡®è®¤"
    
    return [f"ğŸ§  {advice}"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main: Assemble
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    is_closing = "--closing" in sys.argv
    now = datetime.now()
    time_label = now.strftime("%Y-%m-%d %H:%M")
    
    title = "ğŸ“Š Aè‚¡æ”¶ç›˜ç®€æŠ¥" if is_closing else "ğŸ“Š Aè‚¡ç®€æŠ¥"
    output = [f"{title} ({time_label})"]
    output.append("")
    
    # â”€â”€ Fetch all data â”€â”€
    
    # 1. Index data
    index_data = fetch_indices()
    if index_data:
        save_index_snapshot(index_data)
    
    # 2. Alert data
    alert_data = None
    try:
        r = requests.get(f"{API_BASE}/api/news/market-alerts", timeout=10)
        if r.ok:
            alert_data = r.json()
    except Exception:
        pass
    
    # 3. Sector stocks from DB
    sector_stocks = load_sector_stocks()
    
    # 4. Fetch ALL stock quotes (sector stocks + watchlist)
    all_tickers = set()
    for tickers in sector_stocks.values():
        all_tickers.update(tickers)
    
    watchlist = load_watchlist()
    for item in watchlist:
        all_tickers.add(item["ticker"])
    
    print(f"æ­£åœ¨è·å– {len(all_tickers)} åªè‚¡ç¥¨å®æ—¶è¡Œæƒ…...", file=sys.stderr)
    all_quotes = fetch_sina_batch(list(all_tickers))
    print(f"æˆåŠŸè·å– {len(all_quotes)} åª", file=sys.stderr)
    
    # â”€â”€ Assemble sections â”€â”€
    
    # 1. å¤§ç›˜ä¸€å¥è¯
    output.extend(section_headline(index_data, alert_data))
    output.append("")
    
    # 2. èµ›é“ä½“æ£€
    sector_result = section_sectors(sector_stocks, all_quotes)
    sector_stats = {}
    if isinstance(sector_result, tuple):
        sector_lines, sector_stats = sector_result
        output.extend(sector_lines)
    else:
        output.extend(sector_result)
    output.append("")
    
    # 3. è‡ªé€‰ vs å¤§ç›˜
    output.extend(section_watchlist_vs_index(watchlist, all_quotes, index_data))
    output.append("")
    
    # 4. å…³é”®ä¿¡å·
    signal_result = section_signals(index_data)
    signal_data = {}
    if isinstance(signal_result, tuple):
        signal_lines, signal_data = signal_result
        output.extend(signal_lines)
    else:
        output.extend(signal_result)
    output.append("")
    
    # 5. å¿«è®¯ç²¾é€‰
    output.extend(section_news_filtered())
    output.append("")
    
    # 6. æ“ä½œå»ºè®®
    output.extend(section_advice(index_data, signal_data, sector_stats, alert_data))
    
    output.append("")
    output.append(f"â± {datetime.now().strftime('%H:%M:%S')} | æ•°æ®ä»…ä¾›å‚è€ƒ")
    
    full_text = "\n".join(output)
    print(full_text)


if __name__ == "__main__":
    main()
