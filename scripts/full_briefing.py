#!/usr/bin/env python3

"""
ç»Ÿä¸€ç‰ˆå…¨é‡ç®€æŠ¥ - é›†æˆç‰ˆæœ¬
åŒ…å«ï¼šæŒ‡æ•°ã€flowã€å¼‚åŠ¨ã€Wendyåˆ†æã€è‡ªé€‰è‚¡ã€å¿«è®¯
å¯é€šè¿‡ --time/--closing/--midday å‚æ•°æ”¯æŒå¤šæ—¶æ®µ

ä½¿ç”¨æ–¹å¼:
    python3 scripts/full_briefing.py --time closing
    python3 scripts/full_briefing.py --time midday  
    python3 scripts/full_briefing.py --time opening
"""

import json
import requests
import sys
import time
from datetime import datetime
from typing import Optional
from pathlib import Path

# â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ROOT = Path(__file__).parent.parent
SNAPSHOT_FILE = PROJECT_ROOT / "data" / "snapshots" / "intraday" / "today_index_snapshots.json"
VOLUME_HISTORY_FILE = PROJECT_ROOT / "data" / "snapshots" / "daily_volume_history.json"
SNAPSHOT_FILE.parent.mkdir(parents=True, exist_ok=True)

API_BASE = "http://127.0.0.1:8000"
SINA_HEADERS = {"Referer": "https://finance.sina.com.cn", "User-Agent": "Mozilla/5.0"}

# å®½åŸº/éè¡Œä¸šæ¦‚å¿µè¿‡æ»¤åˆ—è¡¨
BROAD_CONCEPTS_FILTER = [
    "èèµ„èåˆ¸", "æ·±è‚¡é€š", "æ²ªè‚¡é€š", "è¯é‡‘æŒè‚¡", "MSCIæ¦‚å¿µ", "æ ‡æ™®é“ç¼æ–¯",
    "å¯Œæ—¶ç½—ç´ ", "åŒèŠ±é¡ºæ¼‚äº®", "åŒèŠ±é¡ºä¸­ç‰¹ä¼°", "è¶…çº§å“ç‰Œ", "åŒ—äº¤æ‰€",
    "åˆ›ä¸šæ¿ç»¼", "å‚è‚¡é“¶è¡Œ", "å‚è‚¡ä¿é™©", "å‚è‚¡åˆ¸å•†", "ç¤¾ä¿é‡ä»“",
    "é™©èµ„é‡ä»“", "åŸºé‡‘é‡ä»“", "æœºæ„é‡ä»“", "å¤–èµ„é‡ä»“", "QFIIé‡ä»“",
]

INDEX_CODES = [
    ("000001.SH", "ä¸Šè¯æŒ‡æ•°"),
    ("399001.SZ", "æ·±è¯æˆæŒ‡"),
    ("399006.SZ", "åˆ›ä¸šæ¿æŒ‡"),
    ("000688.SH", "ç§‘åˆ›50"),
    ("000852.SH", "ä¸­è¯1000"),
]


def safe_section(section_name: str):
    """Decorator to catch section errors"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                return [f"âš ï¸ [{section_name}] è·å–å¤±è´¥: {e}"]
        return wrapper
    return decorator


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. Aè‚¡æŒ‡æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def fetch_indices() -> dict:
    """Fetch current index data via Sina"""
    result = {}
    codes_str = ",".join([f"sh{c[2:] if c.startswith('0') else c[2:]}" if "SH" in c else f"sz{c[2:]}" for c, _ in INDEX_CODES])
    
    try:
        r = requests.get(
            f"http://hq.sinajs.cn/list={codes_str}",
            headers=SINA_HEADERS,
            timeout=8,
        )
        lines = r.text.strip().split("\n")
        
        for line in lines:
            if "hq_str_" in line and "=" in line and '"' in line:
                code_part = line.split("hq_str_")[1].split("=")[0]
                if code_part.startswith("sh"):
                    code = f"{code_part[2:]}.SH"
                elif code_part.startswith("sz"):
                    code = f"{code_part[2:]}.SZ"
                else:
                    continue
                
                data = line.split('"')[1].split(",")
                if len(data) > 5 and data[3] and data[2]:
                    try:
                        current_price = float(data[3])
                        prev_close = float(data[2])
                        pct_change = (current_price - prev_close) / prev_close * 100
                        amount = float(data[9]) if data[9] else 0  # æˆäº¤é‡‘é¢(å…ƒ)
                        
                        # Find name
                        name = next((n for c, n in INDEX_CODES if c == code), code)
                        
                        result[code] = {
                            "name": name,
                            "price": current_price,
                            "pct": pct_change,
                            "amount": amount,
                        }
                    except (ValueError, IndexError, ZeroDivisionError):
                        continue
    except Exception:
        pass
    
    return result


def get_volume_context() -> dict:
    """Get yesterday's and 5-day avg volume for comparison."""
    try:
        if not VOLUME_HISTORY_FILE.exists():
            return {}
        data = json.loads(VOLUME_HISTORY_FILE.read_text())
        history = data.get("history", [])
        if not history:
            return {}
        
        # Yesterday's volume
        yesterday = history[-1] if history else {}
        
        # 5-day average
        recent_5 = history[-5:] if len(history) >= 5 else history
        avg_5_total = sum(h.get("total", 0) for h in recent_5) / len(recent_5) if recent_5 else 0
        
        return {
            "yesterday_total": yesterday.get("total", 0),
            "avg_5_total": avg_5_total,
        }
    except Exception:
        return {}


@safe_section("Aè‚¡æŒ‡æ•°")
def section_indices(index_data: dict) -> list[str]:
    lines = ["ğŸ“ˆ **Aè‚¡æŒ‡æ•°**"]
    if not index_data:
        return lines + ["  æ•°æ®æš‚æ— "]

    # Calculate total volume
    total_amount = 0
    for code, _ in INDEX_CODES:
        if code not in index_data:
            continue
        d = index_data[code]
        emoji = "ğŸŸ¢" if d["pct"] >= 0 else "ğŸ”´"
        sign = "+" if d["pct"] >= 0 else ""
        amt_yi = d["amount"] / 1e4 if d["amount"] else 0  # amount inä¸‡ â†’ äº¿
        total_amount += amt_yi
        lines.append(
            f"  {emoji} {d['name']}: {d['price']:.2f} ({sign}{d['pct']:.2f}%)"
            + (f" æˆäº¤:{amt_yi:.0f}äº¿" if amt_yi > 0 else "")
        )
    
    # Volume comparison
    vol_ctx = get_volume_context()
    if vol_ctx and total_amount > 0:
        lines.append("")
        yesterday = vol_ctx.get("yesterday_total", 0)
        avg_5 = vol_ctx.get("avg_5_total", 0)
        
        if yesterday > 0:
            vs_yesterday = (total_amount - yesterday) / yesterday * 100
            vol_emoji = "ğŸ“ˆ" if vs_yesterday > 10 else "ğŸ“‰" if vs_yesterday < -10 else "â¡ï¸"
            vol_label = "æ”¾é‡" if vs_yesterday > 10 else "ç¼©é‡" if vs_yesterday < -10 else "å¹³é‡"
            lines.append(f"  ğŸ’¹ ä¸¤å¸‚æˆäº¤:{total_amount:.0f}äº¿ | {vol_emoji}{vol_label}{abs(vs_yesterday):.0f}% vsæ˜¨æ—¥")
        
        if avg_5 > 0:
            vs_avg = (total_amount - avg_5) / avg_5 * 100
            avg_label = "é«˜äº" if vs_avg > 0 else "ä½äº"
            lines.append(f"     5æ—¥å‡é‡:{avg_5:.0f}äº¿ ({avg_label}å‡å€¼{abs(vs_avg):.0f}%)")
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. å¼‚åŠ¨æ¦œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¸‚åœºå¼‚åŠ¨")
def section_alerts() -> list[str]:
    try:
        r = requests.get(f"{API_BASE}/api/anomaly/alerts", timeout=20)
        if r.status_code != 200:
            return ["âš ï¸ **å¸‚åœºå¼‚åŠ¨**", "  APIè¯·æ±‚å¤±è´¥"]
        
        alerts = r.json()
        lines = ["âš ï¸ **å¸‚åœºå¼‚åŠ¨**"]
        
        if not alerts:
            lines.append("  æš‚æ— å¼‚åŠ¨æ•°æ®")
            return lines
        
        # Sort categories for consistent display
        categories = ["å°æ¶¨åœæ¿", "å°è·Œåœæ¿", "ç‚¸æ¿", "æ€¥é€Ÿæ‹‰å‡", "æ€¥é€Ÿä¸‹è·Œ", "é‡æ¯”æ”¾å¤§"]
        for category in categories:
            if category in alerts:
                data = alerts[category]
                count = data.get("count", 0)
                stocks = data.get("stocks", [])
                
                if count > 0:
                    emoji = {"å°æ¶¨åœæ¿": "ğŸ“ˆ", "å°è·Œåœæ¿": "ğŸ“‰", "ç‚¸æ¿": "ğŸ’¥"}.get(category, "âš¡")
                    lines.append(f"  {emoji} {category}: {count}åª")
                    
                    # Show top 3
                    for stock in stocks[:3]:
                        name = stock.get("name", "")
                        code = stock.get("code", "")
                        pct = stock.get("change_pct", 0)
                        lines.append(f"    â€¢ {name}({code}) {pct:+.2f}%")
                    
                    if len(stocks) > 3:
                        lines.append(f"    ï¼ˆè¿˜æœ‰{len(stocks) - 3}åª...ï¼‰")
        return lines
    except Exception as e:
        return ["âš ï¸ **å¸‚åœºå¼‚åŠ¨**", f"  è·å–å¤±è´¥: {e}"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ç›˜ä¸­è·¯å¾„åˆ†æ (æ›¿ä»£åŸæ¥çš„è¡¨æ ¼)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ç›˜ä¸­è·¯å¾„")
def section_intraday_table() -> list[str]:
    if not SNAPSHOT_FILE.exists():
        return ["ğŸ“ˆ **ç›˜ä¸­è·¯å¾„**", "  æš‚æ— å¿«ç…§æ•°æ®"]

    data = json.loads(SNAPSHOT_FILE.read_text())
    snapshots = data.get("snapshots", [])
    if len(snapshots) < 2:
        return ["ğŸ“ˆ **ç›˜ä¸­è·¯å¾„**", "  å¿«ç…§ä¸è¶³ï¼Œæ— æ³•åˆ†æ"]

    lines = ["ğŸ“ˆ **ç›˜ä¸­è·¯å¾„åˆ†æ**"]
    
    # åˆ†æä¸Šè¯æŒ‡æ•°è·¯å¾„ (000001.SH)
    sh_data = []
    for snap in snapshots:
        idx = snap.get("indexes", {}).get("000001.SH", {})
        price = idx.get("price", 0)
        pct = idx.get("pct", 0)
        if price > 0:
            sh_data.append({"time": snap["time"], "price": price, "pct": pct})
    
    if len(sh_data) < 2:
        return lines + ["  æ•°æ®ä¸è¶³"]
    
    # å…³é”®ç‚¹åˆ†æ
    open_pct = sh_data[0]["pct"]
    current_pct = sh_data[-1]["pct"]
    current_price = sh_data[-1]["price"]
    current_time = sh_data[-1]["time"]
    
    # æ‰¾é«˜ä½ç‚¹
    high_point = max(sh_data, key=lambda x: x["price"])
    low_point = min(sh_data, key=lambda x: x["price"])
    
    # å¼€ç›˜å®šæ€§
    if open_pct < -0.5:
        open_desc = f"ä½å¼€{abs(open_pct):.1f}%"
    elif open_pct > 0.5:
        open_desc = f"é«˜å¼€{open_pct:.1f}%"
    else:
        open_desc = "å¹³å¼€"
    
    # èµ°åŠ¿æè¿°
    path_parts = []
    path_parts.append(f"å¼€ç›˜{open_desc}")
    
    # åˆ†æèµ°åŠ¿é˜¶æ®µ
    if len(sh_data) >= 3:
        # å‰1/3æ—¶æ®µ
        early_idx = len(sh_data) // 3
        early_pct = sh_data[early_idx]["pct"]
        early_time = sh_data[early_idx]["time"]
        
        if early_pct < open_pct - 0.3:
            path_parts.append(f"æ—©ç›˜ä¸‹æ¢è‡³{early_pct:+.1f}%")
        elif early_pct > open_pct + 0.3:
            path_parts.append(f"æ—©ç›˜æ‹‰å‡è‡³{early_pct:+.1f}%")
        else:
            path_parts.append("æ—©ç›˜çª„å¹…éœ‡è¡")
    
    # ä½ç‚¹åˆ°ç°åœ¨çš„èµ°åŠ¿
    if low_point["pct"] < current_pct - 0.5 and low_point["time"] < current_time:
        recovery = current_pct - low_point["pct"]
        path_parts.append(f"ä»{low_point['time']}ä½ç‚¹{low_point['pct']:+.1f}%åå¼¹{recovery:.1f}%")
    elif high_point["pct"] > current_pct + 0.5 and high_point["time"] < current_time:
        drop = high_point["pct"] - current_pct
        path_parts.append(f"ä»{high_point['time']}é«˜ç‚¹{high_point['pct']:+.1f}%å›è½{drop:.1f}%")
    
    # å½“å‰çŠ¶æ€
    lines.append(f"  **ä¸Šè¯**: {' â†’ '.join(path_parts)}")
    lines.append(f"  **ç°ä»·**: {current_price:.2f} ({current_pct:+.2f}%) @{current_time}")
    
    # å½¢æ€åˆ¤æ–­
    amplitude = high_point["pct"] - low_point["pct"]
    if current_pct > 0.8:
        candle = "ä¸­é˜³çº¿" if current_pct < 2 else "å¤§é˜³çº¿"
    elif current_pct < -0.8:
        candle = "ä¸­é˜´çº¿" if current_pct > -2 else "å¤§é˜´çº¿"
    elif amplitude < 0.5:
        candle = "åå­—æ˜Ÿ"
    else:
        candle = "å°é˜³çº¿" if current_pct > 0 else "å°é˜´çº¿"
    
    lines.append(f"  **å½¢æ€**: {candle} | æŒ¯å¹…{amplitude:.1f}%")
    
    # è¶‹åŠ¿é¢„åˆ¤
    lines.append("")
    if current_pct > 0.5 and low_point["time"] < "10:30" and current_time >= "11:00":
        lines.append("  ğŸ’¡ *æ—©ç›˜æ¢åº•å›å‡ï¼Œä¸‹åˆå¤§æ¦‚ç‡å»¶ç»­æ¶¨åŠ¿*")
    elif current_pct < -0.5 and high_point["time"] < "10:30":
        lines.append("  ğŸ’¡ *æ—©ç›˜å†²é«˜å›è½ï¼Œä¸‹åˆæˆ–ç»§ç»­æ‰¿å‹*")
    elif amplitude > 2 and abs(current_pct) < 0.5:
        lines.append("  ğŸ’¡ *æŒ¯å¹…å¤§ä½†æ”¶ç›˜ä¸­æ€§ï¼Œå¤šç©ºåˆ†æ­§å¤§*")
    elif current_pct > 0 and amplitude < 1:
        lines.append("  ğŸ’¡ *çª„å¹…ä¸Šæ¶¨ï¼Œèµ°åŠ¿å¹³ç¨³*")
    elif current_pct < 0 and amplitude < 1:
        lines.append("  ğŸ’¡ *çª„å¹…ä¸‹è·Œï¼ŒæŠ›å‹æœ‰é™*")
    else:
        lines.append("  ğŸ’¡ *èµ°åŠ¿æ­£å¸¸ï¼Œå…³æ³¨ä¸‹åˆèƒ½å¦çªç ´*")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. FLOW-TOP20 (æ¦‚å¿µèµ„é‡‘æµå‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def section_flow_top20() -> tuple[list[str], Optional]:
    try:
        r = requests.get(f"{API_BASE}/api/rotation/top-inflow", timeout=10)
        if r.status_code != 200:
            return ["ğŸ’° **Flow-TOP20**", "  APIè¯·æ±‚å¤±è´¥"], None
        
        df = r.json()
        if not df:
            return ["ğŸ’° **Flow-TOP20**", "  æ•°æ®ä¸ºç©º"], None
    except Exception as e:
        return ["ğŸ’° **Flow-TOP20**", f"  è·å–å¤±è´¥: {e}"], None

    import pandas as pd
    df = pd.DataFrame(df)
    
    # Remap new API column names to legacy names used throughout this function
    col_map = {"name": "è¡Œä¸š", "net_inflow": "å‡€é¢", "pct_change": "æ¶¨è·Œå¹…"}
    df = df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})
    
    # Add placeholder columns for leader stock (not available in new API)
    if "é¢†æ¶¨è‚¡" not in df.columns:
        df["é¢†æ¶¨è‚¡"] = ""
    if "é¢†æ¶¨è‚¡-æ¶¨è·Œå¹…" not in df.columns:
        df["é¢†æ¶¨è‚¡-æ¶¨è·Œå¹…"] = 0.0
    
    total = len(df)
    net_in = len(df[df["å‡€é¢"] > 0])
    net_out = total - net_in
    
    # Sort by å‡€é¢ descending (should already be, but ensure)
    df_sorted = df.sort_values("å‡€é¢", ascending=False).reset_index(drop=True)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ä¸»é¢˜èšåˆåˆ†æ â€” æŠŠç›¸å…³æ¦‚å¿µå½’ç±»ï¼Œç®—å‡ºçœŸæ­£çš„ä¸»çº¿èµ„é‡‘è§„æ¨¡
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    THEME_KEYWORDS = {
        "ç”µæ± /æ–°èƒ½æºè½¦": ["é”‚ç”µæ± ", "å‚¨èƒ½", "å›ºæ€ç”µæ± ", "é’ ç¦»å­", "æ–°èƒ½æºæ±½è½¦", "æ¯”äºšè¿ª", "å®å¾·æ—¶ä»£", "åŠ¨åŠ›ç”µæ± ", "ç”µè§£æ¶²", "æ­£æ", "è´Ÿæ", "éš”è†œ", "å……ç”µæ¡©"],
        "æœºå™¨äºº": ["æœºå™¨äºº", "äººå½¢æœºå™¨äºº", "å‡é€Ÿå™¨", "ä¼ºæœ", "å·¥ä¸šæ¯æœº"],
        "AI/ç®—åŠ›": ["AIåº”ç”¨", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "æ•°æ®ä¸­å¿ƒ", "CPO", "å…‰æ¨¡å—", "æœåŠ¡å™¨", "è‹±ä¼Ÿè¾¾", "åä¸ºæ˜‡è…¾"],
        "åŠå¯¼ä½“": ["èŠ¯ç‰‡", "åŠå¯¼ä½“", "å…‰åˆ»", "å°è£…", "å­˜å‚¨", "IGBT"],
        "æ±½è½¦é“¾": ["ç‰¹æ–¯æ‹‰", "æ™ºèƒ½é©¾é©¶", "æ±½è½¦ç”µå­", "çº¿æ§", "ä¸€ä½“åŒ–å‹é“¸"],
    }
    
    # è®¡ç®—æ¯ä¸ªä¸»é¢˜çš„æ€»å‡€æµå…¥
    theme_flows = {}
    theme_concepts = {}  # è®°å½•æ¯ä¸ªä¸»é¢˜åŒ…å«å“ªäº›æ¦‚å¿µ
    matched_concepts = set()
    
    for theme, keywords in THEME_KEYWORDS.items():
        theme_flows[theme] = 0
        theme_concepts[theme] = []
        for _, row in df_sorted.iterrows():
            concept_name = row["è¡Œä¸š"]
            if concept_name in matched_concepts:
                continue
            for kw in keywords:
                if kw in concept_name:
                    theme_flows[theme] += row["å‡€é¢"]
                    theme_concepts[theme].append((concept_name, row["å‡€é¢"]))
                    matched_concepts.add(concept_name)
                    break
    
    # æŒ‰å‡€æµå…¥æ’åº
    sorted_themes = sorted(theme_flows.items(), key=lambda x: x[1], reverse=True)
    
    lines = [
        f"ğŸ’° **ä¸»çº¿èµ„é‡‘æµåˆ†æ**",
        f"å…±{total}ä¸ªæ¦‚å¿µ | {net_in}ä¸ªå‡€æµå…¥ | {net_out}ä¸ªå‡€æµå‡º",
        "",
    ]
    
    # è¾“å‡ºä¸»é¢˜èšåˆç»“æœ
    lines.append("**ğŸ“Š ä»Šæ—¥ä¸»çº¿ï¼ˆæ¦‚å¿µèšåˆï¼‰:**")
    main_themes = []
    for theme, total_flow in sorted_themes:
        if total_flow > 50:  # åªæ˜¾ç¤º>50äº¿çš„ä¸»é¢˜
            concepts = theme_concepts[theme]
            concept_count = len(concepts)
            if concept_count > 0:
                emoji = "ğŸ”¥" if total_flow > 300 else "ğŸ“ˆ" if total_flow > 100 else "ğŸ“Š"
                strength = "è¶…å¼ºä¸»çº¿" if total_flow > 300 else "å¼ºä¸»çº¿" if total_flow > 150 else "ä¸»çº¿"
                lines.append(f"  {emoji} **{theme}**: {total_flow:+.0f}äº¿ ({strength}, å«{concept_count}ä¸ªæ¦‚å¿µ)")
                main_themes.append((theme, total_flow))
    
    if not main_themes:
        lines.append("  æ— æ˜æ˜¾ä¸»çº¿ï¼ˆå„ä¸»é¢˜æµå…¥å‡<50äº¿ï¼‰")
    
    lines.append("")
    
    # è¿‡æ»¤å®½åŸºæ¦‚å¿µï¼Œåªä¿ç•™çœŸæ­£çš„è¡Œä¸šæ¿å—
    sector_df = df_sorted[~df_sorted["è¡Œä¸š"].apply(
        lambda x: any(b in x for b in BROAD_CONCEPTS_FILTER)
    )].reset_index(drop=True)
    
    # çœŸæ­£çš„è¡Œä¸šTOP5
    lines.append("**ğŸ“‹ è¡Œä¸šæ¿å—TOP5:**")
    top5 = sector_df.head(5)
    for i, (_, row) in enumerate(top5.iterrows(), 1):
        name = row["è¡Œä¸š"]
        net = row["å‡€é¢"]
        lead = row.get("é¢†æ¶¨è‚¡", "")
        pct = row.get("æ¶¨è·Œå¹…", 0)
        if lead:
            lead_pct = row.get("é¢†æ¶¨è‚¡-æ¶¨è·Œå¹…", 0)
            lines.append(f"  {i}. {name} {net:+.0f}äº¿ | é¢†æ¶¨:{lead}({lead_pct:+.1f}%)")
        else:
            lines.append(f"  {i}. {name} {net:+.0f}äº¿ | æ¿å—{pct:+.1f}%")

    # æµå‡ºå‰3 (ä¹Ÿè¿‡æ»¤å®½åŸº)
    bot3 = sector_df.tail(3).iloc[::-1]
    lines.append("**ğŸ“‰ æµå‡ºå‰3:**")
    for _, row in bot3.iterrows():
        name = row["è¡Œä¸š"]
        net = row["å‡€é¢"]
        lines.append(f"  â€¢ {name} {net:.0f}äº¿")

    return lines, df_sorted


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. ğŸ§  Wendyåˆ†æ (Rule-based, ZERO AI) â€” é‡Insightç‰ˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("Wendyåˆ†æ")
def section_analysis(index_data: dict, flow_df, alert_data: dict = None) -> list[str]:
    lines = ["ğŸ§  **Wendy æ·±åº¦åˆ†æ**"]
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # åŸºç¡€æ•°æ®æå–
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    sh_pct = index_data.get("000001.SH", {}).get("pct", 0)
    sz_pct = index_data.get("399001.SZ", {}).get("pct", 0)
    cy_pct = index_data.get("399006.SZ", {}).get("pct", 0)
    kc_pct = index_data.get("000688.SH", {}).get("pct", 0)
    scissor = sh_pct - cy_pct

    # æ¶¨è·Œåœæ•°æ®
    up_count = alert_data.get("å°æ¶¨åœæ¿", {}).get("count", 0) if alert_data else 0
    down_count = alert_data.get("å°è·Œåœæ¿", {}).get("count", 0) if alert_data else 0
    ud_ratio = up_count / down_count if down_count > 0 else float('inf')

    # èµ„é‡‘æµæ•°æ®
    n_in, n_out, pct_in, total_net = 0, 0, 0, 0
    top1_name, top1_net = "", 0
    è­·ç›˜_count, è­·ç›˜_total = 0, 0
    baijiu_net = None
    theme_clusters = {}

    if flow_df is not None and len(flow_df) > 0:
        n_in = len(flow_df[flow_df["å‡€é¢"] > 0])
        n_out = len(flow_df[flow_df["å‡€é¢"] <= 0])
        total_concepts = len(flow_df)
        pct_in = n_in / total_concepts * 100 if total_concepts > 0 else 0
        total_net = flow_df["å‡€é¢"].sum()

        # æ’é™¤å®½åŸºæ¦‚å¿µ
        BROAD_CONCEPTS = ["è¯é‡‘æŒè‚¡", "åŒèŠ±é¡ºæ¼‚äº®", "åŒèŠ±é¡ºä¸­ç‰¹ä¼°", "èèµ„èåˆ¸", 
                         "æ·±è‚¡é€š", "æ²ªè‚¡é€š", "è¶…çº§å“ç‰Œ", "å‚è‚¡é“¶è¡Œ", "å‚è‚¡ä¿é™©", "å‚è‚¡åˆ¸å•†"]
        theme_df = flow_df[~flow_df["è¡Œä¸š"].apply(
            lambda x: any(b in x for b in BROAD_CONCEPTS)
        )].reset_index(drop=True)
        if len(theme_df) == 0:
            theme_df = flow_df
        top1 = theme_df.iloc[0]
        top1_name = top1["è¡Œä¸š"]
        top1_net = top1["å‡€é¢"]

        # æŠ¤ç›˜æ¿å—
        è­·ç›˜_sectors = {"é“¶è¡Œ": "å‚è‚¡é“¶è¡Œ", "ä¿é™©": "å‚è‚¡ä¿é™©", "è¯åˆ¸": "å‚è‚¡åˆ¸å•†"}
        for display_name, search_key in è­·ç›˜_sectors.items():
            match = flow_df[flow_df["è¡Œä¸š"] == search_key]
            if len(match) == 0:
                match = flow_df[flow_df["è¡Œä¸š"].str.contains(search_key, na=False)]
            if len(match) > 0:
                net = match.iloc[0]["å‡€é¢"]
                è­·ç›˜_total += net
                if net > 0:
                    è­·ç›˜_count += 1

        # ç™½é…’
        baijiu_match = flow_df[flow_df["è¡Œä¸š"].str.contains("ç™½é…’", na=False)]
        if len(baijiu_match) > 0:
            baijiu_net = baijiu_match.iloc[0]["å‡€é¢"]

        # ä¸»é¢˜èšç±»
        sector_keywords = {
            "æ–°èƒ½æº/ç”µæ± ": ["é”‚ç”µæ± ", "å‚¨èƒ½", "å›ºæ€ç”µæ± ", "é’ ç¦»å­", "æ–°èƒ½æºæ±½è½¦", "æ¯”äºšè¿ª", "å®å¾·æ—¶ä»£", "å……ç”µæ¡©"],
            "æœºå™¨äºº/æ™ºé€ ": ["æœºå™¨äºº", "äººå½¢æœºå™¨äºº", "å‡é€Ÿå™¨", "ä¼ºæœ", "å·¥ä¸šæ¯æœº"],
            "AI/ç®—åŠ›": ["AIåº”ç”¨", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "æ•°æ®ä¸­å¿ƒ", "CPO", "å…‰æ¨¡å—", "è‹±ä¼Ÿè¾¾", "åä¸ºæ˜‡è…¾"],
            "åŠå¯¼ä½“": ["èŠ¯ç‰‡", "åŠå¯¼ä½“", "å…‰åˆ»", "å°è£…", "å­˜å‚¨", "IGBT"],
            "æ±½è½¦é“¾": ["ç‰¹æ–¯æ‹‰", "æ™ºèƒ½é©¾é©¶", "æ±½è½¦ç”µå­", "çº¿æ§", "ä¸€ä½“åŒ–å‹é“¸"],
        }
        top10_names = theme_df.head(10)["è¡Œä¸š"].tolist()
        for label, keywords in sector_keywords.items():
            count = sum(1 for name in top10_names if any(kw in name for kw in keywords))
            if count >= 2:
                theme_clusters[label] = count

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1ï¸âƒ£ ä»Šæ—¥å¸‚åœºç”»åƒ (ä¸€å¥è¯å®šæ€§ + åŸå› )
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("**1ï¸âƒ£ ä»Šæ—¥å¸‚åœºç”»åƒ**")
    
    # ç»¼åˆåˆ¤æ–­å¸‚åœºçŠ¶æ€
    if sh_pct > 0.5 and cy_pct > 0.5 and ud_ratio > 3:
        market_state = "ğŸ”¥ å¼ºåŠ¿åšå¤šæ—¥"
        market_reason = f"ä¸¤å¸‚æ™®æ¶¨ï¼Œæ¶¨åœ{up_count}åªè¿œè¶…è·Œåœ{down_count}åªï¼Œèµ„é‡‘è¿›æ”»æ„æ„¿å¼º"
    elif sh_pct < -0.5 and cy_pct < -0.5 and ud_ratio < 0.5:
        market_state = "ğŸ’€ ææ…Œæ€è·Œæ—¥"
        market_reason = f"ä¸¤å¸‚æ™®è·Œï¼Œè·Œåœ{down_count}åªå¤šäºæ¶¨åœï¼Œææ…Œæƒ…ç»ªè”“å»¶"
    elif scissor > 1.5:
        market_state = "ğŸ›¡ï¸ å¤§ç›˜è‚¡æŠ¤ç›˜æ—¥"
        market_reason = f"ä¸Šè¯è·‘èµ¢åˆ›ä¸šæ¿{scissor:.1f}%ï¼Œæƒé‡è‚¡æ‹‰æŒ‡æ•°ã€å°ç›˜è‚¡è¢«æŠ›å”®"
    elif scissor < -1.5:
        market_state = "ğŸš€ é¢˜æç‚’ä½œæ—¥"
        market_reason = f"åˆ›ä¸šæ¿è·‘èµ¢ä¸Šè¯{-scissor:.1f}%ï¼Œèµ„é‡‘å¼ƒå¤§åšå°ã€è¿½é€æ¦‚å¿µ"
    elif abs(sh_pct) < 0.3 and abs(cy_pct) < 0.3:
        market_state = "ğŸ˜´ ç¼©é‡éœ‡è¡æ—¥"
        market_reason = "ä¸¤å¸‚æ³¢åŠ¨æå°ï¼Œå¤šç©ºåƒµæŒï¼Œè§‚æœ›æƒ…ç»ªæµ“"
    elif è­·ç›˜_count >= 2 and (baijiu_net is not None and baijiu_net > 10):
        market_state = "âš ï¸ æç«¯é¿é™©æ—¥"
        market_reason = "é‡‘è+ç™½é…’åŒæ—¶å¸é‡‘ï¼Œæœºæ„æŠ›å”®æˆé•¿è‚¡ã€æ¶Œå…¥é˜²å¾¡æ¿å—"
    else:
        market_state = "âš–ï¸ åˆ†åŒ–éœ‡è¡æ—¥"
        market_reason = f"æ¿å—åˆ†åŒ–ï¼Œä¸Šè¯{sh_pct:+.2f}% vs åˆ›ä¸šæ¿{cy_pct:+.2f}%"

    lines.append(f"  {market_state}")
    lines.append(f"  ğŸ’¡ *{market_reason}*")
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2ï¸âƒ£ ä¸»çº¿è¯†åˆ« + æŒç»­æ€§åˆ¤æ–­
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("**2ï¸âƒ£ ä»Šæ—¥ä¸»çº¿ & æŒç»­æ€§**")
    
    if top1_net >= 200:
        strength_tag = "ğŸ”¥è¶…å¼ºä¸»çº¿"
        persistence = "é«˜æ¦‚ç‡å»¶ç»­ï¼Œå¯é‡ä»“è·Ÿè¿›"
    elif top1_net >= 100:
        strength_tag = "ğŸ“Šä¸­ç­‰ä¸»çº¿"
        persistence = "æœ‰å»¶ç»­å¯èƒ½ï¼Œé€‚åº¦å‚ä¸"
    elif top1_net >= 50:
        strength_tag = "ğŸ“‰å¼±ä¸»çº¿"
        persistence = "æŒç»­æ€§å­˜ç–‘ï¼Œå¿«è¿›å¿«å‡º"
    else:
        strength_tag = "ğŸ˜¶æ— ä¸»çº¿"
        persistence = "èµ„é‡‘åˆ†æ•£ï¼Œä¸å®œè¿½æ¶¨"

    lines.append(f"  â€¢ ä¸»çº¿ï¼š**{top1_name}** ({top1_net:+.0f}äº¿) â€” {strength_tag}")
    lines.append(f"  â€¢ æŒç»­æ€§åˆ¤æ–­ï¼š{persistence}")

    # ä¸»é¢˜é›†ä¸­åº¦åˆ†æ
    if theme_clusters:
        dominant = max(theme_clusters, key=theme_clusters.get)
        lines.append(f"  â€¢ é›†ä¸­åº¦ï¼šTOP10ä¸­{dominant}å {theme_clusters[dominant]}å¸­ â†’ æ–¹å‘æ˜ç¡®")
        if len(theme_clusters) > 1:
            others = [f"{k}({v})" for k, v in theme_clusters.items() if k != dominant]
            lines.append(f"  â€¢ æ¬¡çº¿ç´¢ï¼š{', '.join(others)}")
    else:
        lines.append(f"  â€¢ é›†ä¸­åº¦ï¼šTOP10åˆ†æ•£ï¼Œæ— æ˜æ˜¾ä¸»é¢˜èšé›† â†’ éš¾ä»¥æŒç»­")
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3ï¸âƒ£ èµ„é‡‘è¡Œä¸ºåˆ†æ (æµå‘ vs æ¶¨è·Œä¸€è‡´æ€§)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("**3ï¸âƒ£ èµ„é‡‘è¡Œä¸ºè§£è¯»**")
    
    # å…¨å¸‚åœºèµ„é‡‘æµ
    if total_net > 50:
        flow_state = f"ğŸŸ¢ å‡€æµå…¥{total_net:.0f}äº¿"
        flow_meaning = "åœºå¤–èµ„é‡‘è¿›åœºï¼Œè¡Œæƒ…æœ‰æ”¯æ’‘"
    elif total_net < -50:
        flow_state = f"ğŸ”´ å‡€æµå‡º{abs(total_net):.0f}äº¿"
        flow_meaning = "èµ„é‡‘å‡ºé€ƒï¼Œè°¨æ…è¿½æ¶¨"
    else:
        flow_state = f"âš–ï¸ å‡€é¢{total_net:+.0f}äº¿"
        flow_meaning = "èµ„é‡‘æ‹‰é”¯ï¼Œæ–¹å‘ä¸æ˜"
    
    lines.append(f"  â€¢ å…¨å¸‚åœºï¼š{flow_state} â†’ {flow_meaning}")
    lines.append(f"  â€¢ æ¦‚å¿µåˆ†å¸ƒï¼š{n_in}ä¸ªæµå…¥ vs {n_out}ä¸ªæµå‡º ({pct_in:.0f}%æ­£å‘)")

    # èµ„é‡‘æµå‘ vs æŒ‡æ•°æ¶¨è·Œçš„ä¸€è‡´æ€§åˆ¤æ–­
    if total_net > 30 and sh_pct > 0.3:
        consistency = "âœ… ä¸€è‡´ï¼šèµ„é‡‘æµå…¥+æŒ‡æ•°ä¸Šæ¶¨ï¼Œå¥åº·ä¸Šæ¶¨"
    elif total_net < -30 and sh_pct < -0.3:
        consistency = "âœ… ä¸€è‡´ï¼šèµ„é‡‘æµå‡º+æŒ‡æ•°ä¸‹è·Œï¼Œé¡ºåŠ¿è°ƒæ•´"
    elif total_net > 30 and sh_pct < -0.3:
        consistency = "âš ï¸ èƒŒç¦»ï¼šèµ„é‡‘å‡€æµå…¥ä½†æŒ‡æ•°è·Œ â†’ ä¸»åŠ›å¯èƒ½åœ¨å¸ç­¹"
    elif total_net < -30 and sh_pct > 0.3:
        consistency = "âš ï¸ èƒŒç¦»ï¼šèµ„é‡‘å‡€æµå‡ºä½†æŒ‡æ•°æ¶¨ â†’ æ‹‰é«˜å‡ºè´§é£é™©"
    else:
        consistency = "âš–ï¸ æ— æ˜æ˜¾èƒŒç¦»"
    
    lines.append(f"  â€¢ æµå‘vsæ¶¨è·Œï¼š{consistency}")
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4ï¸âƒ£ é£é™©ä¿¡å·æ‰«æ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("**4ï¸âƒ£ é£é™©ä¿¡å·**")
    
    risks = []
    
    # æŠ¤ç›˜ä¿¡å·
    if è­·ç›˜_count == 3:
        risks.append(f"ğŸš¨ ä¸‰å¤§é‡‘èå…¨éƒ¨å‡€æµå…¥({è­·ç›˜_total:+.0f}äº¿) â€” å›½å®¶æŠ¤ç›˜ï¼Œæˆé•¿è‚¡æ‰¿å‹")
    elif è­·ç›˜_count >= 2:
        risks.append(f"âš ï¸ {è­·ç›˜_count}/3é‡‘èæ¿å—å‡€æµå…¥ â€” æœ‰æŠ¤ç›˜è¿¹è±¡")
    
    # ç™½é…’é¿é™©
    if baijiu_net is not None and baijiu_net > 15:
        risks.append(f"âš ï¸ ç™½é…’å¸é‡‘{baijiu_net:.0f}äº¿ â€” èµ„é‡‘æ¶Œå…¥é˜²å¾¡ï¼ŒRisk OFF")
    
    # è·Œåœé£é™©
    if down_count > 30:
        risks.append(f"âš ï¸ è·Œåœ{down_count}åª â€” ä¸ªè‚¡é›·åŒºå¤šï¼Œæ³¨æ„è¸©é›·")
    
    # æ¶¨è·Œåœæ¯”æç«¯
    if ud_ratio < 0.5:
        risks.append(f"ğŸ”´ æ¶¨è·Œåœæ¯”{up_count}:{down_count} â€” ç©ºå¤´å ç»å¯¹ä¼˜åŠ¿")
    
    # å¤§å°ç›˜å‰ªåˆ€å·®
    if scissor > 2:
        risks.append(f"âš ï¸ å¤§å°ç›˜å‰ªåˆ€å·®{scissor:.1f}% â€” å°ç›˜è‚¡è¢«æŠ›å¼ƒ")
    elif scissor < -2:
        risks.append(f"âš ï¸ å¤§å°ç›˜å‰ªåˆ€å·®{scissor:.1f}% â€” æƒé‡æ‹–ç´¯ï¼ŒæŒ‡æ•°å¤±çœŸ")
    
    if not risks:
        lines.append("  âœ… æš‚æ— æ˜æ˜¾é£é™©ä¿¡å·")
    else:
        for r in risks:
            lines.append(f"  â€¢ {r}")
    lines.append("")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5ï¸âƒ£ æ“ä½œå»ºè®® (ç»“è®ºå¯¼å‘)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    lines.append("**5ï¸âƒ£ Wendyå»ºè®®**")
    
    # ç»¼åˆæ‰“åˆ†
    score = 0
    if sh_pct > 0.3: score += 1
    if cy_pct > 0.3: score += 1
    if pct_in > 55: score += 1
    if ud_ratio > 2: score += 1
    if top1_net >= 150: score += 1
    if total_net > 30: score += 1
    
    if sh_pct < -0.3: score -= 1
    if cy_pct < -0.3: score -= 1
    if pct_in < 40: score -= 1
    if ud_ratio < 0.7: score -= 1
    if è­·ç›˜_count >= 2: score -= 1
    if baijiu_net is not None and baijiu_net > 10: score -= 1

    if score >= 4:
        advice = "âœ… ç§¯æåšå¤š"
        detail = f"è·Ÿè¿›{top1_name}ç­‰ä¸»çº¿ï¼Œä»“ä½å¯åŠ åˆ°7æˆ"
    elif score >= 2:
        advice = "ğŸŸ¢ åå¤šæ“ä½œ"
        detail = f"å‚ä¸å¼ºåŠ¿æ¿å—ï¼Œæ§åˆ¶åœ¨5æˆä»“ä½"
    elif score <= -3:
        advice = "ğŸ›‘ é˜²å®ˆä¸ºä¸»"
        detail = "é™ä»“è‡³3æˆä»¥ä¸‹ï¼Œåªåšè¶…è·Œåå¼¹"
    elif score <= -1:
        advice = "ğŸŸ¡ è°¨æ…è§‚æœ›"
        detail = "è½»ä»“è¯•æ¢ï¼Œä¸¥æ ¼æ­¢æŸ"
    else:
        advice = "âš–ï¸ çµæ´»åº”å¯¹"
        detail = "æ— æ˜ç¡®æ–¹å‘ï¼Œæ—¥å†…é«˜æŠ›ä½å¸"

    lines.append(f"  **{advice}** â€” {detail}")
    lines.append(f"  (ç»¼åˆè¯„åˆ†: {score:+d} | å¤šç©ºä¿¡å·æ¯”)")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. è‡ªé€‰è‚¡èµ›é“æ±‡æ€»
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("èµ›é“æ±‡æ€»")
def section_stock_sectors() -> list[str]:
    """æŒ‰è‡ªå®šä¹‰èµ›é“åˆ†ç»„ç»Ÿè®¡æ¶¨è·Œ"""
    # Get watchlist with sector info
    r = requests.get(f"{API_BASE}/api/watchlist", timeout=10)
    if r.status_code != 200:
        return ["ğŸ“Š **èµ›é“æ±‡æ€»**", "  è·å–è‡ªé€‰è‚¡åˆ—è¡¨å¤±è´¥"]
    watchlist = r.json()
    if not watchlist:
        return ["ğŸ“Š **èµ›é“æ±‡æ€»**", "  è‡ªé€‰è‚¡åˆ—è¡¨ä¸ºç©º"]

    # Build ticker -> sector mapping
    ticker_sector = {}
    ticker_name = {}
    for w in watchlist:
        ticker = w.get("ticker", "")
        sector = w.get("sector", "")
        if ticker and sector:
            ticker_sector[ticker] = sector
            ticker_name[ticker] = w.get("name", ticker)

    # Get available sectors
    sector_resp = requests.get(f"{API_BASE}/api/sectors/list/available", timeout=10)
    available_sectors = sector_resp.json().get("sectors", []) if sector_resp.status_code == 200 else []

    # Fetch prices via Sina
    tickers = list(ticker_sector.keys())
    price_data = {}  # ticker -> (price, change_pct)
    
    for i in range(0, len(tickers), 50):
        batch = tickers[i:i + 50]
        codes = ",".join([f"sh{t}" if t.startswith("6") else f"sz{t}" for t in batch])
        try:
            pr = requests.get(
                f"http://hq.sinajs.cn/list={codes}",
                headers=SINA_HEADERS, timeout=10,
            )
            for line in pr.text.strip().split("\n"):
                if "hq_str_" in line and '"' in line:
                    code_part = line.split("hq_str_")[1].split("=")[0]
                    ticker = code_part[2:]
                    data = line.split('"')[1].split(",")
                    if len(data) > 4 and data[3] and data[2]:
                        try:
                            cur = float(data[3])
                            prev = float(data[2])
                            if prev > 0:
                                pct = (cur - prev) / prev * 100
                                price_data[ticker] = (cur, pct)
                        except (ValueError, ZeroDivisionError):
                            pass
        except Exception:
            pass
        time.sleep(0.1)

    # Calculate sector stats
    sector_stats = {}
    for sector in available_sectors:
        sector_stats[sector] = {
            "count": 0,
            "changes": [],
            "up": 0,
            "down": 0,
            "limit_up": 0,
            "limit_down": 0,
            "max_gainer": None,
            "max_loser": None,
        }

    for ticker, sector in ticker_sector.items():
        if sector not in sector_stats:
            continue
        if ticker not in price_data:
            continue
        
        price, pct = price_data[ticker]
        name = ticker_name.get(ticker, ticker)
        
        sector_stats[sector]["count"] += 1
        sector_stats[sector]["changes"].append(pct)
        
        if pct > 0.01:
            sector_stats[sector]["up"] += 1
        elif pct < -0.01:
            sector_stats[sector]["down"] += 1
        
        if pct >= 9.9:
            sector_stats[sector]["limit_up"] += 1
        elif pct <= -9.9:
            sector_stats[sector]["limit_down"] += 1
        
        current = {"ticker": ticker, "name": name, "change": pct}
        if sector_stats[sector]["max_gainer"] is None or pct > sector_stats[sector]["max_gainer"]["change"]:
            sector_stats[sector]["max_gainer"] = current
        if sector_stats[sector]["max_loser"] is None or pct < sector_stats[sector]["max_loser"]["change"]:
            sector_stats[sector]["max_loser"] = current

    # Build results
    results = []
    for sector, stats in sector_stats.items():
        if stats["count"] == 0:
            continue
        avg_change = sum(stats["changes"]) / len(stats["changes"]) if stats["changes"] else 0
        results.append({
            "sector": sector,
            "count": stats["count"],
            "avg_change": avg_change,
            "up": stats["up"],
            "down": stats["down"],
            "limit_up": stats["limit_up"],
            "limit_down": stats["limit_down"],
            "gainer": stats["max_gainer"],
            "loser": stats["max_loser"],
        })

    # Sort by avg_change desc
    results.sort(key=lambda x: x["avg_change"], reverse=True)

    # è®¡ç®—æ•´ä½“æ¶¨è·Œæ¯”ä¾‹
    total_sectors = len(results)
    up_sectors = sum(1 for r in results if r["avg_change"] > 0.1)
    down_sectors = sum(1 for r in results if r["avg_change"] < -0.1)
    flat_sectors = total_sectors - up_sectors - down_sectors
    
    # Risk ON/OFF åˆ¤æ–­
    if total_sectors > 0:
        up_ratio = up_sectors / total_sectors
        if up_ratio >= 0.7:
            risk_label = "ğŸš€ Risk ON (ç§‘æŠ€ä¸»å¯¼ä¸Šæ¶¨)"
        elif up_ratio >= 0.5:
            risk_label = "ğŸŸ¢ åå¤š (å¤šæ•°èµ›é“ä¸Šæ¶¨)"
        elif up_ratio <= 0.3:
            risk_label = "ğŸ›¡ï¸ Risk OFF (ç§‘æŠ€èµ›é“æ‰¿å‹)"
        else:
            risk_label = "âš–ï¸ ä¸­æ€§åˆ†åŒ–"
    else:
        risk_label = "æ— æ•°æ®"

    lines = ["ğŸ“Š **èµ›é“æ±‡æ€»** (è‡ªé€‰è‚¡åˆ†ç»„)"]
    if not results:
        lines.append("  æ— æ•°æ®")
        return lines
    
    # å…ˆæ˜¾ç¤ºæ•´ä½“ç»Ÿè®¡
    lines.append(f"  **æ•´ä½“**: {total_sectors}èµ›é“ | ğŸŸ¢æ¶¨{up_sectors} ğŸ”´è·Œ{down_sectors} â¡ï¸å¹³{flat_sectors}")
    lines.append(f"  **åˆ¤æ–­**: {risk_label}")
    lines.append("")

    # åªæ˜¾ç¤ºTOP5æ¶¨ + TOP3è·Œï¼ˆç²¾ç®€ç‰ˆï¼‰
    top5 = results[:5]
    bot3 = [r for r in results if r["avg_change"] < 0][-3:] if len([r for r in results if r["avg_change"] < 0]) >= 3 else [r for r in results if r["avg_change"] < 0]
    
    lines.append("  **æ¶¨å¹…å‰5:**")
    for r in top5:
        emoji = "ğŸŸ¢" if r["avg_change"] >= 0 else "ğŸ”´"
        gainer_str = f"é¢†æ¶¨:{r['gainer']['name']}({r['gainer']['change']:+.1f}%)" if r['gainer'] else ""
        lines.append(f"    {emoji} {r['sector']} {r['avg_change']:+.2f}% | {gainer_str}")
    
    if bot3:
        lines.append("  **è·Œå¹…å‰3:**")
        for r in bot3[::-1]:  # å€’åºæ˜¾ç¤ºï¼ˆè·Œæœ€å¤šçš„åœ¨å‰ï¼‰
            loser_str = f"é¢†è·Œ:{r['loser']['name']}({r['loser']['change']:+.1f}%)" if r['loser'] else ""
            lines.append(f"    ğŸ”´ {r['sector']} {r['avg_change']:+.2f}% | {loser_str}")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. è‡ªé€‰è‚¡å¼‚åŠ¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("è‡ªé€‰è‚¡å¼‚åŠ¨")
def section_watchlist() -> list[str]:
    try:
        r = requests.get(f"{API_BASE}/api/watchlist/analytics", timeout=8)
        if r.status_code != 200:
            return ["ğŸ“Š **è‡ªé€‰è‚¡å¼‚åŠ¨**", "  APIè¯·æ±‚å¤±è´¥"]
        
        data = r.json()
        lines = ["ğŸ“Š **è‡ªé€‰è‚¡å¼‚åŠ¨**"]
        
        # Handle both list and dict responses
        alerts = data if isinstance(data, list) else data.get("alerts", data.get("stocks", []))
        
        if not alerts:
            return lines + ["  æš‚æ— å¼‚åŠ¨"]
        
        # Show up to 8 alerts
        for i, alert in enumerate(alerts[:8], 1):
            name = alert.get("name", "")
            code = alert.get("code", alert.get("ticker", ""))
            trigger = alert.get("trigger", alert.get("signal", ""))
            value = alert.get("value", alert.get("change_pct", 0))
            
            emoji = "ğŸ“ˆ" if trigger in ["æ¶¨åœ", "æ€¥æ‹‰"] else "ğŸ“‰" if trigger in ["è·Œåœ", "æ€¥è·Œ"] else "âš¡"
            lines.append(f"  {emoji} {name}({code}) {trigger} {value:+.2f}%")
        
        return lines
    except Exception as e:
        return ["ğŸ“Š **è‡ªé€‰è‚¡å¼‚åŠ¨**", f"  è·å–å¤±è´¥: {e}"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. èˆ†æƒ…ä¿¡å· (park-intel)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("èˆ†æƒ…ä¿¡å·")
def section_intel_signals() -> list[str]:
    """Fetch qualitative signals from park-intel and format for A-share briefing."""
    lines = ["ğŸ“¡ **èˆ†æƒ…ä¿¡å·** (park-intel)"]
    try:
        r = requests.get(
            "http://127.0.0.1:8001/api/articles/signals",
            timeout=10,
        )
        if r.status_code != 200:
            return lines + ["  park-intel è¯·æ±‚å¤±è´¥"]
        data = r.json()
    except Exception:
        return lines + ["  park-intel ä¸å¯ç”¨"]

    # Use narrative_mapping to format
    sys.path.insert(0, str(PROJECT_ROOT))
    from src.services.narrative_mapping import format_intel_section
    lines.extend(format_intel_section(data))
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 9. å¸‚åœºå¿«è®¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¸‚åœºå¿«è®¯")
def section_news() -> list[str]:
    try:
        r = requests.get(f"{API_BASE}/api/news/latest", timeout=8)
        if r.status_code != 200:
            return ["ğŸ“° **å¸‚åœºå¿«è®¯**", "  APIè¯·æ±‚å¤±è´¥"]
        
        data = r.json()
        # Handle both list and {"news": [...]} responses
        news = data if isinstance(data, list) else data.get("news", data.get("data", []))
        lines = ["ğŸ“° **å¸‚åœºå¿«è®¯**"]
        
        if not news:
            return lines + ["  æš‚æ— å¿«è®¯"]
        
        # Show latest 3 news
        for item in news[:3]:
            title = item.get("title", "")
            time_str = item.get("time", "")
            if title:
                lines.append(f"  â€¢ {time_str} {title}")
        
        return lines
    except Exception as e:
        return ["ğŸ“° **å¸‚åœºå¿«è®¯**", f"  è·å–å¤±è´¥: {e}"]


def main():
    """ä¸»å‡½æ•°"""
    # â”€â”€ Data Gathering â”€â”€
    index_data = fetch_indices()
    flow_lines, flow_df = section_flow_top20()
    alert_data = None
    try:
        r = requests.get(f"{API_BASE}/api/anomaly/alerts", timeout=20)
        if r.status_code == 200:
            alert_data = r.json()
    except Exception:
        pass

    # â”€â”€ Build Output â”€â”€
    output_lines = [
        f"ğŸ”¥ **Aè‚¡å¸‚åœºç®€æŠ¥** | {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
    ]

    # â”€â”€ 1. Aè‚¡æŒ‡æ•° â”€â”€
    output_lines.extend(section_indices(index_data))
    output_lines.append("")

    # â”€â”€ 2. å¸‚åœºå¼‚åŠ¨ â”€â”€
    output_lines.extend(section_alerts())
    output_lines.append("")

    # â”€â”€ 3. ç›˜ä¸­è·¯å¾„ â”€â”€
    output_lines.extend(section_intraday_table())
    output_lines.append("")

    # â”€â”€ 4. FLOW-TOP20 â”€â”€
    output_lines.extend(flow_lines)
    output_lines.append("")

    # â”€â”€ 5. Wendyåˆ†æ â”€â”€
    output_lines.extend(section_analysis(index_data, flow_df, alert_data))
    output_lines.append("")

    # â”€â”€ 6. è‡ªé€‰è‚¡èµ›é“æ±‡æ€» â”€â”€
    output_lines.extend(section_stock_sectors())
    output_lines.append("")

    # â”€â”€ 7. è‡ªé€‰è‚¡å¼‚åŠ¨ â”€â”€
    output_lines.extend(section_watchlist())
    output_lines.append("")

    # â”€â”€ 8. èˆ†æƒ…ä¿¡å· â”€â”€
    output_lines.extend(section_intel_signals())
    output_lines.append("")

    # â”€â”€ 9. å¿«è®¯ â”€â”€
    output_lines.extend(section_news())

    output_lines.append("")
    output_lines.append(f"{'â•' * 50}")
    output_lines.append(f"â± ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')} | æ•°æ®ä»…ä¾›å‚è€ƒ")

    full_text = "\n".join(output_lines)
    print(full_text)

    # â”€â”€ Auto-push to Notion â”€â”€
    try:
        from scripts.push_to_notion import push_briefing_to_notion
        push_briefing_to_notion(full_text)
    except Exception:
        try:
            from push_to_notion import push_briefing_to_notion
            push_briefing_to_notion(full_text)
        except Exception as e:
            print(f"\nâš ï¸ Notionæ¨é€å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}", file=sys.stderr)


if __name__ == "__main__":
    main()