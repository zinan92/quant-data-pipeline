#!/usr/bin/env python3
"""
ç¾è‚¡å®Œæ•´ç®€æŠ¥ v4 â€” å¢å¼ºç‰ˆï¼ˆå‚è€ƒAè‚¡ç®€æŠ¥æ ¼å¼ï¼‰
=============================================
ç”¨æ³•: python scripts/us_briefing_enhanced.py [--time]

æ¨¡å—:
1. ä¸‰å¤§æŒ‡æ•° + VIX         â€” è¯¦ç»†è¡Œæƒ…æ•°æ®
2. å¼‚åŠ¨ç»Ÿè®¡              â€” æ¶¨è·Œå¹…æ¦œã€æˆäº¤é‡å¼‚å¸¸
3. ç›˜ä¸­å…¨ç¨‹å›é¡¾è¡¨æ ¼       â€” æŒ‡æ•°å¿«ç…§å†å²è·Ÿè¸ª
4. æ¿å—èµ„é‡‘æµTOP20       â€” æ¿å—ETFèµ„é‡‘æµæ’è¡Œ
5. Mag7 + ç§‘æŠ€é‡ç‚¹è‚¡     â€” ç§‘æŠ€ä¸ƒå·¨å¤´è¯¦ç»†åˆ†æ
6. ä¸­æ¦‚è‚¡/å›½é™…è‚¡         â€” ADR + å›½é™…å¸‚åœº
7. å•†å“æœŸè´§å…¨æ™¯          â€” è´µé‡‘å±/èƒ½æº/å†œäº§å“
8. å€ºåˆ¸/åˆ©ç‡æ›²çº¿         â€” æ”¶ç›Šç‡æ›²çº¿åˆ†æ
9. å¤–æ±‡/è´§å¸ä¿¡å·         â€” ç¾å…ƒæŒ‡æ•°+ä¸»è¦è´§å¸å¯¹
10. ğŸ§  Morningåˆ†æ        â€” è§„åˆ™å¼•æ“ï¼Œç»¼åˆä¿¡å·
11. é‡ç‚¹è‡ªé€‰è‚¡å¼‚åŠ¨        â€” è‡ªå®šä¹‰å…³æ³¨è‚¡ç¥¨
12. é‡è¦å¿«è®¯             â€” å®æ—¶æ–°é—»
13. ğŸ“ ç›˜åæ€»ç»“          â€” å¸‚åœºå›é¡¾å’Œæ˜æ—¥å±•æœ›

æ•°æ®æº: ashare API http://127.0.0.1:8000
"""

import sys
import json
import time
import argparse
import requests
from datetime import datetime, timedelta
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed


# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROJECT_ROOT = Path(__file__).parent.parent
SNAPSHOT_FILE = PROJECT_ROOT / "data" / "snapshots" / "us_stocks" / "today_us_snapshots.json"
SNAPSHOT_FILE.parent.mkdir(parents=True, exist_ok=True)

API_BASE = "http://127.0.0.1:8000"
REQUEST_TIMEOUT = 5

# ç¾è‚¡é‡ç‚¹å…³æ³¨è‚¡ç¥¨ (å¯è‡ªå®šä¹‰)
US_WATCHLIST = [
    ("AAPL", "è‹¹æœ"),
    ("MSFT", "å¾®è½¯"), 
    ("GOOGL", "è°·æ­Œ"),
    ("AMZN", "äºšé©¬é€Š"),
    ("TSLA", "ç‰¹æ–¯æ‹‰"),
    ("NVDA", "è‹±ä¼Ÿè¾¾"),
    ("META", "Meta"),
    ("NFLX", "å¥ˆé£"),
    ("AMD", "AMD"),
    ("INTC", "è‹±ç‰¹å°”"),
    ("CRM", "Salesforce"),
    ("ORCL", "ç”²éª¨æ–‡"),
    ("BABA", "é˜¿é‡Œå·´å·´"),
    ("PDD", "æ‹¼å¤šå¤š"),
    ("JD", "äº¬ä¸œ"),
    ("NIO", "è”šæ¥"),
    ("XPEV", "å°é¹"),
    ("LI", "ç†æƒ³"),
    ("BIDU", "ç™¾åº¦"),
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Helper functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def fetch(endpoint: str) -> dict:
    """Fetch JSON from API. Returns {} on failure."""
    try:
        r = requests.get(f"{API_BASE}{endpoint}", timeout=(2, REQUEST_TIMEOUT))
        return r.json() if r.ok else {}
    except Exception:
        return {}


def safe_section(name: str):
    """Decorator: if a section fails, print error and continue."""
    def decorator(fn):
        def wrapper(*args, **kwargs):
            try:
                return fn(*args, **kwargs)
            except Exception as e:
                return [f"âš ï¸ [{name}] è·å–å¤±è´¥: {e}"]
        return wrapper
    return decorator


def pct_icon(pct: float) -> str:
    """Return colored icon for percentage change."""
    return "ğŸŸ¢" if pct >= 0 else "ğŸ”´"


def format_price(price: float, decimals: int = 2) -> str:
    """Format price with comma separator."""
    if price >= 1000:
        return f"{price:,.{decimals}f}"
    return f"{price:.{decimals}f}"


def format_volume(vol: float) -> str:
    """Format volume to human-readable."""
    if vol >= 1e9:
        return f"{vol / 1e9:.1f}B"
    elif vol >= 1e6:
        return f"{vol / 1e6:.0f}M"
    elif vol >= 1e3:
        return f"{vol / 1e3:.0f}K"
    return f"{vol:.0f}"


def format_market_cap(cap: float) -> str:
    """Format market cap to human-readable."""
    if cap >= 1e12:
        return f"{cap / 1e12:.2f}T"
    elif cap >= 1e9:
        return f"{cap / 1e9:.1f}B"
    elif cap >= 1e6:
        return f"{cap / 1e6:.0f}M"
    return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 0. Save index snapshot (runs every time)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def save_us_index_snapshot(index_data: dict):
    """Save current US index data as a snapshot point."""
    try:
        if SNAPSHOT_FILE.exists():
            snapshots = json.loads(SNAPSHOT_FILE.read_text())
            if snapshots.get("date") != datetime.now().strftime("%Y-%m-%d"):
                snapshots = {"date": datetime.now().strftime("%Y-%m-%d"), "snapshots": []}
        else:
            snapshots = {"date": datetime.now().strftime("%Y-%m-%d"), "snapshots": []}

        now_time = datetime.now().strftime("%H:%M")
        # Avoid duplicate timestamps
        existing_times = {s["time"] for s in snapshots["snapshots"]}
        if now_time in existing_times:
            return

        snapshot_entry = {"time": now_time, "indexes": {}}
        
        quotes = index_data.get("quotes", [])
        for q in quotes:
            symbol = q["symbol"]
            snapshot_entry["indexes"][symbol] = {
                "name": q.get("cn_name") or q["name"],
                "price": q["price"],
                "pct": q["change_pct"],
                "volume": q.get("volume", 0),
            }

        snapshots["snapshots"].append(snapshot_entry)
        SNAPSHOT_FILE.write_text(json.dumps(snapshots, ensure_ascii=False, indent=2))
    except Exception:
        pass  # Non-critical


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ä¸‰å¤§æŒ‡æ•° + VIX ï¼ˆå¢å¼ºç‰ˆï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ä¸‰å¤§æŒ‡æ•°")
def section_indexes(data: dict) -> list[str]:
    lines = ["ğŸ“ˆ **ä¸‰å¤§æŒ‡æ•° + VIX**"]
    quotes = data.get("quotes", [])
    if not quotes:
        return lines + ["  æ•°æ®æš‚æ— "]

    # Separate VIX from main indexes
    main_indexes = []
    vix = None
    for q in quotes:
        if q["symbol"] == "^VIX":
            vix = q
        else:
            main_indexes.append(q)

    # Main indexes with detailed info
    for q in main_indexes:
        icon = pct_icon(q["change_pct"])
        name = q.get("cn_name") or q["name"]
        price = format_price(q["price"])
        change = q.get("change", 0)
        vol = q.get("volume", 0)
        
        vol_str = f" æˆäº¤:{format_volume(vol)}" if vol > 0 else ""
        high = q.get("day_high", 0)
        low = q.get("day_low", 0)
        range_str = ""
        if high > 0 and low > 0:
            range_str = f" æ—¥å†…:{format_price(low)}-{format_price(high)}"
        
        lines.append(
            f"  {icon} {name}: {price} ({q['change_pct']:+.2f}%/"
            f"{change:+.2f}){vol_str}{range_str}"
        )

    # VIX with detailed interpretation
    if vix:
        vix_level = vix["price"]
        if vix_level >= 35:
            vix_emoji, vix_status = "ğŸ”´ğŸ”´", "æåº¦ææ…Œ"
        elif vix_level >= 30:
            vix_emoji, vix_status = "ğŸ”´", "ä¸¥é‡ææ…Œ"
        elif vix_level >= 25:
            vix_emoji, vix_status = "ğŸŸ ", "é«˜åº¦ææ…Œ"
        elif vix_level >= 20:
            vix_emoji, vix_status = "ğŸŸ¡", "è­¦æƒ•"
        elif vix_level >= 15:
            vix_emoji, vix_status = "âš–ï¸", "æ­£å¸¸"
        else:
            vix_emoji, vix_status = "ğŸŸ¢", "ä½æ³¢åŠ¨"
        
        lines.append(
            f"  {vix_emoji} VIXææ…ŒæŒ‡æ•°: {vix_level:.2f} ({vix['change_pct']:+.2f}%) "
            f"â€” {vix_status}"
        )

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. å¼‚åŠ¨ç»Ÿè®¡ï¼ˆæ–°å¢ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¼‚åŠ¨ç»Ÿè®¡")
def section_market_movers() -> list[str]:
    """Get market movers - biggest gainers/losers by volume."""
    lines = ["âš¡ **å¼‚åŠ¨ç»Ÿè®¡**"]
    
    # This would require additional API endpoints for US market movers
    # For now, we'll use sector data as proxy
    sector_data = fetch("/api/us-stock/sectors")
    sectors = sector_data.get("sectors", [])
    
    if not sectors:
        return lines + ["  æ•°æ®æš‚æ— "]
    
    etf_sectors = []
    for s in sectors:
        if s.get("etf"):
            etf_sectors.append({
                "name": s["name_cn"],
                "symbol": s["etf"]["symbol"],
                "pct": s["etf"]["change_pct"],
                "volume": s["etf"].get("volume", 0),
            })
    
    if not etf_sectors:
        return lines + ["  ETFæ•°æ®æš‚æ— "]
    
    # Sort by performance
    sorted_sectors = sorted(etf_sectors, key=lambda x: x["pct"], reverse=True)
    
    # Gainers and losers
    top_gainers = sorted_sectors[:3]
    top_losers = sorted_sectors[-3:]
    
    gainer_names = [f"{s['name']}({s['pct']:+.1f}%)" for s in top_gainers]
    loser_names = [f"{s['name']}({s['pct']:+.1f}%)" for s in top_losers]
    
    lines.append(f"  ğŸŸ¢ é¢†æ¶¨æ¿å—: {' | '.join(gainer_names)}")
    lines.append(f"  ğŸ”´ é¢†è·Œæ¿å—: {' | '.join(loser_names)}")
    
    # Breadth analysis
    up_count = sum(1 for s in etf_sectors if s["pct"] > 0)
    down_count = sum(1 for s in etf_sectors if s["pct"] < 0)
    flat_count = len(etf_sectors) - up_count - down_count
    
    lines.append(f"  ğŸ“Š æ¿å—å¹¿åº¦: {up_count}æ¶¨ / {down_count}è·Œ / {flat_count}å¹³")
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ç›˜ä¸­å…¨ç¨‹å›é¡¾è¡¨æ ¼ï¼ˆå‚è€ƒAè‚¡æ ¼å¼ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ç›˜ä¸­å›é¡¾")
def section_intraday_table() -> list[str]:
    if not SNAPSHOT_FILE.exists():
        return ["ğŸ“‹ **ç›˜ä¸­å…¨ç¨‹å›é¡¾**", "  æš‚æ— å¿«ç…§æ•°æ®"]

    data = json.loads(SNAPSHOT_FILE.read_text())
    snapshots = data.get("snapshots", [])
    if not snapshots:
        return ["ğŸ“‹ **ç›˜ä¸­å…¨ç¨‹å›é¡¾**", "  æš‚æ— å¿«ç…§æ•°æ®"]

    lines = [f"ğŸ“‹ **ç›˜ä¸­å…¨ç¨‹å›é¡¾** ({data.get('date', 'ä»Šæ—¥')})"]

    # Track highs/lows per index
    idx_tracker = {}
    
    # Table header
    lines.append(f"{'æ—¶é—´':>6} | {'æ ‡æ™®500':>12} | {'çº³æ–¯è¾¾å…‹':>12} | {'é“ç¼æ–¯':>12}")
    lines.append(f"{'â”€'*6} | {'â”€'*12} | {'â”€'*12} | {'â”€'*12}")

    for snap in snapshots:
        t = snap["time"]
        indexes = snap.get("indexes", {})

        cols = [f"{t:>6}"]
        for symbol in ["^GSPC", "^IXIC", "^DJI"]:
            idx = indexes.get(symbol, {})
            price = idx.get("price", 0)
            pct = idx.get("pct", 0)

            if price > 0:
                sign = "+" if pct >= 0 else ""
                col_str = f"{price:.0f}({sign}{pct:.2f}%)"

                # Track high/low
                if symbol not in idx_tracker:
                    idx_tracker[symbol] = {
                        "name": idx.get("name", symbol),
                        "high_price": price, "high_time": t, "high_pct": pct,
                        "low_price": price, "low_time": t, "low_pct": pct,
                    }
                else:
                    tr = idx_tracker[symbol]
                    if price > tr["high_price"]:
                        tr["high_price"] = price
                        tr["high_time"] = t
                        tr["high_pct"] = pct
                    if price < tr["low_price"]:
                        tr["low_price"] = price
                        tr["low_time"] = t
                        tr["low_pct"] = pct
            else:
                col_str = "â€”"

            cols.append(f"{col_str:>12}")
        
        lines.append(" | ".join(cols))

    # High/Low summary
    if idx_tracker:
        lines.append("")
        lines.append("ğŸ“ **é«˜ä½ç‚¹:**")
        for symbol in ["^GSPC", "^IXIC", "^DJI"]:
            if symbol in idx_tracker:
                tr = idx_tracker[symbol]
                lines.append(
                    f"  {tr['name']}: "
                    f"é«˜ç‚¹ {tr['high_price']:.0f}({tr['high_pct']:+.2f}%) @{tr['high_time']} | "
                    f"ä½ç‚¹ {tr['low_price']:.0f}({tr['low_pct']:+.2f}%) @{tr['low_time']}"
                )

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. æ¿å—èµ„é‡‘æµTOP20ï¼ˆå¢å¼ºç‰ˆï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("æ¿å—èµ„é‡‘æµ")
def section_sector_flow(data: dict) -> tuple[list[str], list]:
    lines = ["ğŸ’° **æ¿å—ETFèµ„é‡‘æµTOP20**"]
    sectors = data.get("sectors", [])
    
    if not sectors:
        return lines + ["  æ•°æ®æš‚æ— "], []
    
    # Extract ETF data
    etf_data = []
    for s in sectors:
        if s.get("etf"):
            etf = s["etf"]
            etf_data.append({
                "name": s["name_cn"],
                "symbol": etf["symbol"],
                "pct": etf["change_pct"],
                "price": etf["price"],
                "volume": etf.get("volume", 0),
                "market_cap": etf.get("market_cap", 0),
                "avg_volume": etf.get("avg_volume", 0),
            })
    
    if not etf_data:
        return lines + ["  ETFæ•°æ®æš‚æ— "], []
    
    # Sort by performance (proxy for flow)
    sorted_etfs = sorted(etf_data, key=lambda x: x["pct"], reverse=True)
    
    total = len(sorted_etfs)
    net_up = sum(1 for e in sorted_etfs if e["pct"] > 0)
    net_down = total - net_up
    
    lines.append(f"å…±{total}ä¸ªæ¿å—ETF | {net_up}ä¸ªä¸Šæ¶¨ | {net_down}ä¸ªä¸‹è·Œ")
    lines.append("")
    
    # Top performers
    for i, etf in enumerate(sorted_etfs[:15], 1):
        icon = pct_icon(etf["pct"])
        vol_ratio = ""
        if etf["avg_volume"] > 0 and etf["volume"] > 0:
            ratio = etf["volume"] / etf["avg_volume"]
            if ratio > 2:
                vol_ratio = f" ğŸ”¥{ratio:.1f}xé‡"
            elif ratio > 1.5:
                vol_ratio = f" ğŸ“ˆ{ratio:.1f}xé‡"
        
        lines.append(
            f"  {i:>2}. {etf['name']}({etf['symbol']}) {etf['pct']:+.2f}% "
            f"${format_price(etf['price'])} {format_volume(etf['volume'])}{vol_ratio}"
        )
    
    # Bottom performers
    if len(sorted_etfs) > 15:
        lines.append("")
        lines.append("  ğŸ“‰ **é¢†è·Œæ¿å—:**")
        bottom_5 = sorted_etfs[-5:]
        for etf in bottom_5:
            icon = pct_icon(etf["pct"])
            lines.append(
                f"  {icon} {etf['name']}({etf['symbol']}) {etf['pct']:+.2f}%"
            )
    
    return lines, sorted_etfs


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. Mag7 + ç§‘æŠ€é‡ç‚¹è‚¡ï¼ˆå¢å¼ºç‰ˆï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ç§‘æŠ€é‡ç‚¹è‚¡")
def section_tech_detailed(mag7_data: dict) -> tuple[list[str], dict]:
    lines = ["ğŸ’ **Mag7 + ç§‘æŠ€é‡ç‚¹è‚¡**"]
    quotes = mag7_data.get("quotes", [])
    if not quotes:
        return lines + ["  æ•°æ®æš‚æ— "], {}

    # Sort by performance  
    sorted_quotes = sorted(quotes, key=lambda q: q["change_pct"], reverse=True)
    
    # Calculate metrics
    avg_pct = sum(q["change_pct"] for q in sorted_quotes) / len(sorted_quotes)
    total_cap = sum(q.get("market_cap", 0) for q in sorted_quotes)
    up_count = sum(1 for q in sorted_quotes if q["change_pct"] > 0)
    down_count = len(sorted_quotes) - up_count
    
    lines.append(f"Mag7çŠ¶æ€: {up_count}æ¶¨/{down_count}è·Œ | å¹³å‡æ¶¨å¹…: {avg_pct:+.2f}%")
    lines.append(f"æ€»å¸‚å€¼: {format_market_cap(total_cap)}")
    lines.append("")
    
    # Detailed breakdown
    for q in sorted_quotes:
        icon = pct_icon(q["change_pct"])
        name = q.get("cn_name") or q["symbol"]
        cap_str = format_market_cap(q.get("market_cap", 0))
        vol_str = format_volume(q.get("volume", 0))
        
        # P/E ratio if available
        pe_str = ""
        if q.get("pe_ratio"):
            pe_str = f" PE:{q['pe_ratio']:.1f}"
        
        lines.append(
            f"  {icon} {name}({q['symbol']}): ${format_price(q['price'])} "
            f"({q['change_pct']:+.2f}%) [{cap_str}] é‡:{vol_str}{pe_str}"
        )
    
    # Performance analysis
    lines.append("")
    best = sorted_quotes[0]
    worst = sorted_quotes[-1]
    spread = best["change_pct"] - worst["change_pct"]
    
    if spread > 5:
        lines.append(f"âš ï¸ åˆ†åŒ–ä¸¥é‡: {best.get('cn_name', best['symbol'])} vs {worst.get('cn_name', worst['symbol'])} å·®è·{spread:.1f}%")
    elif avg_pct > 1:
        lines.append("ğŸŸ¢ ç§‘æŠ€è‚¡æ•´ä½“å¼ºåŠ¿ï¼Œå¸‚åœºé£é™©åå¥½é«˜")
    elif avg_pct < -1:
        lines.append("ğŸ”´ ç§‘æŠ€è‚¡æ•´ä½“ç–²å¼±ï¼Œæˆé•¿è‚¡æ‰¿å‹")
    else:
        lines.append("âš–ï¸ ç§‘æŠ€è‚¡è¡¨ç°ä¸­æ€§")
    
    signal_data = {
        "avg_pct": avg_pct,
        "up_count": up_count,
        "down_count": down_count,
        "spread": spread,
        "total_cap": total_cap,
    }
    
    return lines, signal_data


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 10. Morningåˆ†æï¼ˆç»¼åˆè§„åˆ™å¼•æ“ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("Morningåˆ†æ")
def section_morning_analysis(
    index_data: dict,
    sector_data: list,
    tech_data: dict,
    commodity_data: dict,
    bond_data: dict,
    forex_data: dict,
) -> tuple[list[str], dict]:
    """Comprehensive rule-based analysis following A-share format."""
    lines = ["ğŸ§  **Morningåˆ†æ**"]
    
    # Extract key metrics
    quotes = index_data.get("quotes", [])
    quote_map = {q["symbol"]: q for q in quotes}
    
    sp500 = quote_map.get("^GSPC", {})
    nasdaq = quote_map.get("^IXIC", {})
    dow = quote_map.get("^DJI", {})
    vix_q = quote_map.get("^VIX", {})
    
    sp_pct = sp500.get("change_pct", 0)
    nas_pct = nasdaq.get("change_pct", 0)
    dow_pct = dow.get("change_pct", 0)
    vix_level = vix_q.get("price", 0)
    
    # â”€â”€ å¸‚åœºå®šæ€§ â”€â”€
    lines.append("")
    lines.append("**å¸‚åœºå®šæ€§:**")
    
    # Style rotation: Value vs Growth (Dow vs Nasdaq)
    style_scissor = dow_pct - nas_pct
    if style_scissor > 1.0:
        market_tone = "âš ï¸ Value > Growth (é“æŒ‡å¼ºã€çº³æŒ‡å¼±) â†’ Risk OFFæ¨¡å¼"
    elif style_scissor < -1.0:
        market_tone = "ğŸš€ Growth > Value (çº³æŒ‡å¼ºã€é“æŒ‡å¼±) â†’ Risk ONæ¨¡å¼"
    elif sp_pct > 0.5 and nas_pct > 0.5:
        market_tone = "ğŸŸ¢ æ™®æ¶¨è¡Œæƒ…ï¼ˆæŒ‡æ•°é½å‡ï¼‰"
    elif sp_pct < -0.5 and nas_pct < -0.5:
        market_tone = "ğŸ”´ æ™®è·Œè¡Œæƒ…ï¼ˆæŒ‡æ•°é½è·Œï¼‰"
    else:
        market_tone = "âš–ï¸ ä¸­æ€§éœ‡è¡"
    
    lines.append(f"  {market_tone}")
    lines.append(f"  é“æŒ‡ {dow_pct:+.2f}% vs çº³æŒ‡ {nas_pct:+.2f}% â†’ é£æ ¼å‰ªåˆ€å·® {style_scissor:+.2f}%")
    
    # VIX fear gauge
    if vix_level > 0:
        if vix_level >= 30:
            vix_signal = "ğŸ”´ VIXæåº¦ææ…ŒåŒºï¼ˆâ‰¥30ï¼‰ï¼Œå¸‚åœºå‰§çƒˆæ³¢åŠ¨"
        elif vix_level >= 20:
            vix_signal = "ğŸŸ¡ VIXè­¦æˆ’åŒºï¼ˆ20-30ï¼‰ï¼ŒæŠ•èµ„è€…ç´§å¼ "
        else:
            vix_signal = "ğŸŸ¢ VIXèˆ’é€‚åŒºï¼ˆ<20ï¼‰ï¼Œå¸‚åœºç›¸å¯¹å¹³é™"
        lines.append(f"  {vix_signal}")
    
    # â”€â”€ æ¿å—è½®åŠ¨ â”€â”€
    lines.append("")
    lines.append("**æ¿å—è½®åŠ¨:**")
    if sector_data:
        top3_up = sector_data[:3]
        top3_down = sector_data[-3:]
        
        up_names = " / ".join([f"{s['name']}({s['pct']:+.1f}%)" for s in top3_up])
        down_names = " / ".join([f"{s['name']}({s['pct']:+.1f}%)" for s in top3_down])
        
        lines.append(f"  ğŸ”º ä¸»åŠ›æµå…¥: {up_names}")
        lines.append(f"  ğŸ”» ä¸»åŠ›æµå‡º: {down_names}")
        
        # Sector breadth
        up_sectors = sum(1 for s in sector_data if s["pct"] > 0)
        total_sectors = len(sector_data)
        breadth_pct = up_sectors / total_sectors * 100 if total_sectors > 0 else 0
        lines.append(f"  ğŸ“Š æ¿å—å¹¿åº¦: {up_sectors}/{total_sectors} ({breadth_pct:.0f}%ä¸Šæ¶¨)")
    else:
        lines.append("  æ•°æ®æš‚æ— ")
    
    # â”€â”€ å…³é”®ä¿¡å· â”€â”€
    lines.append("")
    lines.append("**å…³é”®ä¿¡å·:**")
    
    # Signal 1: VIX vs Market direction
    if vix_level > 0:
        vix_direction = vix_q.get("change_pct", 0)
        if vix_direction > 5 and sp_pct < 0:
            lines.append(f"  â€¢ VIXé£™å‡+å¸‚åœºä¸‹è·Œ â†’ ææ…Œæ€§æŠ›å”®")
        elif vix_direction < -5 and sp_pct > 0:
            lines.append(f"  â€¢ VIXå›è½+å¸‚åœºä¸Šæ¶¨ â†’ é£é™©åå¥½å›å‡")
        else:
            lines.append(f"  â€¢ VIX {vix_level:.1f} ({vix_direction:+.1f}%) vs æ ‡æ™® {sp_pct:+.2f}%")
    
    # Signal 2: Tech leadership
    if tech_data:
        mag7_avg = tech_data.get("avg_pct", 0)
        mag7_spread = tech_data.get("spread", 0)
        if mag7_spread > 5:
            lines.append(f"  â€¢ Mag7åˆ†åŒ–ä¸¥é‡ï¼ˆä»·å·®{mag7_spread:.1f}%ï¼‰â†’ ä¸ªè‚¡é©±åŠ¨")
        elif mag7_avg > sp_pct + 1:
            lines.append(f"  â€¢ ç§‘æŠ€è‚¡è·‘èµ¢å¤§ç›˜{mag7_avg - sp_pct:.1f}% â†’ æˆé•¿ä¸»å¯¼")
        elif mag7_avg < sp_pct - 1:
            lines.append(f"  â€¢ ç§‘æŠ€è‚¡è·‘è¾“å¤§ç›˜{sp_pct - mag7_avg:.1f}% â†’ æƒé‡æ‹–ç´¯")
    
    # â”€â”€ ğŸ›¡ï¸ é¿é™©æŒ‡æ ‡ â”€â”€
    lines.append("")
    lines.append("**ğŸ›¡ï¸ é¿é™©æŒ‡æ ‡:**")
    
    # Get commodity data
    commodities = commodity_data.get("commodities", [])
    commodity_map = {c["symbol"]: c for c in commodities}
    gold = commodity_map.get("GC=F")
    treasury = None
    
    # Get bond data
    bonds = bond_data.get("bonds", [])
    bond_map = {b["symbol"]: b for b in bonds}
    tnx = bond_map.get("^TNX")  # 10Y Treasury
    
    # Get USD data
    forex = forex_data.get("forex", [])
    fx_map = {f["symbol"]: f for f in forex}
    dxy = fx_map.get("DX-Y.NYB")  # Dollar Index
    
    safe_haven_signals = []
    safe_haven_count = 0
    
    # Gold signal
    if gold:
        gold_pct = gold.get("change_pct", 0)
        if gold_pct > 1.5:
            safe_haven_signals.append(f"ğŸŸ¢é»„é‡‘ {gold_pct:+.1f}% (é¿é™©ä¹°å…¥)")
            safe_haven_count += 1
        elif gold_pct < -1.5:
            safe_haven_signals.append(f"ğŸ”´é»„é‡‘ {gold_pct:+.1f}% (é£é™©åå¥½)")
        else:
            safe_haven_signals.append(f"âš–ï¸é»„é‡‘ {gold_pct:+.1f}% (ä¸­æ€§)")
    
    # Treasury signal (inverse of yield)
    if tnx:
        yield_pct = tnx.get("change_pct", 0)
        if yield_pct < -2:  # Yield down = bond up = safe haven
            safe_haven_signals.append(f"ğŸŸ¢ç¾å€º (æ”¶ç›Šç‡{yield_pct:+.1f}%ï¼Œå€ºåˆ¸ä¸Šæ¶¨)")
            safe_haven_count += 1
        elif yield_pct > 2:   # Yield up = bond down = risk on
            safe_haven_signals.append(f"ğŸ”´ç¾å€º (æ”¶ç›Šç‡{yield_pct:+.1f}%ï¼Œå€ºåˆ¸ä¸‹è·Œ)")
        else:
            safe_haven_signals.append(f"âš–ï¸ç¾å€º (æ”¶ç›Šç‡{yield_pct:+.1f}%)")
    
    # USD signal
    if dxy:
        usd_pct = dxy.get("change_pct", 0)
        if usd_pct > 0.5:
            safe_haven_signals.append(f"ğŸŸ¢ç¾å…ƒ {usd_pct:+.1f}% (é¿é™©èµ„é‡‘)")
            safe_haven_count += 1
        elif usd_pct < -0.5:
            safe_haven_signals.append(f"ğŸ”´ç¾å…ƒ {usd_pct:+.1f}% (é£é™©åå¥½)")
        else:
            safe_haven_signals.append(f"âš–ï¸ç¾å…ƒ {usd_pct:+.1f}% (ä¸­æ€§)")
    
    lines.append(f"  {' | '.join(safe_haven_signals)}")
    
    if safe_haven_count >= 2:
        lines.append(f"  âš ï¸ {safe_haven_count}/3é¿é™©èµ„äº§åŒæ—¶ä¸Šæ¶¨ â†’ **é£é™©è§„é¿æƒ…ç»ªæµ“åš**")
    elif safe_haven_count == 0:
        lines.append(f"  ğŸŸ¢ é¿é™©èµ„äº§æœªè§æµå…¥ â†’ å¸‚åœºé£é™©åå¥½è‰¯å¥½")
    else:
        lines.append(f"  ğŸ“Š é¿é™©ä¿¡å·ä¸­æ€§ï¼ˆ{safe_haven_count}/3ï¼‰")
    
    # â”€â”€ ğŸ“ è¶‹åŠ¿å¼ºåº¦ â”€â”€
    lines.append("")
    lines.append("**ğŸ“ è¶‹åŠ¿å¼ºåº¦:**")
    
    if sector_data and len(sector_data) > 0:
        top1_sector = sector_data[0]
        top1_pct = abs(top1_sector["pct"])
        top1_name = top1_sector["name"]
        
        if top1_pct >= 3:
            trend_strength = "ğŸ”¥ å¼ºè¶‹åŠ¿"
            trend_desc = "æ¿å—åˆ†åŒ–æ˜æ˜¾ï¼Œä¸»çº¿æ¸…æ™°"
        elif top1_pct >= 1.5:
            trend_strength = "ğŸ“Š ä¸­ç­‰è¶‹åŠ¿"
            trend_desc = "æœ‰æ–¹å‘ä½†åŠ›åº¦ä¸€èˆ¬"
        else:
            trend_strength = "ğŸ˜¶ å¼±è¶‹åŠ¿"
            trend_desc = "æ¿å—è½®åŠ¨ä¸æ˜æ˜¾"
        
        lines.append(f"  é¢†æ¶¨æ¿å— {top1_name}: {top1_sector['pct']:+.2f}% â†’ {trend_strength}ï¼ˆ{trend_desc}ï¼‰")
    
    # â”€â”€ æ“ä½œå»ºè®® â”€â”€
    lines.append("")
    lines.append("**æ“ä½œå»ºè®®:**")
    
    # Scoring system
    bullish_signals = 0
    bearish_signals = 0
    
    # Index signals
    if sp_pct > 0.3: bullish_signals += 1
    if sp_pct < -0.3: bearish_signals += 1
    if nas_pct > 0.3: bullish_signals += 1
    if nas_pct < -0.3: bearish_signals += 1
    
    # VIX signals
    if vix_level > 0:
        if vix_level < 15: bullish_signals += 1
        elif vix_level >= 25: bearish_signals += 2
        elif vix_level >= 20: bearish_signals += 1
    
    # Tech signals
    if tech_data:
        mag7_avg = tech_data.get("avg_pct", 0)
        if mag7_avg > 1: bullish_signals += 1
        elif mag7_avg < -1: bearish_signals += 1
    
    # Safe haven signals
    if safe_haven_count >= 2: bearish_signals += 1
    elif safe_haven_count == 0: bullish_signals += 1
    
    # Sector breadth
    if sector_data:
        up_ratio = sum(1 for s in sector_data if s["pct"] > 0) / len(sector_data)
        if up_ratio > 0.7: bullish_signals += 1
        elif up_ratio < 0.3: bearish_signals += 1
    
    # Generate advice
    if bullish_signals >= 4:
        advice = "âœ… å¤šå¤´å ä¼˜ï¼Œå¯ç§¯æå‚ä¸å¼ºåŠ¿æ¿å—ï¼Œå…³æ³¨ç§‘æŠ€å’Œæˆé•¿è‚¡"
    elif bearish_signals >= 4:
        advice = "ğŸ›‘ ç©ºå¤´å ä¼˜ï¼Œå»ºè®®å‡ä»“è§‚æœ›ï¼Œå…³æ³¨é˜²å¾¡æ€§æ¿å—"
    elif bullish_signals >= 3 and bearish_signals <= 1:
        advice = "ğŸŸ¢ åå¤šæ ¼å±€ï¼Œå¯é€‚å½“å‚ä¸é¢†æ¶¨æ¿å—ï¼Œæ§åˆ¶é£é™©"
    elif bearish_signals >= 3 and bullish_signals <= 1:
        advice = "ğŸŸ¡ åå¼±æ ¼å±€ï¼Œè½»ä»“ä¸ºä¸»ï¼Œå…³æ³¨é¿é™©èµ„äº§"
    elif abs(style_scissor) > 1.5:
        advice = "ğŸ”„ é£æ ¼è½®åŠ¨å‰§çƒˆï¼Œç²¾é€‰ä¸ªè‚¡ï¼Œå¿«è¿›å¿«å‡º"
    else:
        advice = "âš–ï¸ éœ‡è¡æ ¼å±€ï¼Œä¿æŒçµæ´»ï¼Œç­‰å¾…æ–¹å‘æ˜ç¡®"
    
    lines.append(f"  {advice}")
    lines.append(f"  (å¤šå¤´ä¿¡å·: {bullish_signals} | ç©ºå¤´ä¿¡å·: {bearish_signals})")
    
    # Collect signal data
    signal_data = {
        "sp_pct": sp_pct,
        "nas_pct": nas_pct,
        "dow_pct": dow_pct,
        "vix_level": vix_level,
        "style_scissor": style_scissor,
        "market_tone": market_tone,
        "safe_haven_count": safe_haven_count,
        "trend_strength": trend_strength if 'trend_strength' in locals() else "æœªçŸ¥",
        "bullish_signals": bullish_signals,
        "bearish_signals": bearish_signals,
        "advice": advice,
    }
    
    return lines, signal_data


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 11. é‡ç‚¹è‡ªé€‰è‚¡å¼‚åŠ¨ï¼ˆæ–°å¢ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("è‡ªé€‰è‚¡å¼‚åŠ¨")
def section_us_watchlist() -> list[str]:
    lines = ["â­ **é‡ç‚¹è‡ªé€‰è‚¡å¼‚åŠ¨**"]
    
    # This would require implementing a US stock quote API
    # For now, we'll use a placeholder
    lines.append("  åŠŸèƒ½å¼€å‘ä¸­ï¼Œéœ€è¦å®ç°ç¾è‚¡å®æ—¶è¡Œæƒ…API")
    
    # Future implementation:
    # 1. Get quotes for US_WATCHLIST symbols
    # 2. Sort by performance 
    # 3. Show top gainers/losers
    # 4. Include volume analysis
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 12. é‡è¦å¿«è®¯ï¼ˆå¢å¼ºç‰ˆï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¿«è®¯")
def section_enhanced_news(data: dict) -> list[str]:
    lines = ["ğŸ“° **é‡è¦å¿«è®¯**"]
    news_list = data.get("news", [])
    if isinstance(data, list):
        news_list = data
    if not news_list:
        return lines + ["  æš‚æ— å¿«è®¯"]

    # Categorize news by importance/type
    market_news = []
    fed_news = []
    earnings_news = []
    other_news = []
    
    for item in news_list[:10]:
        title = item.get("title", "").lower()
        if any(keyword in title for keyword in ["fed", "federal", "powell", "interest", "rate"]):
            fed_news.append(item)
        elif any(keyword in title for keyword in ["earnings", "æŠ¥å‘Š", "è´¢æŠ¥", "revenue"]):
            earnings_news.append(item) 
        elif any(keyword in title for keyword in ["market", "stock", "index", "trading"]):
            market_news.append(item)
        else:
            other_news.append(item)
    
    # Display categorized news
    categories = [
        ("ğŸ›ï¸ ç¾è”å‚¨æ”¿ç­–", fed_news),
        ("ğŸ“Š å¸‚åœºåŠ¨æ€", market_news),
        ("ğŸ’° è´¢æŠ¥ä¿¡æ¯", earnings_news),
        ("ğŸ“ˆ å…¶ä»–", other_news),
    ]
    
    shown_count = 0
    for category_name, news_items in categories:
        if news_items and shown_count < 8:
            lines.append(f"  {category_name}:")
            for item in news_items[:3]:  # Max 3 per category
                if shown_count >= 8:
                    break
                title = item.get("title", "")[:70]
                t = item.get("time", "")
                if t and len(t) >= 5:
                    if len(t) >= 16 and "T" in t:
                        t = t[11:16]
                    elif ":" in t:
                        t = t[:5]
                prefix = f"[{t}] " if t else ""
                lines.append(f"    â€¢ {prefix}{title}")
                shown_count += 1
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 13. ç›˜åæ€»ç»“ï¼ˆæ–°å¢ï¼Œæ¨¡ä»¿Aè‚¡æ ¼å¼ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ç›˜åæ€»ç»“")
def section_market_summary(signal_data: dict, sector_data: list) -> list[str]:
    """Generate narrative summary based on signal data."""
    if not signal_data:
        return []
    
    lines = ["â•â•â• ğŸ“ æ€»ç»“ â•â•â•", ""]
    
    sp_pct = signal_data.get("sp_pct", 0)
    nas_pct = signal_data.get("nas_pct", 0) 
    dow_pct = signal_data.get("dow_pct", 0)
    vix_level = signal_data.get("vix_level", 0)
    style_scissor = signal_data.get("style_scissor", 0)
    safe_haven_count = signal_data.get("safe_haven_count", 0)
    bullish_signals = signal_data.get("bullish_signals", 0)
    bearish_signals = signal_data.get("bearish_signals", 0)
    
    # â”€â”€ Market character assessment â”€â”€
    if safe_haven_count >= 2 and vix_level > 25:
        day_type = "extreme_risk_off"
    elif vix_level > 30:
        day_type = "panic_day"
    elif abs(style_scissor) > 2:
        day_type = "style_rotation"
    elif bullish_signals >= 4:
        day_type = "bullish_day"
    elif bearish_signals >= 4:
        day_type = "bearish_day" 
    else:
        day_type = "mixed_day"
    
    # â”€â”€ Headline â”€â”€
    sp_sign = "æ¶¨" if sp_pct >= 0 else "è·Œ"
    nas_sign = "æ¶¨" if nas_pct >= 0 else "è·Œ"
    
    if day_type == "extreme_risk_off":
        lines.append(
            f"ä»Šæ—¥ä¸‰å¤§é¿é™©èµ„äº§åŒæ—¶ä¸Šæ¶¨ï¼ŒVIXè¾¾{vix_level:.1f}ï¼Œ"
            f"æ ‡æ™®{sp_sign}{abs(sp_pct):.2f}%çš„è¡¨ç°æ©ç›–ä¸äº†å¸‚åœºçš„**æåº¦ææ…Œæƒ…ç»ª**ã€‚"
        )
    elif day_type == "panic_day":
        lines.append(f"VIXææ…ŒæŒ‡æ•°é£™å‡è‡³{vix_level:.1f}ï¼Œå¸‚åœºé™·å…¥ææ…Œæ€§æŠ›å”®ã€‚")
    elif day_type == "style_rotation":
        stronger = "ä»·å€¼è‚¡(é“æŒ‡)" if style_scissor > 0 else "æˆé•¿è‚¡(çº³æŒ‡)"
        weaker = "æˆé•¿è‚¡(çº³æŒ‡)" if style_scissor > 0 else "ä»·å€¼è‚¡(é“æŒ‡)"
        lines.append(
            f"ä»Šæ—¥æœ€æ˜¾è‘—ç‰¹å¾æ˜¯é£æ ¼å‰§çƒˆè½®åŠ¨ï¼š{stronger}å¤§å¹…è·‘èµ¢{weaker}ï¼Œ"
            f"å‰ªåˆ€å·®è¾¾{abs(style_scissor):.2f}%ã€‚"
        )
    elif day_type == "bullish_day":
        lines.append(
            f"æ ‡æ™®{sp_sign}{abs(sp_pct):.2f}%ï¼Œçº³æŒ‡{nas_sign}{abs(nas_pct):.2f}%ï¼Œ"
            f"å¤šé‡ä¿¡å·æ˜¾ç¤ºå¸‚åœºé£é™©åå¥½é«˜æ¶¨ã€‚"
        )
    elif day_type == "bearish_day":
        lines.append(
            f"ä¸‰å¤§æŒ‡æ•°å…¨çº¿æ”¶{sp_sign}ï¼Œç©ºå¤´ä¿¡å·å ä¸»å¯¼ï¼ŒæŠ•èµ„è€…æƒ…ç»ªè°¨æ…ã€‚"
        )
    else:
        lines.append(
            f"æ ‡æ™®{sp_sign}{abs(sp_pct):.2f}%ï¼Œçº³æŒ‡{nas_sign}{abs(nas_pct):.2f}%ï¼Œ"
            f"å¸‚åœºæ–¹å‘æ€§ä¸æ˜ç¡®ã€‚"
        )
    
    lines.append("")
    
    # â”€â”€ Key themes â”€â”€
    if sector_data and len(sector_data) > 0:
        best_sector = sector_data[0]
        worst_sector = sector_data[-1]
        sector_spread = best_sector["pct"] - worst_sector["pct"]
        
        if sector_spread > 4:
            lines.append(
                f"æ¿å—åˆ†åŒ–ä¸¥é‡ï¼š{best_sector['name']}é¢†æ¶¨({best_sector['pct']:+.2f}%)ï¼Œ"
                f"{worst_sector['name']}å«åº•({worst_sector['pct']:+.2f}%)ï¼Œä»·å·®{sector_spread:.1f}%ã€‚"
            )
        elif best_sector["pct"] > 2:
            lines.append(f"ä»Šæ—¥äº®ç‚¹ï¼š{best_sector['name']}å¼ºåŠ¿ä¸Šæ¶¨{best_sector['pct']:+.2f}%ã€‚")
    
    # â”€â”€ Tomorrow focus â”€â”€
    lines.append("")
    lines.append("**æ˜æ—¥å…³æ³¨ï¼š**")
    focus_points = []
    
    if vix_level > 25:
        focus_points.append("VIXèƒ½å¦ä»ææ…ŒåŒºå›è½")
    if abs(style_scissor) > 1.5:
        focus_points.append("ä»·å€¼æˆé•¿é£æ ¼è½®åŠ¨æ˜¯å¦æŒç»­")
    if safe_haven_count >= 2:
        focus_points.append("é¿é™©èµ„äº§æµå…¥æ˜¯å¦å‡å¼±")
    if bearish_signals >= 3:
        focus_points.append("ç©ºå¤´ä¿¡å·èƒ½å¦ç¼“è§£")
    
    # Add market-specific focus
    if not focus_points:
        focus_points.append("å…³é”®æ”¯æ’‘é˜»åŠ›ä½è¡¨ç°")
        focus_points.append("ç§‘æŠ€è‚¡ä¸å¤§ç›˜èµ°åŠ¿åˆ†åŒ–")
    
    for fp in focus_points:
        lines.append(f"  â€¢ {fp}")
    
    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Other existing sections (simplified for brevity)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@safe_section("ä¸­æ¦‚è‚¡")
def section_china_adr(data: dict) -> list[str]:
    # ... existing implementation
    lines = ["ğŸ‡¨ğŸ‡³ **ä¸­æ¦‚è‚¡ ADR**"]
    quotes = data.get("quotes", [])
    if not quotes:
        return lines + ["  æ•°æ®æš‚æ— "]

    sorted_q = sorted(quotes, key=lambda q: q["change_pct"], reverse=True)
    avg_pct = sum(q["change_pct"] for q in sorted_q) / len(sorted_q) if sorted_q else 0

    for q in sorted_q:
        icon = pct_icon(q["change_pct"])
        name = q.get("cn_name") or q["symbol"]
        vol_str = f" é‡:{format_volume(q.get('volume', 0))}" if q.get("volume") else ""
        lines.append(
            f"  {icon} {name}({q['symbol']}): ${format_price(q['price'])} "
            f"({q['change_pct']:+.2f}%){vol_str}"
        )

    icon_avg = pct_icon(avg_pct)
    lines.append(f"  {icon_avg} ä¸­æ¦‚è‚¡å¹³å‡æ¶¨å¹…: {avg_pct:+.2f}%")
    return lines


@safe_section("å•†å“æœŸè´§")
def section_commodities(data: dict) -> list[str]:
    # ... existing implementation with enhancements
    lines = ["ğŸ“¦ **å•†å“æœŸè´§å…¨æ™¯**"]
    commodities = data.get("commodities", [])
    if not commodities:
        return lines + ["  æ•°æ®æš‚æ— "]

    # Group by category
    precious = []
    energy = []
    industrial = []
    
    for c in commodities:
        symbol = c["symbol"]
        entry = {
            "cn_name": c.get("cn_name") or c["name"],
            "price": c["price"],
            "pct": c.get("change_pct", 0),
            "volume": c.get("volume", 0),
        }
        if symbol in ("GC=F", "SI=F"):
            precious.append(entry)
        elif symbol in ("CL=F", "BZ=F", "NG=F"):
            energy.append(entry)
        elif symbol in ("HG=F",):
            industrial.append(entry)
        else:
            energy.append(entry)

    categories = [
        ("è´µé‡‘å±", precious),
        ("èƒ½æº", energy), 
        ("å·¥ä¸šé‡‘å±", industrial),
    ]
    
    for cat_name, items in categories:
        if items:
            parts = []
            for c in items:
                icon = pct_icon(c["pct"])
                vol_str = f" é‡:{format_volume(c['volume'])}" if c["volume"] > 0 else ""
                parts.append(f"{icon}{c['cn_name']} ${format_price(c['price'])} ({c['pct']:+.2f}%){vol_str}")
            lines.append(f"  {cat_name}: {' | '.join(parts)}")

    return lines


@safe_section("å€ºåˆ¸æ”¶ç›Šç‡")
def section_bonds(data: dict) -> list[str]:
    # ... existing implementation
    lines = ["ğŸ¦ **ç¾å€ºæ”¶ç›Šç‡æ›²çº¿**"]
    bonds = data.get("bonds", [])
    if not bonds:
        return lines + ["  æ•°æ®æš‚æ— "]

    # Show yield curve
    for b in bonds:
        icon = pct_icon(b.get("change_pct", 0))
        name = b.get("cn_name") or b["name"]
        lines.append(f"  {icon} {name}: {b['price']:.3f}% ({b.get('change_pct', 0):+.3f}%)")

    # Yield curve analysis
    bond_map = {b["symbol"]: b for b in bonds}
    tnx = bond_map.get("^TNX")  # 10Y
    fvx = bond_map.get("^FVX")  # 5Y
    tyx = bond_map.get("^TYX")  # 30Y
    
    if tnx and fvx:
        spread_10_5 = tnx["price"] - fvx["price"]
        curve_status = "æ­£å¸¸" if spread_10_5 > 0 else "âš ï¸ å€’æŒ‚"
        lines.append(f"  ğŸ“ æ”¶ç›Šç‡æ›²çº¿: 10Y-5Y = {spread_10_5:+.3f}% ({curve_status})")
    
    if tyx and tnx:
        spread_30_10 = tyx["price"] - tnx["price"]
        lines.append(f"  ğŸ“ é•¿ç«¯åˆ©å·®: 30Y-10Y = {spread_30_10:+.3f}%")

    return lines


@safe_section("å¤–æ±‡")
def section_forex(data: dict) -> list[str]:
    # ... existing implementation
    lines = ["ğŸ’µ **ç¾å…ƒæŒ‡æ•° / ä¸»è¦è´§å¸**"]
    forex = data.get("forex", [])
    if not forex:
        return lines + ["  æ•°æ®æš‚æ— "]

    for f in forex:
        icon = pct_icon(f.get("change_pct", 0))
        name = f.get("cn_name") or f["name"]
        lines.append(f"  {icon} {name}: {f['price']:.3f} ({f.get('change_pct', 0):+.2f}%)")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main assembly function
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def format_enhanced_briefing(show_time: bool = False) -> str:
    now = datetime.now()
    time_label = now.strftime("%Y-%m-%d %H:%M")
    weekday_cn = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]

    output = []
    output.append(f"{'â•' * 50}")
    output.append(f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡å®Œæ•´ç®€æŠ¥** ({time_label} {weekday_cn})")
    output.append(f"{'â•' * 50}")

    if show_time:
        output.append(f"â± ç”Ÿæˆæ—¶é—´æˆ³: {now.strftime('%Y-%m-%d %H:%M:%S')}")
        output.append("")

    # â”€â”€ Fetch all data concurrently â”€â”€
    endpoints = {
        "index": "/api/us-stock/indexes",
        "sector": "/api/us-stock/sectors", 
        "mag7": "/api/us-stock/mag7",
        "adr": "/api/us-stock/china-adr",
        "commodity": "/api/us-stock/commodities",
        "bond": "/api/us-stock/bonds",
        "forex": "/api/us-stock/forex",
        "news": "/api/news/latest?limit=10",
    }
    
    results = {}
    with ThreadPoolExecutor(max_workers=8) as executor:
        futures = {executor.submit(fetch, ep): key for key, ep in endpoints.items()}
        for future in as_completed(futures):
            key = futures[future]
            results[key] = future.result()

    index_data = results.get("index", {})
    sector_data = results.get("sector", {})
    mag7_data = results.get("mag7", {})
    adr_data = results.get("adr", {})
    commodity_data = results.get("commodity", {})
    bond_data = results.get("bond", {})
    forex_data = results.get("forex", {})
    news_data = results.get("news", {})

    # Save index snapshot
    if index_data:
        save_us_index_snapshot(index_data)

    # â”€â”€ Section 1: Indexes â”€â”€
    output.extend(section_indexes(index_data))
    output.append("")

    # â”€â”€ Section 2: Market movers â”€â”€
    output.extend(section_market_movers())
    output.append("")

    # â”€â”€ Section 3: Intraday table â”€â”€
    output.extend(section_intraday_table()) 
    output.append("")

    # â”€â”€ Section 4: Sector flow â”€â”€
    sector_flow_result = section_sector_flow(sector_data)
    if isinstance(sector_flow_result, tuple):
        sector_lines, processed_sectors = sector_flow_result
        output.extend(sector_lines)
    else:
        output.extend(sector_flow_result)
        processed_sectors = []
    output.append("")

    # â”€â”€ Section 5: Tech detailed â”€â”€
    tech_result = section_tech_detailed(mag7_data)
    if isinstance(tech_result, tuple):
        tech_lines, tech_signal_data = tech_result
        output.extend(tech_lines)
    else:
        output.extend(tech_result)
        tech_signal_data = {}
    output.append("")

    # â”€â”€ Section 6: China ADR â”€â”€
    output.extend(section_china_adr(adr_data))
    output.append("")

    # â”€â”€ Section 7: Commodities â”€â”€
    output.extend(section_commodities(commodity_data))
    output.append("")

    # â”€â”€ Section 8: Bonds â”€â”€
    output.extend(section_bonds(bond_data))
    output.append("")

    # â”€â”€ Section 9: Forex â”€â”€
    output.extend(section_forex(forex_data))
    output.append("")

    # â”€â”€ Section 10: Morning Analysis â”€â”€
    analysis_result = section_morning_analysis(
        index_data, processed_sectors, tech_signal_data,
        commodity_data, bond_data, forex_data
    )
    if isinstance(analysis_result, tuple):
        analysis_lines, signal_data = analysis_result
        output.extend(analysis_lines)
    else:
        output.extend(analysis_result)
        signal_data = {}
    output.append("")

    # â”€â”€ Section 11: US Watchlist â”€â”€
    output.extend(section_us_watchlist())
    output.append("")

    # â”€â”€ Section 12: Enhanced News â”€â”€
    output.extend(section_enhanced_news(news_data))
    output.append("")

    # â”€â”€ Section 13: Market Summary â”€â”€
    summary_lines = section_market_summary(signal_data, processed_sectors)
    if summary_lines:
        output.extend(summary_lines)
        output.append("")

    output.append(f"{'â•' * 50}")
    output.append(f"â± ç”Ÿæˆ: {datetime.now().strftime('%H:%M:%S')} | æ•°æ®ä»…ä¾›å‚è€ƒ")

    return "\n".join(output)


def main():
    parser = argparse.ArgumentParser(description="ç¾è‚¡å®Œæ•´ç®€æŠ¥ v4 å¢å¼ºç‰ˆ")
    parser.add_argument("--time", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†æ—¶é—´æˆ³")
    args = parser.parse_args()

    print(format_enhanced_briefing(show_time=args.time))


if __name__ == "__main__":
    main()