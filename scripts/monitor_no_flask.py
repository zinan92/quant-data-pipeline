#!/usr/bin/env python3
"""
æ¿å—ç›‘æŽ§ â€” åŒèŠ±é¡ºæ•°æ®æºç‰ˆæœ¬
ä½¿ç”¨ TuShare Pro çš„åŒèŠ±é¡ºè¡Œä¸šèµ„é‡‘æµå‘æŽ¥å£èŽ·å–æ¿å—æ¶¨è·Œæ•°æ®ã€‚
å®šæ—¶æ›´æ–°æ•°æ®åˆ° data/monitor/latest.jsonï¼Œå‰ç«¯ API ç›´æŽ¥è¯»å–ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import time
from datetime import datetime
from typing import Dict, List

import pandas as pd

from src.config import get_settings
from src.services.tushare_client import TushareClient
from src.services.tonghuashun_service import (
    TonghuashunService,
    CATEGORY_TO_THS_CONCEPTS,
)

# â”€â”€ é…ç½® â”€â”€
UPDATE_INTERVAL = 300  # æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰â€” åŒèŠ±é¡ºæ•°æ®éžå®žæ—¶ï¼Œ5åˆ†é’Ÿè¶³å¤Ÿ
TOP_N = 20  # ç›‘æŽ§å‰ N ä¸ªæ¿å—

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path(__file__).parent.parent / "data" / "monitor"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

OUTPUT_FILE = OUTPUT_DIR / "latest.json"

# â”€â”€ è‡ªé€‰çƒ­é—¨æ¦‚å¿µåç§°ï¼ˆä»Ž CATEGORY_TO_THS_CONCEPTS æ±‡æ€»ï¼‰ â”€â”€
# å–æ¯ä¸ªèµ›é“æœ€æ ¸å¿ƒçš„æ¦‚å¿µåç§°ï¼Œç¡®ä¿ä¸Žè¡Œä¸šèµ„é‡‘æµå‘æ•°æ®èƒ½åŒ¹é…
WATCH_NAMES: List[str] = [
    "å…‰ä¼è®¾å¤‡",
    "åŠå¯¼ä½“",
    "å°é‡‘å±ž",
    "é€šä¿¡è®¾å¤‡",
    "ç”µåŠ›",
    "æ±½è½¦é›¶éƒ¨ä»¶",
    "æ¶ˆè´¹ç”µå­",
    "è®¡ç®—æœºè®¾å¤‡",
    "åŒ–å­¦åˆ¶è¯",
    "å†›å·¥ç”µå­",
    "ç”µæ± ",
    "è´µé‡‘å±ž",
    "ç”µç½‘è®¾å¤‡",
    "ç™½é…’",
    "æ¸¸æˆ",
    "è‡ªåŠ¨åŒ–è®¾å¤‡",
    "è½¯ä»¶å¼€å‘",
    "èƒ½æºé‡‘å±ž",
]


def _fetch_historical_changes(client: TushareClient, ts_codes: List[str]) -> Dict[str, Dict]:
    """Fetch 5d/10d/20d historical changes and volume via ths_daily."""
    import tushare as ts
    pro = ts.pro_api(client.token)
    
    result = {}
    for code in ts_codes:
        try:
            df = pro.ths_daily(ts_code=code, start_date='20260101', end_date='20260203')
            if df.empty or len(df) < 2:
                continue
            
            today_close = df.iloc[0]["close"]
            today_vol = float(df.iloc[0].get("vol", 0) or 0)
            
            # Calculate N-day changes
            day5 = day10 = day20 = 0.0
            if len(df) >= 6:
                day5 = round((today_close - df.iloc[5]["close"]) / df.iloc[5]["close"] * 100, 2)
            if len(df) >= 11:
                day10 = round((today_close - df.iloc[10]["close"]) / df.iloc[10]["close"] * 100, 2)
            if len(df) >= 21:
                day20 = round((today_close - df.iloc[20]["close"]) / df.iloc[20]["close"] * 100, 2)
            
            result[code] = {
                "day5Change": day5,
                "day10Change": day10,
                "day20Change": day20,
                "volume": round(today_vol / 10000, 2),  # è½¬ä¸‡æ‰‹
            }
        except Exception:
            continue
    
    return result


def _row_to_concept_dict(row: pd.Series, rank: int, hist: Dict = None) -> Dict:
    """å°† moneyflow DataFrame è¡Œè½¬ä¸ºå‰ç«¯æ ¼å¼ dictã€‚"""

    pct_change = float(row.get("pct_change", 0) or 0)
    net_amount = float(row.get("net_amount", 0) or 0)
    company_num = int(row.get("company_num", 0) or 0)
    close = float(row.get("close", 0) or 0)
    net_buy = float(row.get("net_buy_amount", 0) or 0)
    net_sell = float(row.get("net_sell_amount", 0) or 0)
    ts_code = row.get("ts_code", "")
    
    # Historical data if available
    h = (hist or {}).get(ts_code, {})

    return {
        "rank": rank,
        "name": row.get("industry", row.get("name", "")),
        "code": ts_code,
        "changePct": round(pct_change, 2),
        "changeValue": round(close, 2),
        "moneyInflow": round(net_amount, 2),
        "volumeRatio": 0,
        "upCount": 0,
        "downCount": 0,
        "limitUp": 0,
        "totalStocks": company_num,
        "turnover": round(net_buy + net_sell, 2),
        "volume": h.get("volume", 0),
        "day5Change": h.get("day5Change", 0),
        "day10Change": h.get("day10Change", 0),
        "day20Change": h.get("day20Change", 0),
    }


def update_data(service: TonghuashunService) -> None:
    """ä¸»æ›´æ–°é€»è¾‘ï¼šèŽ·å–è¡Œä¸šæŽ’å â†’ ç”Ÿæˆ JSONã€‚"""

    print(f"\n{'=' * 60}")
    print(f"å¼€å§‹æ›´æ–° â€” {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'=' * 60}")

    # 1. èŽ·å–è¡Œä¸šèµ„é‡‘æµå‘æŽ’å
    print("\n[1/3] èŽ·å–åŒèŠ±é¡ºè¡Œä¸šèµ„é‡‘æµå‘...")
    df = service.get_industry_ranking()

    if df.empty:
        print("âš ï¸  è¡Œä¸šèµ„é‡‘æµå‘æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡æœ¬æ¬¡æ›´æ–°")
        return

    print(f"  âœ“ èŽ·å–åˆ° {len(df)} ä¸ªè¡Œä¸šæ¿å—")

    # 1.5. èŽ·å–åŽ†å²æ¶¨è·Œæ•°æ®ï¼ˆ5æ—¥/10æ—¥/20æ—¥ + æˆäº¤é‡ï¼‰
    print("\n[1.5/3] èŽ·å–åŽ†å²æ¶¨è·Œæ•°æ®...")
    all_codes = df["ts_code"].tolist()
    hist = _fetch_historical_changes(service._client, all_codes[:TOP_N + len(WATCH_NAMES)])
    print(f"  âœ“ èŽ·å–åˆ° {len(hist)} ä¸ªæ¿å—çš„åŽ†å²æ•°æ®")

    # 2. æž„å»º topConceptsï¼ˆæ¶¨å¹…å‰ TOP_Nï¼‰
    print(f"\n[2/3] æž„å»ºæ¶¨å¹… TOP{TOP_N}...")
    df_top = df.head(TOP_N)
    top_data = []
    for idx, (_, row) in enumerate(df_top.iterrows(), start=1):
        top_data.append(_row_to_concept_dict(row, idx, hist))

    # 3. æž„å»º watchConceptsï¼ˆè‡ªé€‰çƒ­é—¨ï¼‰
    print(f"\n[3/3] æž„å»ºè‡ªé€‰çƒ­é—¨æ¦‚å¿µ...")
    watch_data = []
    for watch_name in WATCH_NAMES:
        matched = df[df["industry"] == watch_name]
        if not matched.empty:
            row = matched.iloc[0]
            watch_data.append(_row_to_concept_dict(row, len(watch_data) + 1, hist))
        else:
            print(f"  âš ï¸  è‡ªé€‰æ¦‚å¿µ '{watch_name}' æœªåœ¨è¡Œä¸šæ•°æ®ä¸­æ‰¾åˆ°")

    # Re-rank watch data
    for idx, item in enumerate(watch_data, start=1):
        item["rank"] = idx

    # 4. ä¿å­˜ JSON
    output = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "updateInterval": UPDATE_INTERVAL,
        "dataSource": "tonghuashun_tushare",
        "topConcepts": {
            "total": len(top_data),
            "data": top_data,
        },
        "watchConcepts": {
            "total": len(watch_data),
            "data": watch_data,
        },
    }

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ•°æ®å·²å†™å…¥: {OUTPUT_FILE}")
    print(f"   â€” æ¶¨å¹… TOP{TOP_N}: {len(top_data)} ä¸ª")
    print(f"   â€” è‡ªé€‰çƒ­é—¨: {len(watch_data)} ä¸ª")

    # æ‘˜è¦
    print(f"\nðŸ“Š æ¶¨å¹…å‰ 5:")
    for item in top_data[:5]:
        print(
            f"   {item['rank']:2d}. {item['name']:10s}  "
            f"{item['changePct']:+6.2f}%  "
            f"å‡€æµå…¥: {item['moneyInflow']:+8.2f}äº¿  "
            f"æˆåˆ†: {item['totalStocks']}åª"
        )


def run_once(service: TonghuashunService) -> None:
    """å•æ¬¡è¿è¡Œã€‚"""
    print("è¿è¡Œæ¨¡å¼: å•æ¬¡æ›´æ–°")
    update_data(service)


def run_continuous(service: TonghuashunService) -> None:
    """æŒç»­è¿è¡Œæ¨¡å¼ã€‚"""
    print("=" * 60)
    print("ðŸš€ æ¿å—ç›‘æŽ§å¯åŠ¨ï¼ˆåŒèŠ±é¡ºæ•°æ®æºï¼‰")
    print("=" * 60)
    print(f"ç›‘æŽ§é…ç½®:")
    print(f"  â€” æ¶¨å¹…å‰ {TOP_N} è¡Œä¸š")
    print(f"  â€” è‡ªé€‰çƒ­é—¨: {len(WATCH_NAMES)} ä¸ª")
    print(f"  â€” æ›´æ–°é—´éš”: {UPDATE_INTERVAL} ç§’ ({UPDATE_INTERVAL / 60:.1f} åˆ†é’Ÿ)")
    print(f"  â€” è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    print("=" * 60)

    iteration = 0
    while True:
        try:
            iteration += 1
            print(f"\nç¬¬ {iteration} è½®ç›‘æŽ§")
            update_data(service)
            print(f"\nâ° ç­‰å¾… {UPDATE_INTERVAL} ç§’...")
            time.sleep(UPDATE_INTERVAL)
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢ç›‘æŽ§")
            break
        except Exception as e:
            print(f"\nâŒ æ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            print("ç­‰å¾… 30 ç§’åŽé‡è¯•...")
            time.sleep(30)


if __name__ == "__main__":
    # Initialise service
    settings = get_settings()
    client = TushareClient(
        token=settings.tushare_token,
        points=settings.tushare_points,
    )
    svc = TonghuashunService(client=client)

    if len(sys.argv) > 1 and sys.argv[1] == "--once":
        run_once(svc)
    else:
        run_continuous(svc)
