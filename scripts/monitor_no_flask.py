#!/usr/bin/env python3
"""
æ¿å—ç›‘æ§ - æ— éœ€Flaskç‰ˆæœ¬
å®šæ—¶æ›´æ–°æ•°æ®åˆ°JSONæ–‡ä»¶ï¼Œå‰ç«¯ç›´æ¥è¯»å–
åŒ…å«åŠ¨é‡ä¿¡å·æ£€æµ‹åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import akshare as ak
import pandas as pd
import json
import time
from datetime import datetime, timedelta
from collections import deque
from typing import Dict, List, Optional
from src.database import SessionLocal
from src.models import Kline, SymbolType, KlineTimeframe
from sqlalchemy import and_, desc

# é…ç½®
WATCH_LIST = [
    "å…ˆè¿›å°è£…",
    "å­˜å‚¨èŠ¯ç‰‡",
    "å…‰åˆ»æœº",
    "ç¬¬ä¸‰ä»£åŠå¯¼ä½“",
    "å›½å®¶å¤§åŸºé‡‘æŒè‚¡",
    "æ±½è½¦èŠ¯ç‰‡",
    "MCUèŠ¯ç‰‡",
    "ä¸­èŠ¯å›½é™…æ¦‚å¿µ",
    "äººå½¢æœºå™¨äºº",
    "ç‰¹é«˜å‹"
]

UPDATE_INTERVAL = 60  # æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
TOP_N = 20  # ç›‘æ§å‰Nä¸ªæ¿å—

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path(__file__).parent.parent / 'data' / 'monitor'
OUTPUT_DIR.mkdir(exist_ok=True)

OUTPUT_FILE = OUTPUT_DIR / 'latest.json'
SIGNALS_FILE = OUTPUT_DIR / 'momentum_signals.json'

# æ•°æ®ç›®å½•
DATA_DIR = Path('/Users/park/a-share-data/data')

# å¿«ç…§å†å²ï¼ˆä¿ç•™æœ€è¿‘10æ¬¡ï¼Œç”¨äºæ£€æµ‹åŠ¨é‡å˜åŒ–ï¼‰
SNAPSHOT_HISTORY: deque = deque(maxlen=10)


def build_concept_code_mapping():
    """
    å»ºç«‹æ–°æ—§æ¦‚å¿µä»£ç æ˜ å°„
    æ–°ç³»ç»Ÿä»£ç (AKShare) -> æ—§ç³»ç»Ÿä»£ç (æ•°æ®åº“)
    é€šè¿‡æ¦‚å¿µåç§°ä½œä¸ºæ¡¥æ¢
    """
    # è¯»å–æ—§ç³»ç»Ÿæ˜ å°„æ–‡ä»¶
    concept_file = DATA_DIR / 'concept_to_tickers.csv'
    df_old = pd.read_csv(concept_file)

    # åˆ›å»ºåç§° -> æ—§ä»£ç æ˜ å°„
    old_mapping = {}
    for _, row in df_old.iterrows():
        name = row['æ¿å—åç§°']
        code = row['æ¿å—ä»£ç '].replace('.TI', '')  # 886042.TI -> 886042
        old_mapping[name] = code

    return old_mapping


def calculate_n_day_change(old_code: str, n_days: int) -> float:
    """
    ä»æ•°æ®åº“Kçº¿æ•°æ®è®¡ç®—Næ—¥æ¶¨å¹…

    Args:
        old_code: æ—§ç³»ç»Ÿä»£ç  (å¦‚ 886042)
        n_days: å¤©æ•° (5, 10, 20)

    Returns:
        Næ—¥æ¶¨å¹…ç™¾åˆ†æ¯”ï¼Œå¦‚æœæ•°æ®ä¸è¶³è¿”å›0
    """
    session = SessionLocal()
    try:
        # è·å–æœ€è¿‘çš„ n_days+1 æ¡æ—¥Kçº¿ï¼ˆéœ€è¦å¤šä¸€æ¡ç”¨äºè®¡ç®—ï¼‰
        klines = session.query(Kline).filter(
            and_(
                Kline.symbol_type == SymbolType.CONCEPT,
                Kline.symbol_code == old_code,
                Kline.timeframe == KlineTimeframe.DAY
            )
        ).order_by(desc(Kline.trade_time)).limit(n_days + 1).all()

        if len(klines) < n_days + 1:
            return 0.0

        # æœ€æ–°æ”¶ç›˜ä»·
        latest_close = klines[0].close
        # Nå¤©å‰çš„æ”¶ç›˜ä»·
        n_days_ago_close = klines[n_days].close

        if n_days_ago_close > 0:
            change_pct = ((latest_close - n_days_ago_close) / n_days_ago_close) * 100
            return round(change_pct, 2)

        return 0.0

    except Exception as e:
        print(f"  âš ï¸  è®¡ç®—{old_code}çš„{n_days}æ—¥æ¶¨å¹…å¤±è´¥: {e}")
        return 0.0
    finally:
        session.close()


def calculate_limit_up_count(concept_name):
    """è®¡ç®—æ¶¨åœæ•°"""
    try:
        df_stocks = ak.stock_board_concept_cons_em(symbol=concept_name)
        if df_stocks is not None and len(df_stocks) > 0:
            limit_up_count = 0
            for _, stock in df_stocks.iterrows():
                change_pct = stock.get('æ¶¨è·Œå¹…', 0)
                code = stock.get('ä»£ç ', '')

                if code.startswith('688') or code.startswith('300'):
                    if change_pct >= 19.9:
                        limit_up_count += 1
                else:
                    if change_pct >= 9.9:
                        limit_up_count += 1

            return limit_up_count
    except:
        pass
    return 0


def fetch_all_concepts():
    """è·å–æ‰€æœ‰æ¦‚å¿µæ¿å—æ•°æ®"""
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹è·å–æ¿å—æ•°æ®...")

    df_names = ak.stock_board_concept_name_ths()
    results = []

    for idx, row in df_names.iterrows():
        concept_name = row['name']
        concept_code = row['code']

        try:
            df_info = ak.stock_board_concept_info_ths(symbol=concept_name)

            data = {}
            for i, info_row in df_info.iterrows():
                data[info_row['é¡¹ç›®']] = info_row['å€¼']

            up_down = data.get('æ¶¨è·Œå®¶æ•°', '0/0')
            up_count, down_count = map(int, up_down.split('/'))

            change_pct_str = data.get('æ¿å—æ¶¨å¹…', '0%').replace('%', '')
            money_inflow = float(data.get('èµ„é‡‘å‡€æµå…¥(äº¿)', 0))
            turnover = float(data.get('æˆäº¤é¢(äº¿)', 0))
            volume = float(data.get('æˆäº¤é‡(ä¸‡æ‰‹)', 0))

            results.append({
                'code': concept_code,
                'name': concept_name,
                'changePct': float(change_pct_str),
                'changeValue': 0,
                'moneyInflow': money_inflow,
                'volumeRatio': 0,
                'upCount': up_count,
                'downCount': down_count,
                'limitUp': 0,
                'totalStocks': up_count + down_count,
                'turnover': turnover,
                'volume': volume,
                'day5Change': 0,
                'day10Change': 0,
                'day20Change': 0,
            })

            time.sleep(0.25)

        except Exception as e:
            print(f"  âœ— {concept_name}: {str(e)[:50]}")
            continue

    df = pd.DataFrame(results)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] æˆåŠŸè·å– {len(df)} ä¸ªæ¿å—")
    return df


def enhance_with_limit_up(df, concepts):
    """ä¸ºæŒ‡å®šæ¿å—è¡¥å……æ¶¨åœæ•°"""
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] è®¡ç®—æ¶¨åœæ•°...")

    for idx, row in df[df['name'].isin(concepts)].iterrows():
        concept_name = row['name']
        limit_up = calculate_limit_up_count(concept_name)
        df.at[idx, 'limitUp'] = limit_up
        print(f"  {concept_name}: {limit_up}åªæ¶¨åœ")
        time.sleep(0.3)

    return df


def enhance_with_historical_changes(df, concepts):
    """
    ä¸ºæŒ‡å®šæ¿å—è¡¥å……å†å²æ¶¨å¹…æ•°æ®
    ä»æœ¬åœ°æ•°æ®åº“Kçº¿è¡¨è¯»å–
    """
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] è®¡ç®—å†å²æ¶¨å¹…...")

    # å»ºç«‹æ–°æ—§ä»£ç æ˜ å°„
    code_mapping = build_concept_code_mapping()

    for idx, row in df[df['name'].isin(concepts)].iterrows():
        concept_name = row['name']

        # è·å–æ—§ç³»ç»Ÿä»£ç 
        old_code = code_mapping.get(concept_name)

        if not old_code:
            print(f"  âš ï¸  {concept_name}: æœªæ‰¾åˆ°æ—§ä»£ç æ˜ å°„")
            continue

        # è®¡ç®—5æ—¥ã€10æ—¥ã€20æ—¥æ¶¨å¹…
        day5_change = calculate_n_day_change(old_code, 5)
        day10_change = calculate_n_day_change(old_code, 10)
        day20_change = calculate_n_day_change(old_code, 20)

        df.at[idx, 'day5Change'] = day5_change
        df.at[idx, 'day10Change'] = day10_change
        df.at[idx, 'day20Change'] = day20_change

        print(f"  {concept_name}: 5æ—¥{day5_change:+.2f}% 10æ—¥{day10_change:+.2f}% 20æ—¥{day20_change:+.2f}%")

    return df


def check_kline_pattern(old_code: str) -> Optional[Dict]:
    """
    æ£€æµ‹30åˆ†é’ŸKçº¿å½¢æ€ (Criterion 3)
    é˜³çº¿ä¸”æ— ä¸Šå½±çº¿: close > open ä¸” (high - close) / (close - open) < 0.05

    Args:
        old_code: æ—§ç³»ç»Ÿä»£ç  (å¦‚ 886042)

    Returns:
        å¦‚æœç¬¦åˆæ¡ä»¶è¿”å›å½¢æ€ä¿¡æ¯ï¼Œå¦åˆ™è¿”å›None
    """
    session = SessionLocal()
    try:
        # è·å–æœ€æ–°çš„30åˆ†é’ŸKçº¿
        latest_kline = session.query(Kline).filter(
            and_(
                Kline.symbol_type == SymbolType.CONCEPT,
                Kline.symbol_code == old_code,
                Kline.timeframe == KlineTimeframe.MINS_30
            )
        ).order_by(desc(Kline.trade_time)).first()

        if not latest_kline:
            return None

        # æ£€æŸ¥æ˜¯å¦ä¸ºé˜³çº¿
        is_yang = latest_kline.close > latest_kline.open
        if not is_yang:
            return None

        # æ£€æŸ¥ä¸Šå½±çº¿æ¯”ä¾‹
        body_size = latest_kline.close - latest_kline.open
        if body_size <= 0:
            return None

        upper_shadow_ratio = (latest_kline.high - latest_kline.close) / body_size

        # ä¸Šå½±çº¿å°äº5%è§†ä¸ºæ— ä¸Šå½±çº¿
        if upper_shadow_ratio < 0.05:
            return {
                'trade_time': latest_kline.trade_time,
                'open': latest_kline.open,
                'high': latest_kline.high,
                'low': latest_kline.low,
                'close': latest_kline.close,
                'upper_shadow_ratio': round(upper_shadow_ratio * 100, 2)
            }

        return None

    except Exception as e:
        print(f"  âš ï¸  æ£€æµ‹{old_code}çš„Kçº¿å½¢æ€å¤±è´¥: {e}")
        return None
    finally:
        session.close()


def detect_surge_signals(df_current: pd.DataFrame) -> List[Dict]:
    """
    æ£€æµ‹ä¸Šæ¶¨å®¶æ•°æ¿€å¢ä¿¡å· (Criterion 2)
    å¤§æ¿å—(â‰¥50åª): 60ç§’å†…æ–°å¢â‰¥5åªä¸Šæ¶¨
    å°æ¿å—(<50åª): 60ç§’å†…æ–°å¢â‰¥3åªä¸Šæ¶¨

    Args:
        df_current: å½“å‰æ¿å—æ•°æ®

    Returns:
        ç¬¦åˆæ¡ä»¶çš„ä¿¡å·åˆ—è¡¨
    """
    signals = []

    # éœ€è¦è‡³å°‘ä¸€æ¬¡å†å²å¿«ç…§æ‰èƒ½æ£€æµ‹
    if len(SNAPSHOT_HISTORY) == 0:
        return signals

    # è·å–60ç§’å‰çš„å¿«ç…§ï¼ˆå½“å‰é—´éš”60ç§’ï¼Œæ‰€ä»¥å–ä¸Šä¸€æ¬¡å¿«ç…§ï¼‰
    prev_snapshot = SNAPSHOT_HISTORY[0]

    # éå†å½“å‰æ‰€æœ‰æ¿å—
    for _, current_row in df_current.iterrows():
        concept_name = current_row['name']
        current_up_count = current_row['upCount']
        total_stocks = current_row['totalStocks']

        # æŸ¥æ‰¾å†å²å¿«ç…§ä¸­å¯¹åº”çš„æ¿å—
        prev_row = prev_snapshot[prev_snapshot['name'] == concept_name]
        if prev_row.empty:
            continue

        prev_up_count = prev_row.iloc[0]['upCount']
        delta_up_count = current_up_count - prev_up_count

        # åˆ¤æ–­æ˜¯å¦è§¦å‘ä¿¡å·
        is_large_board = total_stocks >= 50
        threshold = 5 if is_large_board else 3

        if delta_up_count >= threshold:
            signals.append({
                'concept_name': concept_name,
                'concept_code': current_row['code'],
                'signal_type': 'surge',
                'total_stocks': total_stocks,
                'prev_up_count': int(prev_up_count),
                'current_up_count': int(current_up_count),
                'delta_up_count': int(delta_up_count),
                'threshold': threshold,
                'board_type': 'large' if is_large_board else 'small',
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'details': f"{delta_up_count}åªæ–°å¢ä¸Šæ¶¨ (é˜ˆå€¼: {threshold}åª)"
            })

    return signals


def detect_kline_pattern_signals(df_current: pd.DataFrame) -> List[Dict]:
    """
    æ£€æµ‹30åˆ†é’ŸKçº¿å½¢æ€ä¿¡å· (Criterion 3)

    Args:
        df_current: å½“å‰æ¿å—æ•°æ®

    Returns:
        ç¬¦åˆæ¡ä»¶çš„ä¿¡å·åˆ—è¡¨
    """
    signals = []
    code_mapping = build_concept_code_mapping()

    # åªæ£€æµ‹æ¶¨å¹…å‰20çš„æ¿å—å’Œè‡ªé€‰æ¿å—
    focus_concepts = df_current.head(TOP_N)['name'].tolist() + WATCH_LIST
    focus_concepts = list(set(focus_concepts))

    for concept_name in focus_concepts:
        old_code = code_mapping.get(concept_name)
        if not old_code:
            continue

        pattern_info = check_kline_pattern(old_code)
        if pattern_info:
            # è·å–å½“å‰æ¿å—æ•°æ®
            concept_row = df_current[df_current['name'] == concept_name]
            if concept_row.empty:
                continue

            concept_data = concept_row.iloc[0]

            signals.append({
                'concept_name': concept_name,
                'concept_code': concept_data['code'],
                'signal_type': 'kline_pattern',
                'total_stocks': int(concept_data['totalStocks']),
                'current_change_pct': float(concept_data['changePct']),
                'kline_info': pattern_info,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'details': f"é˜³çº¿æ— ä¸Šå½±çº¿ (ä¸Šå½±{pattern_info['upper_shadow_ratio']}%)"
            })

    return signals


def save_momentum_signals(surge_signals: List[Dict], kline_signals: List[Dict]):
    """
    ä¿å­˜åŠ¨é‡ä¿¡å·åˆ°JSONæ–‡ä»¶

    Args:
        surge_signals: ä¸Šæ¶¨æ¿€å¢ä¿¡å·åˆ—è¡¨
        kline_signals: Kçº¿å½¢æ€ä¿¡å·åˆ—è¡¨
    """
    all_signals = surge_signals + kline_signals

    output_data = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_signals': len(all_signals),
        'surge_signals_count': len(surge_signals),
        'kline_signals_count': len(kline_signals),
        'signals': all_signals
    }

    with open(SIGNALS_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    if all_signals:
        print(f"\nğŸ”” æ£€æµ‹åˆ° {len(all_signals)} ä¸ªåŠ¨é‡ä¿¡å·:")
        print(f"   - ä¸Šæ¶¨æ¿€å¢: {len(surge_signals)}ä¸ª")
        print(f"   - Kçº¿å½¢æ€: {len(kline_signals)}ä¸ª")
        for signal in all_signals[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"   [{signal['signal_type']}] {signal['concept_name']}: {signal['details']}")


def update_data():
    """æ›´æ–°æ•°æ®"""
    print("\n" + "="*60)
    print(f"å¼€å§‹æ›´æ–° - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)

    # 1. è·å–æ‰€æœ‰æ¿å—æ•°æ®
    df_all = fetch_all_concepts()

    # 2. è·å–æ¶¨å¹…å‰20
    df_all = df_all.sort_values('changePct', ascending=False)
    top_concepts = df_all.head(TOP_N)['name'].tolist()

    # 3. åˆå¹¶éœ€è¦è®¡ç®—æ¶¨åœæ•°å’Œå†å²æ¶¨å¹…çš„æ¿å—
    focus_concepts = list(set(top_concepts + WATCH_LIST))

    # 4. è®¡ç®—æ¶¨åœæ•°
    df_all = enhance_with_limit_up(df_all, focus_concepts)

    # 5. è®¡ç®—å†å²æ¶¨å¹… (5æ—¥/10æ—¥/20æ—¥)
    df_all = enhance_with_historical_changes(df_all, focus_concepts)

    # 6. æŒ‰æ¶¨å¹…é‡æ–°æ’åº
    df_all = df_all.sort_values('changePct', ascending=False)

    # 7. æå–æ•°æ®
    df_top = df_all.head(TOP_N).copy()
    df_watch = df_all[df_all['name'].isin(WATCH_LIST)].copy()

    # 8. æ·»åŠ æ’å
    df_top['rank'] = range(1, len(df_top) + 1)
    df_watch['rank'] = range(1, len(df_watch) + 1)

    # 9. æ£€æµ‹åŠ¨é‡ä¿¡å·
    surge_signals = detect_surge_signals(df_all)
    kline_signals = detect_kline_pattern_signals(df_all)

    # 10. ä¿å­˜åŠ¨é‡ä¿¡å·
    save_momentum_signals(surge_signals, kline_signals)

    # 11. ä¿å­˜å½“å‰å¿«ç…§åˆ°å†å²
    SNAPSHOT_HISTORY.appendleft(df_all.copy())

    # 12. ä¿å­˜ä¸ºJSON
    output_data = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'updateInterval': UPDATE_INTERVAL,
        'topConcepts': {
            'total': len(df_top),
            'data': df_top.to_dict('records')
        },
        'watchConcepts': {
            'total': len(df_watch),
            'data': df_watch.to_dict('records')
        }
    }

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ•°æ®å·²æ›´æ–°: {OUTPUT_FILE}")
    print(f"   - æ¶¨å¹…å‰{TOP_N}: {len(df_top)}ä¸ª")
    print(f"   - è‡ªé€‰æ¦‚å¿µ: {len(df_watch)}ä¸ª")

    # 13. æ‰“å°æ‘˜è¦
    print(f"\nğŸ“Š æ¶¨å¹…å‰5:")
    for idx, row in df_top.head(5).iterrows():
        print(f"   {row['rank']}. {row['name']:15s} "
              f"{row['changePct']:+6.2f}% "
              f"æ¶¨åœ:{row['limitUp']:2d} "
              f"èµ„é‡‘:{row['moneyInflow']:8.2f}äº¿")


def run_continuous():
    """æŒç»­è¿è¡Œ"""
    print("="*60)
    print("ğŸš€ æ¿å—ç›‘æ§å¯åŠ¨ï¼ˆæ— éœ€Flaskç‰ˆæœ¬ï¼‰")
    print("="*60)
    print(f"ç›‘æ§é…ç½®:")
    print(f"  - æ¶¨å¹…å‰{TOP_N}æ¦‚å¿µ")
    print(f"  - è‡ªé€‰æ¦‚å¿µ: {len(WATCH_LIST)}ä¸ª")
    print(f"  - æ›´æ–°é—´éš”: {UPDATE_INTERVAL}ç§’ ({UPDATE_INTERVAL/60:.1f}åˆ†é’Ÿ)")
    print(f"  - è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    print("="*60)
    print(f"\nğŸ’¡ å‰ç«¯è¯»å–: {OUTPUT_FILE}")
    print(f"   æˆ–é€šè¿‡HTTP: http://localhost:8000/docs/monitor/latest.json")
    print("="*60)

    iteration = 0
    while True:
        try:
            iteration += 1
            print(f"\nç¬¬{iteration}è½®ç›‘æ§")

            update_data()

            print(f"\nâ° ç­‰å¾… {UPDATE_INTERVAL}ç§’...")
            time.sleep(UPDATE_INTERVAL)

        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢ç›‘æ§")
            break
        except Exception as e:
            print(f"\nâŒ æ›´æ–°å¤±è´¥: {e}")
            print(f"ç­‰å¾…30ç§’åé‡è¯•...")
            time.sleep(30)


def run_once():
    """å•æ¬¡è¿è¡Œ"""
    print("è¿è¡Œæ¨¡å¼: å•æ¬¡æ›´æ–°")
    update_data()


if __name__ == '__main__':
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == '--once':
        run_once()
    else:
        run_continuous()
