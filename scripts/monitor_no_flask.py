#!/usr/bin/env python3
"""
æ¿å—ç›‘æŽ§ â€” åŒèŠ±é¡ºæ•°æ®æºç‰ˆæœ¬ (æ··æŽ’: 90è¡Œä¸š + ~390æ¦‚å¿µ)
ä½¿ç”¨ TuShare Pro çš„ ths_daily èŽ·å–æ‰€æœ‰æ¿å—æ¶¨è·Œæ•°æ®ï¼Œ
moneyflow_ind_ths è¡¥å……90ä¸ªè¡Œä¸šçš„èµ„é‡‘æµå‘ã€‚
å®šæ—¶æ›´æ–°æ•°æ®åˆ° data/monitor/latest.jsonï¼Œå‰ç«¯ API ç›´æŽ¥è¯»å–ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import json
import re
import time
from datetime import datetime
from typing import Dict, List, Optional, Set

import pandas as pd

from src.config import get_settings
from src.services.tushare_client import TushareClient
from src.services.tonghuashun_service import TonghuashunService

# â”€â”€ é…ç½® â”€â”€
UPDATE_INTERVAL = 300  # æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰â€” åŒèŠ±é¡ºæ•°æ®éžå®žæ—¶ï¼Œ5åˆ†é’Ÿè¶³å¤Ÿ
TOP_N = 20  # ç›‘æŽ§å‰ N ä¸ªæ¿å—

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path(__file__).parent.parent / "data" / "monitor"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_FILE = OUTPUT_DIR / "latest.json"

# â”€â”€ è‡ªé€‰çƒ­é—¨ï¼ˆè¡Œä¸š + æ¦‚å¿µæ··æŽ’ï¼‰ â”€â”€
WATCH_NAMES: List[str] = [
    # è¡Œä¸š
    "å…‰ä¼è®¾å¤‡", "åŠå¯¼ä½“", "ç”µæ± ", "è´µé‡‘å±ž", "ç™½é…’", "å†›å·¥ç”µå­",
    "é€šä¿¡è®¾å¤‡", "æ¶ˆè´¹ç”µå­", "è‡ªåŠ¨åŒ–è®¾å¤‡", "è½¯ä»¶å¼€å‘", "èƒ½æºé‡‘å±ž",
    # æ¦‚å¿µ
    "äººå½¢æœºå™¨äºº", "AIåº”ç”¨", "å…‰åˆ»æœº", "BCç”µæ± ", "é’™é’›çŸ¿ç”µæ± ",
    "ç¨€åœŸæ°¸ç£", "æ™ºèƒ½ç”µç½‘", "èŠ¯ç‰‡æ¦‚å¿µ",
]


# â”€â”€ æ¿å—ä»£ç å‰ç¼€ â”€â”€
_INDUSTRY_PREFIX = "881"
_CONCEPT_PREFIXES = ("885", "886")
_ALL_PREFIXES_RE = re.compile(r"^(881|885|886)")


def _build_name_map(client: TushareClient) -> Dict[str, str]:
    """Build ts_code â†’ name mapping from ths_index (industry + concept)."""
    import tushare as ts
    pro = ts.pro_api(client.token)
    name_map: Dict[str, str] = {}

    try:
        df_i = pro.ths_index(exchange='A', type='I')  # è¡Œä¸š
        if not df_i.empty:
            name_map.update(dict(zip(df_i['ts_code'], df_i['name'])))
            print(f"  âœ“ è¡Œä¸šæŒ‡æ•°åç§°: {len(df_i)} æ¡")
        time.sleep(0.3)

        df_n = pro.ths_index(exchange='A', type='N')  # æ¦‚å¿µ
        if not df_n.empty:
            name_map.update(dict(zip(df_n['ts_code'], df_n['name'])))
            print(f"  âœ“ æ¦‚å¿µæŒ‡æ•°åç§°: {len(df_n)} æ¡")
    except Exception as e:
        print(f"  âš ï¸ èŽ·å–åç§°æ˜ å°„å¤±è´¥: {e}")

    return name_map


def _fetch_mixed_daily(client: TushareClient, trade_date: str, name_map: Dict[str, str]) -> pd.DataFrame:
    """Fetch ths_daily for the given date, filter to 881/885/886, add name & board_type."""
    import tushare as ts
    pro = ts.pro_api(client.token)

    try:
        df = pro.ths_daily(trade_date=trade_date)
    except Exception as e:
        print(f"  âš ï¸ ths_daily èŽ·å–å¤±è´¥: {e}")
        return pd.DataFrame()

    if df.empty:
        return pd.DataFrame()

    # Filter to industry + concept codes
    mask = df['ts_code'].str.match(_ALL_PREFIXES_RE)
    df = df[mask].copy()

    # Add name and board_type
    df['name'] = df['ts_code'].map(name_map)
    df['board_type'] = df['ts_code'].apply(
        lambda x: 'è¡Œä¸š' if x.startswith(_INDUSTRY_PREFIX) else 'æ¦‚å¿µ'
    )

    # Drop rows with no name mapping
    df = df.dropna(subset=['name'])

    # Sort by pct_change descending
    df = df.sort_values('pct_change', ascending=False).reset_index(drop=True)
    return df


def _fetch_moneyflow_map(client: TushareClient, trade_date: str) -> Dict[str, Dict]:
    """Fetch moneyflow for 90 industries, return {ts_code: {net_amount, turnover, company_num, ...}}."""
    try:
        df = client.fetch_ths_industry_moneyflow(trade_date=trade_date)
    except Exception as e:
        print(f"  âš ï¸ moneyflow èŽ·å–å¤±è´¥: {e}")
        return {}

    if df.empty:
        return {}

    result: Dict[str, Dict] = {}
    for _, row in df.iterrows():
        ts_code = row.get("ts_code", "")
        net_buy = float(row.get("net_buy_amount", 0) or 0)
        net_sell = float(row.get("net_sell_amount", 0) or 0)
        result[ts_code] = {
            "net_amount": float(row.get("net_amount", 0) or 0),
            "turnover": round(net_buy + net_sell, 2),
            "company_num": int(row.get("company_num", 0) or 0),
            "lead_stock": row.get("lead_stock", ""),
        }
    return result


def _fetch_limit_counts(client: TushareClient, trade_date: str) -> Dict[str, Dict]:
    """Fetch limit-up/down counts per industry name from limit_list_d."""
    import tushare as ts
    pro = ts.pro_api(client.token)

    result: Dict[str, Dict] = {}
    try:
        df_up = pro.limit_list_d(trade_date=trade_date, limit_type='U')
        if not df_up.empty:
            counts = df_up.groupby('industry').size()
            for ind, cnt in counts.items():
                result.setdefault(ind, {})["limitUp"] = int(cnt)

        time.sleep(0.3)

        df_down = pro.limit_list_d(trade_date=trade_date, limit_type='D')
        if not df_down.empty:
            counts = df_down.groupby('industry').size()
            for ind, cnt in counts.items():
                result.setdefault(ind, {})["limitDown"] = int(cnt)
    except Exception as e:
        print(f"  âš ï¸ èŽ·å–æ¶¨è·Œåœæ•°æ®å¤±è´¥: {e}")

    return result


def _fetch_up_down_counts(client: TushareClient, ts_codes: List[str], trade_date: str) -> Dict[str, Dict]:
    """Fetch up/down stock counts for given board ts_codes via ths_member + daily."""
    import tushare as ts
    pro = ts.pro_api(client.token)

    result: Dict[str, Dict] = {}

    # Get all A-share daily data for today in one call
    try:
        df_daily = pro.daily(trade_date=trade_date)
        if df_daily.empty:
            return result
    except Exception as e:
        print(f"  âš ï¸ èŽ·å–æ—¥çº¿æ•°æ®å¤±è´¥: {e}")
        return result

    for code in ts_codes:
        try:
            members = pro.ths_member(ts_code=code)
            time.sleep(0.3)
            if members.empty:
                continue

            member_codes = set(members["con_code"].tolist())
            matched = df_daily[df_daily["ts_code"].isin(member_codes)]

            up_count = int((matched["pct_chg"] > 0).sum())
            down_count = int((matched["pct_chg"] < 0).sum())

            result[code] = {"upCount": up_count, "downCount": down_count}
        except Exception:
            continue

    return result


def _fetch_historical_changes(client: TushareClient, ts_codes: List[str]) -> Dict[str, Dict]:
    """Fetch 5d/10d/20d historical changes and volume via ths_daily."""
    import tushare as ts
    pro = ts.pro_api(client.token)

    result: Dict[str, Dict] = {}
    for code in ts_codes:
        try:
            df = pro.ths_daily(ts_code=code, start_date='20260101', end_date='20260630')
            time.sleep(0.3)
            if df.empty or len(df) < 2:
                continue

            today_close = df.iloc[0]["close"]
            today_vol = float(df.iloc[0].get("vol", 0) or 0)

            day5 = day10 = day20 = 0.0
            if len(df) >= 6:
                day5 = round((today_close - df.iloc[5]["close"]) / df.iloc[5]["close"] * 100, 2)
            if len(df) >= 11:
                day10 = round((today_close - df.iloc[10]["close"]) / df.iloc[10]["close"] * 100, 2)
            if len(df) >= 21:
                day20 = round((today_close - df.iloc[20]["close"]) / df.iloc[20]["close"] * 100, 2)

            result[code] = {
                "day5Change": day5,
                "day10Change": day10,
                "day20Change": day20,
                "volume": round(today_vol / 10000, 2),  # è½¬ä¸‡æ‰‹
            }
        except Exception:
            continue

    return result


def _build_item(
    row: pd.Series,
    rank: int,
    moneyflow: Dict[str, Dict],
    hist: Dict[str, Dict],
    limit_counts: Dict[str, Dict],
    up_down: Dict[str, Dict],
) -> Dict:
    """Convert a mixed-daily row into frontend-compatible dict."""
    ts_code = row.get("ts_code", "")
    name = row.get("name", "")
    board_type = row.get("board_type", "è¡Œä¸š")
    pct_change = float(row.get("pct_change", 0) or 0)
    close = float(row.get("close", 0) or 0)
    vol = float(row.get("vol", 0) or 0)

    # Moneyflow data (only for industries)
    mf = moneyflow.get(ts_code, {})
    net_amount = mf.get("net_amount", 0)
    turnover = mf.get("turnover", 0)
    company_num = mf.get("company_num", 0)

    # Historical data
    h = hist.get(ts_code, {})

    # Limit counts (keyed by industry name, only for 881xxx)
    lc = limit_counts.get(name, {}) if board_type == "è¡Œä¸š" else {}

    # Up/down counts (keyed by ts_code)
    ud = up_down.get(ts_code, {})

    return {
        "rank": rank,
        "name": name,
        "code": ts_code,
        "boardType": board_type,
        "changePct": round(pct_change, 2),
        "changeValue": round(close, 2),
        "moneyInflow": round(net_amount, 2),
        "volumeRatio": 0,
        "upCount": ud.get("upCount", 0),
        "downCount": ud.get("downCount", 0),
        "limitUp": lc.get("limitUp", 0),
        "totalStocks": company_num,
        "turnover": round(turnover, 2),
        "volume": h.get("volume", round(vol / 10000, 2)),
        "day5Change": h.get("day5Change", 0),
        "day10Change": h.get("day10Change", 0),
        "day20Change": h.get("day20Change", 0),
    }


def update_data(service: TonghuashunService) -> None:
    """ä¸»æ›´æ–°é€»è¾‘ï¼šèŽ·å–è¡Œä¸š+æ¦‚å¿µæ··æŽ’ â†’ ç”Ÿæˆ JSONã€‚"""

    print(f"\n{'=' * 60}")
    print(f"å¼€å§‹æ›´æ–° â€” {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'=' * 60}")

    client = service.client
    trade_date = client.get_latest_trade_date()
    print(f"  äº¤æ˜“æ—¥: {trade_date}")

    # 1. Build name mapping
    print("\n[1/6] èŽ·å–æ¿å—åç§°æ˜ å°„...")
    name_map = _build_name_map(client)
    if not name_map:
        print("âš ï¸  åç§°æ˜ å°„ä¸ºç©ºï¼Œè·³è¿‡æœ¬æ¬¡æ›´æ–°")
        return

    # Reverse map: name â†’ ts_code (for watchlist lookup)
    reverse_map: Dict[str, str] = {v: k for k, v in name_map.items()}

    # 2. Fetch mixed daily (industry + concept)
    print("\n[2/6] èŽ·å– ths_daily æ··æŽ’æ•°æ®...")
    df_mixed = _fetch_mixed_daily(client, trade_date, name_map)
    if df_mixed.empty:
        print("âš ï¸  ths_daily æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡æœ¬æ¬¡æ›´æ–°")
        return

    n_industry = (df_mixed['board_type'] == 'è¡Œä¸š').sum()
    n_concept = (df_mixed['board_type'] == 'æ¦‚å¿µ').sum()
    print(f"  âœ“ å…± {len(df_mixed)} ä¸ªæ¿å— (è¡Œä¸š: {n_industry}, æ¦‚å¿µ: {n_concept})")

    # 3. Fetch moneyflow for 90 industries
    print("\n[3/6] èŽ·å–è¡Œä¸šèµ„é‡‘æµå‘ (90ä¸ªè¡Œä¸š)...")
    moneyflow = _fetch_moneyflow_map(client, trade_date)
    print(f"  âœ“ èŽ·å–åˆ° {len(moneyflow)} ä¸ªè¡Œä¸šçš„èµ„é‡‘æ•°æ®")

    # 4. Fetch limit-up/down counts
    print("\n[4/6] èŽ·å–æ¶¨è·Œåœç»Ÿè®¡...")
    limit_counts = _fetch_limit_counts(client, trade_date)
    print(f"  âœ“ èŽ·å–åˆ° {len(limit_counts)} ä¸ªè¡Œä¸šçš„æ¶¨è·Œåœæ•°æ®")

    # 5. Determine which codes need detailed data (TOP_N + watchlist)
    top_codes: List[str] = df_mixed.head(TOP_N)["ts_code"].tolist()
    watch_codes: List[str] = [reverse_map[n] for n in WATCH_NAMES if n in reverse_map]
    detail_codes: List[str] = list(dict.fromkeys(top_codes + watch_codes))  # dedupe, preserve order

    # 5a. Historical changes
    print(f"\n[5/6] èŽ·å–åŽ†å²æ¶¨è·Œæ•°æ® ({len(detail_codes)} ä¸ªæ¿å—)...")
    hist = _fetch_historical_changes(client, detail_codes)
    print(f"  âœ“ èŽ·å–åˆ° {len(hist)} ä¸ªæ¿å—çš„åŽ†å²æ•°æ®")

    # 5b. Up/down stock counts
    print(f"\n[6/6] èŽ·å–æ¶¨è·Œå®¶æ•° ({len(detail_codes)} ä¸ªæ¿å—)...")
    up_down = _fetch_up_down_counts(client, detail_codes, trade_date)
    print(f"  âœ“ èŽ·å–åˆ° {len(up_down)} ä¸ªæ¿å—çš„æ¶¨è·Œå®¶æ•°")

    # â”€â”€ Build output â”€â”€

    # Top N (mixed)
    df_top = df_mixed.head(TOP_N)
    top_data = []
    for idx, (_, row) in enumerate(df_top.iterrows(), start=1):
        top_data.append(_build_item(row, idx, moneyflow, hist, limit_counts, up_down))

    # Watch list
    watch_data = []
    for watch_name in WATCH_NAMES:
        matched = df_mixed[df_mixed["name"] == watch_name]
        if not matched.empty:
            row = matched.iloc[0]
            watch_data.append(
                _build_item(row, len(watch_data) + 1, moneyflow, hist, limit_counts, up_down)
            )
        else:
            print(f"  âš ï¸  è‡ªé€‰æ¦‚å¿µ '{watch_name}' æœªåœ¨æ··æŽ’æ•°æ®ä¸­æ‰¾åˆ°")

    # Re-rank watchlist
    for idx, item in enumerate(watch_data, start=1):
        item["rank"] = idx

    # Save JSON
    output = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "updateInterval": UPDATE_INTERVAL,
        "dataSource": "tonghuashun_mixed",
        "topConcepts": {
            "total": len(top_data),
            "data": top_data,
        },
        "watchConcepts": {
            "total": len(watch_data),
            "data": watch_data,
        },
    }

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ•°æ®å·²å†™å…¥: {OUTPUT_FILE}")
    print(f"   â€” æ¶¨å¹… TOP{TOP_N}: {len(top_data)} ä¸ª")
    print(f"   â€” è‡ªé€‰çƒ­é—¨: {len(watch_data)} ä¸ª")

    # Summary
    print(f"\nðŸ“Š æ¶¨å¹…å‰ 5:")
    for item in top_data[:5]:
        tag = f"[{item['boardType']}]"
        print(
            f"   {item['rank']:2d}. {tag:4s} {item['name']:12s}  "
            f"{item['changePct']:+6.2f}%  "
            f"å‡€æµå…¥: {item['moneyInflow']:+8.2f}äº¿  "
        )


def run_once(service: TonghuashunService) -> None:
    """å•æ¬¡è¿è¡Œã€‚"""
    print("è¿è¡Œæ¨¡å¼: å•æ¬¡æ›´æ–°")
    update_data(service)


def run_continuous(service: TonghuashunService) -> None:
    """æŒç»­è¿è¡Œæ¨¡å¼ã€‚"""
    print("=" * 60)
    print("ðŸš€ æ¿å—ç›‘æŽ§å¯åŠ¨ï¼ˆåŒèŠ±é¡ºæ··æŽ’: è¡Œä¸š+æ¦‚å¿µï¼‰")
    print("=" * 60)
    print(f"ç›‘æŽ§é…ç½®:")
    print(f"  â€” æ¶¨å¹…å‰ {TOP_N} è¡Œä¸š/æ¦‚å¿µï¼ˆæ··æŽ’ï¼‰")
    print(f"  â€” è‡ªé€‰çƒ­é—¨: {len(WATCH_NAMES)} ä¸ª")
    print(f"  â€” æ›´æ–°é—´éš”: {UPDATE_INTERVAL} ç§’ ({UPDATE_INTERVAL / 60:.1f} åˆ†é’Ÿ)")
    print(f"  â€” è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    print("=" * 60)

    iteration = 0
    while True:
        try:
            iteration += 1
            print(f"\nç¬¬ {iteration} è½®ç›‘æŽ§")
            update_data(service)
            print(f"\nâ° ç­‰å¾… {UPDATE_INTERVAL} ç§’...")
            time.sleep(UPDATE_INTERVAL)
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢ç›‘æŽ§")
            break
        except Exception as e:
            print(f"\nâŒ æ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            print("ç­‰å¾… 30 ç§’åŽé‡è¯•...")
            time.sleep(30)


if __name__ == "__main__":
    # Initialise service
    settings = get_settings()
    client = TushareClient(
        token=settings.tushare_token,
        points=settings.tushare_points,
    )
    svc = TonghuashunService(client=client)

    if len(sys.argv) > 1 and sys.argv[1] == "--once":
        run_once(svc)
    else:
        run_continuous(svc)
