#!/usr/bin/env python3
"""
æ¦‚å¿µæ¿å—èµ„é‡‘æµåˆ†æå™¨ v2
=============================
æ•°æ®æº: Tushare (moneyflow_ths + ths_member + ths_daily)
å£å¾„: Tushareä¸»åŠ› â‰ˆ åŒèŠ±é¡º Ã— 0.6
é—¨æ§›: â‰¥30äº¿å‡€æµå…¥

åŠŸèƒ½:
1. æ¦‚å¿µæ¿å—æˆåˆ†è‚¡ç¼“å­˜ (board_mappingè¡¨ï¼Œæ¯å¤©æ›´æ–°)
2. æ¦‚å¿µæ¿å—èµ„é‡‘æµèšåˆ (ä¸ªè‚¡moneyflow â†’ æ¦‚å¿µèšåˆ)
3. æ—¥åº¦å¯¹æ¯” (yesterday vs todayï¼ŒåŠ é€Ÿ/å‡é€Ÿåˆ¤æ–­)
4. å¤šæ—¥è¶‹åŠ¿ (3æ—¥/5æ—¥ç´¯è®¡ï¼Œè¶‹åŠ¿æ–¹å‘)
5. ç›˜ä¸­30åˆ†é’Ÿè½®åŠ¨å¿«ç…§å¯¹æ¯” (ä»·æ ¼å˜åŠ¨æ’åè½®åŠ¨æ£€æµ‹)

ç”¨æ³•:
  python scripts/concept_flow_analysis.py                    # å®Œæ•´åˆ†æ (ä»Šæ—¥)
  python scripts/concept_flow_analysis.py --date 20260203    # æŒ‡å®šæ—¥æœŸ
  python scripts/concept_flow_analysis.py --update-members   # ä»…æ›´æ–°æˆåˆ†è‚¡ç¼“å­˜
  python scripts/concept_flow_analysis.py --trend            # å«å¤šæ—¥è¶‹åŠ¿
  python scripts/concept_flow_analysis.py --json             # JSONè¾“å‡º (ä¾›API/cronä½¿ç”¨)
  python scripts/concept_flow_analysis.py --rotation         # ç›˜ä¸­è½®åŠ¨æ£€æµ‹
  python scripts/concept_flow_analysis.py --rotation --snapshot  # ä¿å­˜è½®åŠ¨å¿«ç…§
"""

import sys
import os
import json
import time
import argparse
from pathlib import Path
from datetime import datetime, timezone, timedelta

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import tushare as ts
import pandas as pd
from src.config import get_settings

# ============================================================
# Configuration
# ============================================================
FLOW_THRESHOLD = 30  # äº¿å…ƒ, æ¦‚å¿µæ¿å—èµ„é‡‘å‡€æµå…¥é—¨æ§›
TUSHARE_THS_COEFF = 0.6  # Tushare â‰ˆ åŒèŠ±é¡º Ã— 0.6
MEMBER_CACHE_FILE = project_root / "data" / "cache" / "concept_members.json"
FLOW_SNAPSHOT_DIR = project_root / "data" / "snapshots" / "concept_flow"
INTRADAY_SNAPSHOT_DIR = project_root / "data" / "snapshots" / "intraday"
ANALYSIS_OUTPUT_DIR = project_root / "data" / "analysis"

# Rotation detection thresholds
ROTATION_RANK_JUMP = 20       # æ’åè·³å‡â‰¥20ä½è§†ä¸ºæ˜¾è‘—è½®åŠ¨
ROTATION_TOP_N = 50           # åªå…³æ³¨æ’åå‰50çš„æ¦‚å¿µ

# Ensure dirs exist
MEMBER_CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)
FLOW_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
INTRADAY_SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)
ANALYSIS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def get_pro():
    settings = get_settings()
    return ts.pro_api(settings.tushare_token)


# ============================================================
# 1. Concept Membership Cache
# ============================================================
def load_member_cache() -> dict:
    """Load cached concept â†’ stock mapping"""
    if MEMBER_CACHE_FILE.exists():
        with open(MEMBER_CACHE_FILE, 'r') as f:
            data = json.load(f)
        return data
    return {}


def save_member_cache(data: dict):
    """Save concept â†’ stock mapping to cache"""
    with open(MEMBER_CACHE_FILE, 'w') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def update_member_cache(pro, force=False) -> dict:
    """
    Fetch concept members from Tushare and cache.
    Takes ~80 seconds for 395 concepts. Only run once daily.
    """
    cache = load_member_cache()
    today = datetime.now().strftime('%Y%m%d')

    if not force and cache.get('_updated') == today:
        print(f"âœ… æˆåˆ†è‚¡ç¼“å­˜å·²æ˜¯æœ€æ–° ({today}), è·³è¿‡æ›´æ–°", flush=True)
        return cache

    print(f"ğŸ”„ æ›´æ–°æ¦‚å¿µæ¿å—æˆåˆ†è‚¡ç¼“å­˜...", flush=True)

    # Get all concept boards
    df_concepts = pro.ths_index(exchange='A', type='N')
    concept_codes = df_concepts['ts_code'].tolist()
    name_map = dict(zip(df_concepts['ts_code'], df_concepts['name']))

    members = {}
    errors = 0
    total = len(concept_codes)

    for i, code in enumerate(concept_codes):
        try:
            df = pro.ths_member(ts_code=code)
            if df is not None and len(df) > 0:
                members[code] = {
                    'name': name_map.get(code, ''),
                    'stocks': df['con_code'].tolist()
                }
            time.sleep(0.12)
        except Exception:
            errors += 1
            time.sleep(0.5)

        if (i + 1) % 50 == 0:
            print(f"  [{i+1}/{total}] å¤±è´¥{errors}", flush=True)

    members['_updated'] = today
    members['_count'] = len([k for k in members if not k.startswith('_')])
    save_member_cache(members)

    print(f"âœ… æˆåˆ†è‚¡ç¼“å­˜æ›´æ–°å®Œæˆ: {members['_count']}ä¸ªæ¦‚å¿µ, å¤±è´¥{errors}", flush=True)
    return members


# ============================================================
# 2. Concept Flow Aggregation
# ============================================================
def fetch_concept_flow(pro, trade_date: str, members: dict) -> pd.DataFrame:
    """
    Aggregate stock-level moneyflow to concept-level.
    
    Returns DataFrame with columns:
        ts_code, name, net_inflow (äº¿), pct_change, member_count, vol
    """
    # Get stock moneyflow (all stocks, one call)
    df_flow = pro.moneyflow_ths(trade_date=trade_date)
    if df_flow is None or len(df_flow) == 0:
        print(f"âš ï¸ æ— ä¸ªè‚¡èµ„é‡‘æµæ•°æ®: {trade_date}", flush=True)
        return pd.DataFrame()
    
    flow_map = dict(zip(df_flow['ts_code'], df_flow['net_amount']))  # ä¸‡å…ƒ

    # Get concept daily prices
    df_daily = pro.ths_daily(trade_date=trade_date)
    if df_daily is None or len(df_daily) == 0:
        print(f"âš ï¸ æ— æ¦‚å¿µæ—¥çº¿æ•°æ®: {trade_date}", flush=True)
        return pd.DataFrame()

    # Get concept list for filtering
    df_concepts = pro.ths_index(exchange='A', type='N')
    concept_codes = set(df_concepts['ts_code'])
    name_map_ts = dict(zip(df_concepts['ts_code'], df_concepts['name']))

    # Filter daily to concepts only
    df_cd = df_daily[df_daily['ts_code'].isin(concept_codes)].copy()

    # Aggregate moneyflow by concept
    results = []
    for _, row in df_cd.iterrows():
        code = row['ts_code']
        member_info = members.get(code)
        if not member_info or isinstance(member_info, str):
            continue

        stocks = member_info.get('stocks', [])
        total_net = sum(flow_map.get(s, 0) for s in stocks) / 10000  # ä¸‡å…ƒ â†’ äº¿å…ƒ

        results.append({
            'ts_code': code,
            'name': member_info.get('name', name_map_ts.get(code, '')),
            'net_inflow': round(total_net, 1),
            'pct_change': round(row['pct_change'], 2),
            'member_count': len(stocks),
            'vol': row.get('vol', 0),
            'trade_date': trade_date,
        })

    df = pd.DataFrame(results)
    if len(df) > 0:
        df = df.sort_values('net_inflow', ascending=False).reset_index(drop=True)
    return df


def save_flow_snapshot(df: pd.DataFrame, trade_date: str, label: str = "close"):
    """Save a flow snapshot to disk for later comparison"""
    filepath = FLOW_SNAPSHOT_DIR / f"{trade_date}_{label}.json"
    records = df.to_dict(orient='records')
    with open(filepath, 'w') as f:
        json.dump({
            'trade_date': trade_date,
            'label': label,
            'timestamp': datetime.now().isoformat(),
            'count': len(records),
            'data': records
        }, f, ensure_ascii=False, indent=2)
    return filepath


def load_flow_snapshot(trade_date: str, label: str = "close") -> pd.DataFrame:
    """Load a previously saved snapshot"""
    filepath = FLOW_SNAPSHOT_DIR / f"{trade_date}_{label}.json"
    if not filepath.exists():
        return pd.DataFrame()
    with open(filepath, 'r') as f:
        data = json.load(f)
    return pd.DataFrame(data['data'])


# ============================================================
# 3. Day-over-Day Comparison
# ============================================================
def compare_days(today_df: pd.DataFrame, yesterday_df: pd.DataFrame) -> list[dict]:
    """
    Compare two days of concept flow data.
    Detect acceleration/deceleration in moneyflow.
    
    Returns list of dicts with:
        name, today_flow, yesterday_flow, flow_delta, flow_trend,
        today_pct, yesterday_pct, pct_delta
    """
    if today_df.empty or yesterday_df.empty:
        return []

    # Merge on ts_code
    merged = today_df.merge(
        yesterday_df[['ts_code', 'net_inflow', 'pct_change']],
        on='ts_code',
        how='left',
        suffixes=('_today', '_yesterday')
    )

    comparisons = []
    for _, row in merged.iterrows():
        today_flow = row.get('net_inflow_today', row.get('net_inflow', 0))
        yesterday_flow = row.get('net_inflow_yesterday', 0)

        if pd.isna(yesterday_flow):
            yesterday_flow = 0

        flow_delta = today_flow - yesterday_flow
        today_pct = row.get('pct_change_today', row.get('pct_change', 0))
        yesterday_pct = row.get('pct_change_yesterday', 0)

        if pd.isna(yesterday_pct):
            yesterday_pct = 0

        # Determine trend
        if today_flow >= FLOW_THRESHOLD:
            if yesterday_flow > 0 and today_flow > yesterday_flow * 1.3:
                trend = "ğŸš€åŠ é€Ÿ"
            elif yesterday_flow > 0 and today_flow > yesterday_flow:
                trend = "ğŸ“ˆå¢é•¿"
            elif yesterday_flow <= 0 and today_flow > 0:
                trend = "ğŸ”„è½¬æ­£"
            elif yesterday_flow > 0 and today_flow < yesterday_flow * 0.7:
                trend = "âš ï¸å‡é€Ÿ"
            elif yesterday_flow > 0:
                trend = "â¡ï¸æŒå¹³"
            else:
                trend = "ğŸ†•æ–°è¿›"
        else:
            if yesterday_flow >= FLOW_THRESHOLD and today_flow < FLOW_THRESHOLD:
                trend = "ğŸ“‰è·Œå‡º"
            else:
                trend = ""

        comparisons.append({
            'ts_code': row['ts_code'],
            'name': row['name'],
            'today_flow': today_flow,
            'yesterday_flow': yesterday_flow,
            'flow_delta': round(flow_delta, 1),
            'trend': trend,
            'today_pct': today_pct,
            'yesterday_pct': yesterday_pct,
            'member_count': row.get('member_count', 0),
        })

    # Sort by today's flow
    comparisons.sort(key=lambda x: x['today_flow'], reverse=True)
    return comparisons


# ============================================================
# 4. Multi-day Trend (3-day / 5-day)
# ============================================================
def compute_multi_day_trend(pro, members: dict, target_date: str, days: int = 5) -> pd.DataFrame:
    """
    Compute multi-day flow trend for concept boards.
    Fetches data for last N trading days and computes:
    - Cumulative flow
    - Trend direction (accelerating/decelerating/stable)
    - Consecutive days of inflow/outflow
    """
    # Get trading calendar
    cal = pro.trade_cal(exchange='SSE', start_date='20260101', end_date=target_date)
    trade_dates = cal[cal['is_open'] == 1]['cal_date'].sort_values(ascending=False).head(days + 1).tolist()
    
    if len(trade_dates) < 2:
        return pd.DataFrame()

    # Load or fetch data for each date
    all_data = {}
    for date in trade_dates[:days]:
        # Try loading snapshot first
        df = load_flow_snapshot(date)
        if df.empty:
            print(f"  ğŸ“¥ è·å– {date} æ•°æ®...", flush=True)
            df = fetch_concept_flow(pro, date, members)
            if not df.empty:
                save_flow_snapshot(df, date)
            time.sleep(0.5)
        if not df.empty:
            all_data[date] = df

    if len(all_data) < 2:
        return pd.DataFrame()

    # Build trend for each concept
    dates_sorted = sorted(all_data.keys())
    all_concepts = set()
    for df in all_data.values():
        all_concepts.update(df['ts_code'].tolist())

    trends = []
    for code in all_concepts:
        daily_flows = []
        daily_pcts = []
        name = ''
        member_count = 0

        for date in dates_sorted:
            df = all_data[date]
            row = df[df['ts_code'] == code]
            if len(row) > 0:
                daily_flows.append(row.iloc[0]['net_inflow'])
                daily_pcts.append(row.iloc[0]['pct_change'])
                name = row.iloc[0]['name']
                member_count = row.iloc[0].get('member_count', 0)
            else:
                daily_flows.append(0)
                daily_pcts.append(0)

        cum_flow = sum(daily_flows)
        avg_flow = cum_flow / len(daily_flows) if daily_flows else 0
        cum_pct = sum(daily_pcts)

        # Trend direction: compare recent half vs older half
        mid = len(daily_flows) // 2
        recent_avg = sum(daily_flows[mid:]) / max(len(daily_flows[mid:]), 1)
        older_avg = sum(daily_flows[:mid]) / max(len(daily_flows[:mid]), 1)

        if recent_avg > older_avg * 1.3 and cum_flow > 0:
            direction = "ğŸ“ˆåŠ é€Ÿ"
        elif recent_avg < older_avg * 0.7 and older_avg > 0:
            direction = "ğŸ“‰å‡é€Ÿ"
        elif cum_flow > 0:
            direction = "â¡ï¸ç¨³å®š"
        else:
            direction = "ğŸ”»æµå‡º"

        # Consecutive inflow days
        consec = 0
        for f in reversed(daily_flows):
            if f > 0:
                consec += 1
            else:
                break

        trends.append({
            'ts_code': code,
            'name': name,
            'cum_flow': round(cum_flow, 1),
            'avg_flow': round(avg_flow, 1),
            'cum_pct': round(cum_pct, 2),
            'direction': direction,
            'consec_inflow_days': consec,
            'daily_flows': [round(f, 1) for f in daily_flows],
            'dates': dates_sorted,
            'member_count': member_count,
        })

    df_trend = pd.DataFrame(trends)
    df_trend = df_trend.sort_values('cum_flow', ascending=False).reset_index(drop=True)
    return df_trend


# ============================================================
# 5. Intraday Rotation Detection (30-min snapshots)
# ============================================================
# NOTE: Tushare moneyflow is daily-only. Intraday rotation uses
# PRICE CHANGE rankings from ths_daily (æ¦‚å¿µæŒ‡æ•°æ¶¨è·Œå¹…æ’å).
# Also tries the local API concept-monitor for realtime data.

def fetch_concept_price_rankings(pro, trade_date: str = None) -> pd.DataFrame:
    """
    Get concept board price change rankings.
    Uses ths_daily for all concept boards.
    
    Returns DataFrame: ts_code, name, pct_change, close, vol, rank
    """
    if trade_date is None:
        trade_date = datetime.now().strftime('%Y%m%d')

    # Try local API first (realtime during market hours)
    try:
        import requests
        r = requests.get(
            'http://127.0.0.1:8000/api/concept-monitor/top',
            params={'limit': 500},
            timeout=5
        )
        if r.status_code == 200:
            data = r.json()
            items = data.get('data', [])
            # Filter to concept boards only (exclude industry boards)
            concepts = [x for x in items if x.get('boardType') == 'æ¦‚å¿µ']
            if len(concepts) >= 10:
                df = pd.DataFrame(concepts)
                df = df.rename(columns={'code': 'ts_code', 'changePct': 'pct_change'})
                df = df.sort_values('pct_change', ascending=False).reset_index(drop=True)
                df['rank'] = range(1, len(df) + 1)
                return df[['ts_code', 'name', 'pct_change', 'rank',
                           'volume', 'upCount', 'downCount', 'limitUp']]
    except Exception:
        pass

    # Fallback: Tushare ths_daily (all concept boards)
    df_daily = pro.ths_daily(trade_date=trade_date)
    if df_daily is None or len(df_daily) == 0:
        return pd.DataFrame()

    # Filter to concept boards (N type)
    df_concepts = pro.ths_index(exchange='A', type='N')
    concept_codes = set(df_concepts['ts_code'])
    name_map = dict(zip(df_concepts['ts_code'], df_concepts['name']))

    df = df_daily[df_daily['ts_code'].isin(concept_codes)].copy()
    df['name'] = df['ts_code'].map(name_map)
    df = df.sort_values('pct_change', ascending=False).reset_index(drop=True)
    df['rank'] = range(1, len(df) + 1)
    return df[['ts_code', 'name', 'pct_change', 'close', 'vol', 'rank']]


def save_intraday_snapshot(df: pd.DataFrame, label: str = None) -> Path:
    """
    Save an intraday price ranking snapshot.
    Label format: YYYYMMDD_HHMM (e.g., 20260203_1030)
    """
    if label is None:
        label = datetime.now().strftime('%Y%m%d_%H%M')

    filepath = INTRADAY_SNAPSHOT_DIR / f"rotation_{label}.json"
    records = df.to_dict(orient='records')
    with open(filepath, 'w') as f:
        json.dump({
            'label': label,
            'timestamp': datetime.now().isoformat(),
            'count': len(records),
            'data': records,
        }, f, ensure_ascii=False, indent=2)
    return filepath


def load_intraday_snapshot(label: str) -> pd.DataFrame:
    """Load a previously saved intraday snapshot."""
    filepath = INTRADAY_SNAPSHOT_DIR / f"rotation_{label}.json"
    if not filepath.exists():
        return pd.DataFrame()
    with open(filepath, 'r') as f:
        data = json.load(f)
    return pd.DataFrame(data['data'])


def get_previous_snapshot_label() -> str | None:
    """Find the most recent intraday snapshot for today."""
    today_prefix = datetime.now().strftime('%Y%m%d')
    snapshots = sorted(INTRADAY_SNAPSHOT_DIR.glob(f"rotation_{today_prefix}_*.json"),
                       reverse=True)
    if not snapshots:
        return None
    # Extract label from filename: rotation_YYYYMMDD_HHMM.json â†’ YYYYMMDD_HHMM
    return snapshots[0].stem.replace('rotation_', '')


def detect_rotation(current_df: pd.DataFrame, previous_df: pd.DataFrame,
                    top_n: int = ROTATION_TOP_N,
                    rank_jump: int = ROTATION_RANK_JUMP) -> dict:
    """
    Compare two snapshots and detect rotation signals.
    
    A rotation signal is a concept that jumped significantly in rank,
    indicating capital is rotating into/out of it.
    
    Args:
        current_df: Current snapshot with 'ts_code', 'name', 'pct_change', 'rank'
        previous_df: Previous snapshot with same columns
        top_n: Only consider concepts in current top N
        rank_jump: Minimum rank improvement to flag as rotation
        
    Returns:
        dict with 'rising' (moved up), 'falling' (moved down), 'new_entrants', 'summary'
    """
    if current_df.empty or previous_df.empty:
        return {'rising': [], 'falling': [], 'new_entrants': [], 'summary': {}}

    # Build rank maps
    curr_ranks = dict(zip(current_df['ts_code'], current_df['rank']))
    prev_ranks = dict(zip(previous_df['ts_code'], previous_df['rank']))
    curr_names = dict(zip(current_df['ts_code'], current_df['name']))
    curr_pcts = dict(zip(current_df['ts_code'], current_df['pct_change']))
    prev_pcts = dict(zip(previous_df['ts_code'], previous_df['pct_change']))

    rising = []
    falling = []
    new_entrants = []

    for code, curr_rank in curr_ranks.items():
        if curr_rank > top_n:
            continue

        name = curr_names.get(code, '')
        curr_pct = curr_pcts.get(code, 0)
        prev_pct = prev_pcts.get(code, 0)

        if code not in prev_ranks:
            # New entrant to the rankings
            new_entrants.append({
                'ts_code': code,
                'name': name,
                'rank': curr_rank,
                'pct_change': curr_pct,
            })
            continue

        prev_rank = prev_ranks[code]
        rank_delta = prev_rank - curr_rank  # positive = moved up

        if rank_delta >= rank_jump:
            rising.append({
                'ts_code': code,
                'name': name,
                'prev_rank': prev_rank,
                'curr_rank': curr_rank,
                'rank_delta': rank_delta,
                'pct_change': curr_pct,
                'prev_pct': prev_pct,
                'pct_delta': round(curr_pct - prev_pct, 2),
            })
        elif rank_delta <= -rank_jump:
            falling.append({
                'ts_code': code,
                'name': name,
                'prev_rank': prev_rank,
                'curr_rank': curr_rank,
                'rank_delta': rank_delta,
                'pct_change': curr_pct,
                'prev_pct': prev_pct,
                'pct_delta': round(curr_pct - prev_pct, 2),
            })

    # Sort by magnitude of rank change
    rising.sort(key=lambda x: x['rank_delta'], reverse=True)
    falling.sort(key=lambda x: x['rank_delta'])

    return {
        'rising': rising,
        'falling': falling,
        'new_entrants': new_entrants,
        'summary': {
            'current_snapshot_count': len(current_df),
            'previous_snapshot_count': len(previous_df),
            'rising_count': len(rising),
            'falling_count': len(falling),
            'new_entrant_count': len(new_entrants),
        },
    }


def format_rotation(rotation: dict, label: str = '') -> str:
    """Format rotation detection results for Telegram."""
    lines = []
    now_str = label or datetime.now().strftime('%H:%M')
    lines.append(f"ğŸ”„ **ç›˜ä¸­è½®åŠ¨æ£€æµ‹** ({now_str})")

    rising = rotation.get('rising', [])
    falling = rotation.get('falling', [])
    new_entrants = rotation.get('new_entrants', [])
    summary = rotation.get('summary', {})

    if not rising and not falling and not new_entrants:
        lines.append("æ— æ˜¾è‘—è½®åŠ¨ä¿¡å·")
        return '\n'.join(lines)

    lines.append(f"æ’åè·³å‡â‰¥{ROTATION_RANK_JUMP}ä½ | "
                 f"ğŸ”º{summary.get('rising_count', 0)} "
                 f"ğŸ”»{summary.get('falling_count', 0)} "
                 f"ğŸ†•{summary.get('new_entrant_count', 0)}")
    lines.append("")

    if rising:
        lines.append("**ğŸ”º èµ„é‡‘è½®å…¥ï¼ˆæ’åå¤§å¹…ä¸Šå‡ï¼‰:**")
        for r in rising[:8]:
            lines.append(f"â€¢ {r['name']} "
                         f"#{r['prev_rank']}â†’#{r['curr_rank']} (â†‘{r['rank_delta']}ä½) "
                         f"{r['pct_change']:+.2f}%")
        lines.append("")

    if falling:
        lines.append("**ğŸ”» èµ„é‡‘è½®å‡ºï¼ˆæ’åå¤§å¹…ä¸‹é™ï¼‰:**")
        for f in falling[:5]:
            lines.append(f"â€¢ {f['name']} "
                         f"#{f['prev_rank']}â†’#{f['curr_rank']} (â†“{abs(f['rank_delta'])}ä½) "
                         f"{f['pct_change']:+.2f}%")
        lines.append("")

    if new_entrants:
        top_new = sorted(new_entrants, key=lambda x: x['rank'])[:5]
        lines.append("**ğŸ†• æ–°è¿›å‰50:**")
        for n in top_new:
            lines.append(f"â€¢ {n['name']} #{n['rank']} ({n['pct_change']:+.2f}%)")
        lines.append("")

    return '\n'.join(lines)


def run_rotation_detection(pro, save_snapshot: bool = True) -> tuple[dict, str]:
    """
    Run a full rotation detection cycle:
    1. Fetch current concept price rankings
    2. Load previous snapshot (if any)
    3. Compare and detect rotation
    4. Save current snapshot
    
    Returns: (rotation_dict, formatted_text)
    """
    # 1. Get current rankings
    current_df = fetch_concept_price_rankings(pro)
    if current_df.empty:
        return {}, "âš ï¸ æ— æ³•è·å–æ¦‚å¿µæ’åæ•°æ®"

    # 2. Load previous snapshot
    prev_label = get_previous_snapshot_label()
    previous_df = pd.DataFrame()
    if prev_label:
        previous_df = load_intraday_snapshot(prev_label)

    # 3. Save current snapshot
    current_label = datetime.now().strftime('%Y%m%d_%H%M')
    if save_snapshot:
        save_intraday_snapshot(current_df, current_label)

    # 4. Detect rotation
    if previous_df.empty:
        return {
            'rising': [], 'falling': [], 'new_entrants': [],
            'summary': {'note': 'é¦–æ¬¡å¿«ç…§ï¼Œæ— å¯¹æ¯”æ•°æ®'},
        }, f"ğŸ“¸ é¦–æ¬¡è½®åŠ¨å¿«ç…§å·²ä¿å­˜ ({current_label}), å…±{len(current_df)}ä¸ªæ¦‚å¿µ"

    rotation = detect_rotation(current_df, previous_df)
    text = format_rotation(rotation, label=f"{prev_label.split('_')[-1]}â†’{current_label.split('_')[-1]}")
    return rotation, text


# ============================================================
# 6. Formatted Output
# ============================================================
def format_analysis(
    flow_df: pd.DataFrame,
    comparisons: list[dict] = None,
    trend_df: pd.DataFrame = None,
    trade_date: str = "",
    label: str = ""
) -> str:
    """Generate formatted analysis text for Telegram"""
    lines = []
    
    if not label:
        label = trade_date

    # Header
    passed = flow_df[flow_df['net_inflow'] >= FLOW_THRESHOLD] if not flow_df.empty else pd.DataFrame()
    total = len(flow_df)
    lines.append(f"ğŸ“Š **æ¦‚å¿µæ¿å—èµ„é‡‘æµåˆ†æ** ({label})")
    lines.append(f"Tushareèšåˆ | â‰¥{FLOW_THRESHOLD}äº¿é—¨æ§› | **{len(passed)}/{total}** é€šè¿‡")
    lines.append("")

    # === Section 1: Top by flow ===
    # Filter out index-like concepts (èèµ„èåˆ¸, æ·±è‚¡é€š, etc.)
    index_keywords = ['èèµ„èåˆ¸', 'æ·±è‚¡é€š', 'æ²ªè‚¡é€š', 'æˆä»½è‚¡', 'æ ·æœ¬è‚¡', 'ä¸­ç‰¹ä¼°', 'åŒèŠ±é¡ºæ¼‚äº®', 'åŒèŠ±é¡ºæœ', 'åŒèŠ±é¡ºå‡ºæµ·']
    
    def is_thematic(name):
        return not any(kw in name for kw in index_keywords)
    
    thematic = passed[passed['name'].apply(is_thematic)] if not passed.empty else pd.DataFrame()
    
    lines.append(f"**ğŸ”¥ èµ„é‡‘ TOP 20ï¼ˆä¸»é¢˜æ¦‚å¿µï¼‰:**")
    for i, (_, row) in enumerate(thematic.head(20).iterrows(), 1):
        lines.append(f"{i}. **{row['name']}** +{row['net_inflow']:.0f}äº¿ | {row['pct_change']:+.2f}% | {row['member_count']}åª")
    lines.append("")

    # === Section 2: æ¶¨å¹…+èµ„é‡‘åŒå¼º ===
    if not passed.empty:
        dual_strong = passed[(passed['pct_change'] >= 4) & passed['name'].apply(is_thematic)]
        if not dual_strong.empty:
            dual_strong = dual_strong.sort_values('pct_change', ascending=False)
            lines.append("**ğŸ¯ æ¶¨å¹…+èµ„é‡‘åŒå¼ºï¼ˆæ¶¨å¹…>4% ä¸” â‰¥30äº¿ï¼‰:**")
            for _, row in dual_strong.iterrows():
                lines.append(f"â€¢ {row['name']} {row['pct_change']:+.2f}% / {row['net_inflow']:.0f}äº¿")
            lines.append("")

    # === Section 3: Day-over-Day Comparison ===
    if comparisons:
        # Show accelerating concepts
        accel = [c for c in comparisons if 'åŠ é€Ÿ' in c.get('trend', '') and c['today_flow'] >= FLOW_THRESHOLD]
        if accel:
            lines.append("**ğŸš€ èµ„é‡‘åŠ é€Ÿæµå…¥ï¼ˆä»Šæ—¥>æ˜¨æ—¥Ã—1.3ï¼‰:**")
            for c in accel[:10]:
                lines.append(f"â€¢ {c['name']}: {c['yesterday_flow']:+.0f}äº¿â†’{c['today_flow']:+.0f}äº¿ ({c['flow_delta']:+.0f})")
            lines.append("")

        # Show reversals (turned positive)
        turns = [c for c in comparisons if 'è½¬æ­£' in c.get('trend', '')]
        if turns:
            lines.append("**ğŸ”„ èµ„é‡‘è½¬æ­£ï¼ˆæ˜¨æ—¥æµå‡ºâ†’ä»Šæ—¥æµå…¥ï¼‰:**")
            for c in turns[:5]:
                lines.append(f"â€¢ {c['name']}: {c['yesterday_flow']:+.0f}äº¿â†’{c['today_flow']:+.0f}äº¿")
            lines.append("")

        # Show decelerating
        decel = [c for c in comparisons if 'å‡é€Ÿ' in c.get('trend', '') and c['today_flow'] >= FLOW_THRESHOLD]
        if decel:
            lines.append("**âš ï¸ èµ„é‡‘å‡é€Ÿï¼ˆä»Šæ—¥<æ˜¨æ—¥Ã—0.7ï¼‰:**")
            for c in decel[:5]:
                lines.append(f"â€¢ {c['name']}: {c['yesterday_flow']:+.0f}äº¿â†’{c['today_flow']:+.0f}äº¿ ({c['flow_delta']:+.0f})")
            lines.append("")

    # === Section 4: Multi-day Trend ===
    if trend_df is not None and not trend_df.empty:
        n_days = len(trend_df.iloc[0]['dates']) if len(trend_df) > 0 else 0
        thematic_trends = trend_df[trend_df['name'].apply(is_thematic)]

        # 4a: Accelerating concepts (recent half > older half by 30%+)
        accel_trends = thematic_trends[
            thematic_trends['direction'].str.contains('åŠ é€Ÿ')
        ].nlargest(10, 'cum_flow')
        
        if not accel_trends.empty:
            lines.append(f"**ğŸ“Š {n_days}æ—¥è¶‹åŠ¿ â€” èµ„é‡‘åŠ é€Ÿ:**")
            for _, row in accel_trends.iterrows():
                flow_str = 'â†’'.join([f"{f:+.0f}" for f in row['daily_flows']])
                lines.append(f"â€¢ {row['name']} {row['direction']} ç´¯è®¡{row['cum_flow']:+.0f}äº¿ ({flow_str})")
            lines.append("")

        # 4b: Sustained inflow (consecutive days >= 2)
        sustained = thematic_trends[
            (thematic_trends['consec_inflow_days'] >= 2) &
            (thematic_trends['cum_flow'] > 0)
        ].nlargest(10, 'cum_flow')

        if not sustained.empty:
            lines.append(f"**ğŸ”„ è¿ç»­æµå…¥ï¼ˆâ‰¥2æ—¥ï¼‰:**")
            for _, row in sustained.iterrows():
                flow_str = 'â†’'.join([f"{f:+.0f}" for f in row['daily_flows']])
                lines.append(f"â€¢ {row['name']} è¿ç»­{row['consec_inflow_days']}æ—¥ ç´¯è®¡{row['cum_flow']:+.0f}äº¿ ({flow_str})")
            lines.append("")

        # 4c: Decelerating - were strong, now weakening
        decel_trends = thematic_trends[
            thematic_trends['direction'].str.contains('å‡é€Ÿ')
        ].nlargest(5, 'cum_flow')

        if not decel_trends.empty:
            lines.append(f"**âš ï¸ {n_days}æ—¥è¶‹åŠ¿ â€” èµ„é‡‘å‡é€Ÿ:**")
            for _, row in decel_trends.iterrows():
                flow_str = 'â†’'.join([f"{f:+.0f}" for f in row['daily_flows']])
                lines.append(f"â€¢ {row['name']} {row['direction']} ç´¯è®¡{row['cum_flow']:+.0f}äº¿ ({flow_str})")
            lines.append("")

    # === Section 5: Net outflow ===
    outflow = flow_df[flow_df['net_inflow'] < 0] if not flow_df.empty else pd.DataFrame()
    if not outflow.empty:
        lines.append(f"**ğŸ”» å‡€æµå‡º ({len(outflow)}ä¸ª):**")
        for _, row in outflow.head(5).iterrows():
            lines.append(f"â€¢ {row['name']} {row['net_inflow']:+.1f}äº¿ ({row['pct_change']:+.2f}%)")
        lines.append("")

    # === Section 6: Summary stats ===
    if not flow_df.empty:
        total_pass_flow = passed['net_inflow'].sum() if not passed.empty else 0
        n_outflow = len(outflow)
        lines.append(f"ğŸ“ˆ **æ±‡æ€»:** {len(passed)}æ¦‚å¿µè¿‡é—¨æ§› | å‡€æµå‡º{n_outflow}ä¸ª | è¿‡é—¨æ§›æ€»è®¡{total_pass_flow:.0f}äº¿")

    return '\n'.join(lines)


# ============================================================
# 6. Main Logic
# ============================================================
def get_prev_trade_date(pro, date: str) -> str:
    """Get the previous trading date"""
    cal = pro.trade_cal(exchange='SSE', start_date='20250101', end_date=date)
    trade_dates = cal[(cal['is_open'] == 1) & (cal['cal_date'] < date)]['cal_date'].sort_values(ascending=False)
    return trade_dates.iloc[0] if len(trade_dates) > 0 else ''


def main():
    parser = argparse.ArgumentParser(description='æ¦‚å¿µæ¿å—èµ„é‡‘æµåˆ†æ')
    parser.add_argument('--date', default=None, help='äº¤æ˜“æ—¥æœŸ YYYYMMDD')
    parser.add_argument('--update-members', action='store_true', help='å¼ºåˆ¶æ›´æ–°æˆåˆ†è‚¡ç¼“å­˜')
    parser.add_argument('--trend', action='store_true', help='åŒ…å«å¤šæ—¥è¶‹åŠ¿åˆ†æ')
    parser.add_argument('--trend-days', type=int, default=5, help='è¶‹åŠ¿å¤©æ•° (é»˜è®¤5)')
    parser.add_argument('--json', action='store_true', help='JSONæ ¼å¼è¾“å‡º')
    parser.add_argument('--compare', action='store_true', help='åŒ…å«æ—¥åº¦å¯¹æ¯”')
    parser.add_argument('--full', action='store_true', help='å®Œæ•´åˆ†æ (å¯¹æ¯”+è¶‹åŠ¿)')
    parser.add_argument('--save', action='store_true', help='ä¿å­˜å¿«ç…§åˆ°æ–‡ä»¶')
    parser.add_argument('--rotation', action='store_true', help='ç›˜ä¸­è½®åŠ¨æ£€æµ‹')
    parser.add_argument('--snapshot', action='store_true', help='ä¿å­˜è½®åŠ¨å¿«ç…§ (é…åˆ--rotation)')
    args = parser.parse_args()

    if args.full:
        args.compare = True
        args.trend = True

    pro = get_pro()

    # Handle rotation detection (standalone mode)
    if args.rotation:
        rotation_result, rotation_text = run_rotation_detection(pro, save_snapshot=args.snapshot)
        print(rotation_text)
        if args.json:
            print(json.dumps(rotation_result, ensure_ascii=False, indent=2))
        return 0

    # Determine trade date
    if args.date:
        trade_date = args.date
    else:
        # Latest trade date
        cal = pro.trade_cal(exchange='SSE', start_date='20260101')
        today = datetime.now().strftime('%Y%m%d')
        open_dates = cal[(cal['is_open'] == 1) & (cal['cal_date'] <= today)]['cal_date'].sort_values(ascending=False)
        trade_date = open_dates.iloc[0] if len(open_dates) > 0 else today

    print(f"ğŸ“… åˆ†ææ—¥æœŸ: {trade_date}", flush=True)

    # Step 1: Ensure member cache
    members = load_member_cache()
    if not members or members.get('_count', 0) == 0 or args.update_members:
        members = update_member_cache(pro, force=args.update_members)
    else:
        print(f"âœ… ä½¿ç”¨æˆåˆ†è‚¡ç¼“å­˜ (æ›´æ–°äº: {members.get('_updated', 'unknown')}, {members.get('_count', 0)}ä¸ªæ¦‚å¿µ)", flush=True)

    # Step 2: Fetch today's flow
    print(f"ğŸ“Š è·å– {trade_date} èµ„é‡‘æµ...", flush=True)
    today_df = load_flow_snapshot(trade_date)
    if today_df.empty:
        today_df = fetch_concept_flow(pro, trade_date, members)
        if not today_df.empty and args.save:
            save_flow_snapshot(today_df, trade_date)
            print(f"ğŸ’¾ å¿«ç…§å·²ä¿å­˜", flush=True)

    if today_df.empty:
        print(f"âŒ æ— æ³•è·å– {trade_date} æ•°æ®", flush=True)
        return 1

    # Step 3: Day-over-day comparison
    comparisons = None
    if args.compare:
        prev_date = get_prev_trade_date(pro, trade_date)
        if prev_date:
            print(f"ğŸ“Š è·å– {prev_date} æ•°æ®åšå¯¹æ¯”...", flush=True)
            yesterday_df = load_flow_snapshot(prev_date)
            if yesterday_df.empty:
                yesterday_df = fetch_concept_flow(pro, prev_date, members)
                if not yesterday_df.empty:
                    save_flow_snapshot(yesterday_df, prev_date)
            
            if not yesterday_df.empty:
                comparisons = compare_days(today_df, yesterday_df)
                print(f"âœ… æ—¥åº¦å¯¹æ¯”å®Œæˆ ({prev_date} vs {trade_date})", flush=True)

    # Step 4: Multi-day trend
    trend_df = None
    if args.trend:
        print(f"ğŸ“Š è®¡ç®— {args.trend_days} æ—¥è¶‹åŠ¿...", flush=True)
        trend_df = compute_multi_day_trend(pro, members, trade_date, args.trend_days)
        if trend_df is not None and not trend_df.empty:
            print(f"âœ… è¶‹åŠ¿åˆ†æå®Œæˆ ({len(trend_df)} æ¦‚å¿µ)", flush=True)

    # Step 5: Output
    if args.json:
        output = {
            'trade_date': trade_date,
            'timestamp': datetime.now().isoformat(),
            'threshold': FLOW_THRESHOLD,
            'total_concepts': len(today_df),
            'passed_threshold': len(today_df[today_df['net_inflow'] >= FLOW_THRESHOLD]),
            'flow_data': today_df.to_dict(orient='records'),
        }
        if comparisons:
            output['comparisons'] = comparisons
        if trend_df is not None and not trend_df.empty:
            output['trends'] = trend_df.to_dict(orient='records')
        
        output_file = ANALYSIS_OUTPUT_DIR / f"concept_flow_{trade_date}.json"
        with open(output_file, 'w') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ JSONè¾“å‡º: {output_file}", flush=True)
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        text = format_analysis(
            today_df, comparisons, trend_df,
            trade_date=trade_date,
            label=trade_date
        )
        print("\n" + text)

    return 0


if __name__ == '__main__':
    sys.exit(main())
