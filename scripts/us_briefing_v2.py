#!/usr/bin/env python3
"""
ç¾è‚¡ç®€æŠ¥ v3 â€” å®Œæ•´ç‰ˆï¼ˆæ¨¡å—åŒ– + è§„åˆ™å¼•æ“åˆ†æ + ç›˜åæ€»ç»“ï¼‰
=============================================
ç”¨æ³•: python scripts/us_briefing_v2.py [--time]

æ¨¡å—:
1.  ä¸‰å¤§æŒ‡æ•° + VIX             â€” /api/us-stock/indexes
2.  æ¿å—è¡¨ç°ï¼ˆETF + å¹¿åº¦ï¼‰      â€” /api/us-stock/sectors
3.  Mag7 ä¸ƒå·¨å¤´                â€” /api/us-stock/mag7
4.  ä¸­æ¦‚è‚¡ ADR                 â€” /api/us-stock/china-adr
5.  å•†å“ï¼ˆè´µé‡‘å±/èƒ½æº/å·¥ä¸šï¼‰     â€” /api/us-stock/commodities
6.  ç¾å€ºæ”¶ç›Šç‡ + åˆ©å·®           â€” /api/us-stock/bonds
7.  ç¾å…ƒæŒ‡æ•° / å¤–æ±‡             â€” /api/us-stock/forex
8.  ç›˜ä¸­å…¨ç¨‹å›é¡¾                â€” æŒ‡æ•°å¿«ç…§æ—¶é—´çº¿
9.  ğŸ“° å¿«è®¯                    â€” /api/news/latest
10. ğŸ§  Wendyåˆ†æ               â€” è§„åˆ™å¼•æ“åˆ†æ
11. ğŸ“ ç›˜åæ€»ç»“                â€” æ¨¡æ¿åŒ–å™äº‹æ€»ç»“
12. ğŸ“… ç»æµæ—¥å†                â€” /api/us-stock/calendar

æ•°æ®æº: ashare API http://127.0.0.1:8000
"""

import sys
import json
import argparse
import requests
import time as time_mod
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed


# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_BASE = "http://127.0.0.1:8000"
REQUEST_TIMEOUT = 10  # Increased from 5
CONNECT_TIMEOUT = 3   # Increased from 2
MAX_RETRIES = 2

PROJECT_ROOT = Path(__file__).parent.parent
SNAPSHOT_FILE = PROJECT_ROOT / "data" / "snapshots" / "intraday" / "us_index_snapshots.json"
SNAPSHOT_FILE.parent.mkdir(parents=True, exist_ok=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Helper: safe fetch with retry
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def fetch(endpoint: str) -> dict:
    """Fetch JSON from API with retry. Returns {} on failure."""
    for attempt in range(MAX_RETRIES + 1):
        try:
            r = requests.get(
                f"{API_BASE}{endpoint}",
                timeout=(CONNECT_TIMEOUT, REQUEST_TIMEOUT),
            )
            if r.ok:
                return r.json()
        except Exception:
            if attempt < MAX_RETRIES:
                time_mod.sleep(0.3)
    return {}


def safe_section(name: str):
    """Decorator: if a section fails, print error and continue."""
    def decorator(fn):
        def wrapper(*args, **kwargs):
            try:
                return fn(*args, **kwargs)
            except Exception as e:
                return [f"âš ï¸ [{name}] è·å–å¤±è´¥: {e}"]
        return wrapper
    return decorator


def pct_icon(pct: float) -> str:
    return "ğŸŸ¢" if pct >= 0 else "ğŸ”´"


def format_price(price: float, decimals: int = 2) -> str:
    if price >= 1000:
        return f"{price:,.{decimals}f}"
    return f"{price:.{decimals}f}"


def format_market_cap(cap: float) -> str:
    if cap >= 1e12:
        return f"{cap / 1e12:.2f}T"
    elif cap >= 1e9:
        return f"{cap / 1e9:.1f}B"
    elif cap >= 1e6:
        return f"{cap / 1e6:.0f}M"
    return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 0. Save index snapshot (side effect, runs every time)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def save_index_snapshot(quotes: list):
    """Save current index prices as a snapshot point."""
    try:
        if SNAPSHOT_FILE.exists():
            data = json.loads(SNAPSHOT_FILE.read_text())
            if data.get("date") != datetime.now().strftime("%Y-%m-%d"):
                data = {"date": datetime.now().strftime("%Y-%m-%d"), "snapshots": []}
        else:
            data = {"date": datetime.now().strftime("%Y-%m-%d"), "snapshots": []}

        now_time = datetime.now().strftime("%H:%M")
        existing = {s["time"] for s in data["snapshots"]}
        if now_time in existing:
            return

        entry = {"time": now_time, "indexes": {}}
        for q in quotes:
            if q["symbol"] in ("^GSPC", "^DJI", "^IXIC", "^NDX", "^VIX"):
                entry["indexes"][q["symbol"]] = {
                    "name": q.get("cn_name") or q["name"],
                    "price": q["price"],
                    "pct": q["change_pct"],
                }
        data["snapshots"].append(entry)
        SNAPSHOT_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2))
    except Exception:
        pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ä¸‰å¤§æŒ‡æ•° + VIX
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ä¸‰å¤§æŒ‡æ•°")
def section_indexes(data: dict) -> list[str]:
    lines = ["ğŸ“ˆ **ä¸‰å¤§æŒ‡æ•° + VIX**"]
    quotes = data.get("quotes", [])
    if not quotes:
        return lines + ["  æ•°æ®æš‚æ— "]

    main_indexes = []
    vix = None
    for q in quotes:
        if q["symbol"] == "^VIX":
            vix = q
        else:
            main_indexes.append(q)

    for q in main_indexes:
        icon = pct_icon(q["change_pct"])
        name = q.get("cn_name") or q["name"]
        price = format_price(q["price"])
        vol_str = ""
        if q.get("volume") and q["volume"] > 0:
            vol_b = q["volume"] / 1e9
            vol_str = f" æˆäº¤:{vol_b:.1f}B" if vol_b >= 1 else f" æˆäº¤:{q['volume'] / 1e6:.0f}M"
        lines.append(f"  {icon} {name}: {price} ({q['change_pct']:+.2f}%){vol_str}")

    if vix:
        vl = vix["price"]
        if vl >= 30:
            ve = "ğŸ”´ğŸ”´"
        elif vl >= 25:
            ve = "ğŸ”´"
        elif vl >= 20:
            ve = "ğŸŸ¡"
        else:
            ve = "ğŸŸ¢"
        lines.append(f"  {ve} VIXææ…ŒæŒ‡æ•°: {vl:.2f} ({vix['change_pct']:+.2f}%)")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. æ¿å—è¡¨ç°ï¼ˆæŒ‰æ¶¨è·Œæ’åº + å¹¿åº¦ + æ”»é˜²ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("æ¿å—è¡¨ç°")
def section_sectors(data: dict) -> list[str]:
    lines = ["ğŸ›ï¸ **æ¿å—è¡¨ç°**"]
    sectors = data.get("sectors", [])
    if not sectors:
        return lines + ["  æ•°æ®æš‚æ— "]

    etf_sectors = []
    for s in sectors:
        if s.get("etf"):
            etf_sectors.append({
                "name_cn": s["name_cn"],
                "symbol": s["etf"]["symbol"],
                "pct": s["etf"]["change_pct"],
                "price": s["etf"]["price"],
                "volume": s["etf"].get("volume", 0),
            })

    if not etf_sectors:
        return lines + ["  æ— ETFæ•°æ®"]

    etf_sectors.sort(key=lambda x: x["pct"], reverse=True)

    # Show ALL sectors (not just top/bottom 3)
    for s in etf_sectors:
        icon = pct_icon(s["pct"])
        vol_str = ""
        if s["volume"] > 0:
            vol_m = s["volume"] / 1e6
            vol_str = f" æˆäº¤:{vol_m:.0f}M"
        lines.append(f"  {icon} {s['name_cn']}({s['symbol']}): {s['pct']:+.2f}%{vol_str}")

    # Breadth
    up_count = sum(1 for s in etf_sectors if s["pct"] > 0)
    down_count = sum(1 for s in etf_sectors if s["pct"] < 0)
    flat_count = len(etf_sectors) - up_count - down_count
    lines.append(f"  æ¿å—å¹¿åº¦: {up_count}æ¶¨ / {down_count}è·Œ / {flat_count}å¹³")

    # Offensive vs Defensive
    defensive_names = {"å…¬ç”¨äº‹ä¸š", "å¿…éœ€æ¶ˆè´¹", "åŒ»ç–—å¥åº·", "æˆ¿åœ°äº§"}
    offensive_names = {"åŠå¯¼ä½“", "å¯é€‰æ¶ˆè´¹", "é€šä¿¡æœåŠ¡", "é‡‘è"}
    def_pcts = [s["pct"] for s in etf_sectors if s["name_cn"] in defensive_names]
    off_pcts = [s["pct"] for s in etf_sectors if s["name_cn"] in offensive_names]

    if def_pcts and off_pcts:
        def_avg = sum(def_pcts) / len(def_pcts)
        off_avg = sum(off_pcts) / len(off_pcts)
        if def_avg > off_avg + 0.5:
            lines.append(f"  ğŸ›¡ï¸ é˜²å¾¡>è¿›æ”»ï¼ˆ{def_avg:+.2f}% vs {off_avg:+.2f}%ï¼‰â†’ é¿é™©æƒ…ç»ª")
        elif off_avg > def_avg + 0.5:
            lines.append(f"  âš”ï¸ è¿›æ”»>é˜²å¾¡ï¼ˆ{off_avg:+.2f}% vs {def_avg:+.2f}%ï¼‰â†’ é£é™©åå¥½é«˜")
        else:
            lines.append(f"  âš–ï¸ æ”»é˜²å‡è¡¡ï¼ˆè¿›æ”»{off_avg:+.2f}% / é˜²å¾¡{def_avg:+.2f}%ï¼‰")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. Mag7 ä¸ƒå·¨å¤´
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("Mag7")
def section_mag7(data: dict) -> list[str]:
    lines = ["ğŸ’ **Mag7 ç§‘æŠ€ä¸ƒå·¨å¤´**"]
    quotes = data.get("quotes", [])
    if not quotes:
        return lines + ["  æ•°æ®æš‚æ— "]

    sorted_q = sorted(quotes, key=lambda q: q["change_pct"], reverse=True)
    avg_pct = sum(q["change_pct"] for q in sorted_q) / len(sorted_q)
    total_cap = sum(q.get("market_cap", 0) for q in sorted_q)

    for q in sorted_q:
        icon = pct_icon(q["change_pct"])
        name = q.get("cn_name") or q["symbol"]
        cap_str = format_market_cap(q.get("market_cap", 0))
        vol_str = ""
        if q.get("volume") and q["volume"] > 0:
            vol_m = q["volume"] / 1e6
            vol_str = f" æˆäº¤:{vol_m:.0f}M"
        lines.append(
            f"  {icon} {name}({q['symbol']}): ${format_price(q['price'])} "
            f"({q['change_pct']:+.2f}%) [{cap_str}]{vol_str}"
        )

    icon_avg = pct_icon(avg_pct)
    total_cap_str = format_market_cap(total_cap)
    up_count = sum(1 for q in sorted_q if q["change_pct"] > 0)
    down_count = len(sorted_q) - up_count
    lines.append(f"  {icon_avg} Mag7: {up_count}æ¶¨/{down_count}è·Œ å‡æ¶¨å¹…{avg_pct:+.2f}% | æ€»å¸‚å€¼{total_cap_str}")

    # Spread analysis
    best = sorted_q[0]
    worst = sorted_q[-1]
    spread = best["change_pct"] - worst["change_pct"]
    if spread > 5:
        lines.append(f"  âš ï¸ å†…éƒ¨åˆ†åŒ–{spread:.1f}%ï¼š{best.get('cn_name', best['symbol'])}é¢†æ¶¨ vs {worst.get('cn_name', worst['symbol'])}é¢†è·Œï¼Œäº‹ä»¶é©±åŠ¨")
    elif avg_pct > 1:
        lines.append(f"  ğŸŸ¢ å·¨å¤´æ•´ä½“å¼ºåŠ¿ï¼Œç§‘æŠ€ç‰›å¸‚åŸºè°ƒä¸å˜")
    elif avg_pct < -1:
        lines.append(f"  ğŸ”´ å·¨å¤´æ•´ä½“ç–²å¼±ï¼Œæ‹–ç´¯æŒ‡æ•°æƒé‡")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. ä¸­æ¦‚è‚¡ ADR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ä¸­æ¦‚è‚¡")
def section_china_adr(data: dict) -> list[str]:
    lines = ["ğŸ‡¨ğŸ‡³ **ä¸­æ¦‚è‚¡ ADR**"]
    quotes = data.get("quotes", [])
    if not quotes:
        return lines + ["  æ•°æ®æš‚æ— "]

    sorted_q = sorted(quotes, key=lambda q: q["change_pct"], reverse=True)
    avg_pct = sum(q["change_pct"] for q in sorted_q) / len(sorted_q)

    for q in sorted_q:
        icon = pct_icon(q["change_pct"])
        name = q.get("cn_name") or q["symbol"]
        vol_str = ""
        if q.get("volume") and q["volume"] > 0:
            vol_m = q["volume"] / 1e6
            vol_str = f" æˆäº¤:{vol_m:.0f}M"
        lines.append(
            f"  {icon} {name}({q['symbol']}): ${format_price(q['price'])} "
            f"({q['change_pct']:+.2f}%){vol_str}"
        )

    icon_avg = pct_icon(avg_pct)
    up_count = sum(1 for q in sorted_q if q["change_pct"] > 0)
    down_count = len(sorted_q) - up_count
    lines.append(f"  {icon_avg} ä¸­æ¦‚è‚¡: {up_count}æ¶¨/{down_count}è·Œ å‡æ¶¨å¹…{avg_pct:+.2f}%")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. å•†å“ï¼ˆè´µé‡‘å± / èƒ½æº / å·¥ä¸šé‡‘å±ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å•†å“")
def section_commodities(data: dict) -> list[str]:
    lines = ["ğŸ“¦ **å•†å“æœŸè´§**"]
    commodities = data.get("commodities", [])
    if not commodities:
        return lines + ["  æ•°æ®æš‚æ— "]

    precious, energy, industrial = [], [], []
    for c in commodities:
        entry = {
            "cn_name": c.get("cn_name") or c["name"],
            "symbol": c["symbol"],
            "price": c["price"],
            "pct": c.get("change_pct", 0),
        }
        if c["symbol"] in ("GC=F", "SI=F"):
            precious.append(entry)
        elif c["symbol"] in ("CL=F", "BZ=F", "NG=F"):
            energy.append(entry)
        elif c["symbol"] in ("HG=F",):
            industrial.append(entry)
        else:
            energy.append(entry)

    if precious:
        parts = []
        for c in precious:
            icon = pct_icon(c["pct"])
            parts.append(f"{icon}{c['cn_name']} ${format_price(c['price'])} ({c['pct']:+.2f}%)")
        lines.append(f"  è´µé‡‘å±: {' | '.join(parts)}")

    if energy:
        parts = []
        for c in energy:
            icon = pct_icon(c["pct"])
            parts.append(f"{icon}{c['cn_name']} ${format_price(c['price'])} ({c['pct']:+.2f}%)")
        lines.append(f"  èƒ½æº: {' | '.join(parts)}")

    if industrial:
        parts = []
        for c in industrial:
            icon = pct_icon(c["pct"])
            parts.append(f"{icon}{c['cn_name']} ${format_price(c['price'])} ({c['pct']:+.2f}%)")
        lines.append(f"  å·¥ä¸šé‡‘å±: {' | '.join(parts)}")

    # Gold/Silver ratio
    gold_p = next((c["price"] for c in precious if c["symbol"] == "GC=F"), 0)
    silver_p = next((c["price"] for c in precious if c["symbol"] == "SI=F"), 0)
    if gold_p > 0 and silver_p > 0:
        gs_ratio = gold_p / silver_p
        label = "åé«˜â†’é¿é™©" if gs_ratio > 80 else "åä½â†’å·¥ä¸šéœ€æ±‚æ—º" if gs_ratio < 60 else "æ­£å¸¸"
        lines.append(f"  ğŸ“Š é‡‘é“¶æ¯”: {gs_ratio:.1f} ({label})")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. ç¾å€ºæ”¶ç›Šç‡ + åˆ©å·®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å€ºåˆ¸")
def section_bonds(data: dict) -> list[str]:
    lines = ["ğŸ¦ **ç¾å€ºæ”¶ç›Šç‡**"]
    bonds = data.get("bonds", [])
    if not bonds:
        return lines + ["  æ•°æ®æš‚æ— "]

    bond_map = {}
    for b in bonds:
        bond_map[b["symbol"]] = b
        icon = pct_icon(b.get("change_pct", 0))
        name = b.get("cn_name") or b["name"]
        lines.append(f"  {icon} {name}: {b['price']:.3f}% ({b.get('change_pct', 0):+.2f}%)")

    tnx = bond_map.get("^TNX")
    fvx = bond_map.get("^FVX")
    tyx = bond_map.get("^TYX")

    if tnx and fvx:
        spread_10_5 = tnx["price"] - fvx["price"]
        label = "æ­£å¸¸" if spread_10_5 > 0 else "âš ï¸ å€’æŒ‚"
        lines.append(f"  ğŸ“ 10Y-5Yåˆ©å·®: {spread_10_5:+.3f}% ({label})")
    if tyx and tnx:
        spread_30_10 = tyx["price"] - tnx["price"]
        lines.append(f"  ğŸ“ 30Y-10Yåˆ©å·®: {spread_30_10:+.3f}%")

    # Yield level commentary
    if tnx:
        y10 = tnx["price"]
        if y10 > 5.0:
            lines.append(f"  ğŸ”´ 10Y > 5%ï¼šç´§ç¼©ç¯å¢ƒï¼Œè‚¡å¸‚æ‰¿å‹")
        elif y10 > 4.5:
            lines.append(f"  ğŸŸ¡ 10Y > 4.5%ï¼šåˆ©ç‡åé«˜ï¼Œå…³æ³¨é€šèƒ€æ•°æ®")
        elif y10 < 3.5:
            lines.append(f"  ğŸŸ¢ 10Y < 3.5%ï¼šå®½æ¾é¢„æœŸï¼Œåˆ©å¥½æˆé•¿è‚¡")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. ç¾å…ƒæŒ‡æ•° / å¤–æ±‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¤–æ±‡")
def section_forex(data: dict) -> list[str]:
    lines = ["ğŸ’µ **ç¾å…ƒæŒ‡æ•° / å¤–æ±‡**"]
    forex = data.get("forex", [])
    if not forex:
        return lines + ["  æ•°æ®æš‚æ— "]

    for f in forex:
        icon = pct_icon(f.get("change_pct", 0))
        name = f.get("cn_name") or f["name"]
        lines.append(f"  {icon} {name}: {f['price']:.3f} ({f.get('change_pct', 0):+.2f}%)")

    # Dollar strength commentary
    dxy = next((f for f in forex if f["symbol"] == "DX-Y.NYB"), None)
    if dxy:
        p = dxy["price"]
        if p > 105:
            lines.append(f"  ğŸ’ª ç¾å…ƒå¼ºåŠ¿ â†’ å‹åˆ¶å•†å“/æ–°å…´å¸‚åœº")
        elif p < 95:
            lines.append(f"  ğŸ“‰ ç¾å…ƒå¼±åŠ¿ â†’ åˆ©å¥½å•†å“/æ–°å…´å¸‚åœº")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. ç›˜ä¸­å…¨ç¨‹å›é¡¾ï¼ˆæŒ‡æ•°å¿«ç…§æ—¶é—´çº¿ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ç›˜ä¸­å›é¡¾")
def section_intraday_table() -> list[str]:
    if not SNAPSHOT_FILE.exists():
        return []

    data = json.loads(SNAPSHOT_FILE.read_text())
    snapshots = data.get("snapshots", [])
    if len(snapshots) < 2:
        return []  # Need at least 2 points to show timeline

    lines = [f"ğŸ“‹ **ç›˜ä¸­å…¨ç¨‹å›é¡¾** ({data.get('date', 'ä»Šæ—¥')})"]

    # Track highs/lows
    idx_tracker = {}

    lines.append(f"{'æ—¶é—´':>6} | {'S&P500':>12} | {'çº³æ–¯è¾¾å…‹':>12} | {'é“ç¼æ–¯':>12} | {'VIX':>8}")
    lines.append(f"{'â”€' * 6} | {'â”€' * 12} | {'â”€' * 12} | {'â”€' * 12} | {'â”€' * 8}")

    for snap in snapshots:
        t = snap["time"]
        idxs = snap.get("indexes", {})

        cols = [f"{t:>6}"]
        for code in ["^GSPC", "^IXIC", "^DJI"]:
            idx = idxs.get(code, {})
            price = idx.get("price", 0)
            pct = idx.get("pct", 0)
            if price > 0:
                sign = "+" if pct >= 0 else ""
                col_str = f"{sign}{pct:.2f}%"
                # Track high/low
                if code not in idx_tracker:
                    idx_tracker[code] = {
                        "name": idx.get("name", code),
                        "high_pct": pct, "high_time": t,
                        "low_pct": pct, "low_time": t,
                    }
                else:
                    tr = idx_tracker[code]
                    if pct > tr["high_pct"]:
                        tr["high_pct"] = pct
                        tr["high_time"] = t
                    if pct < tr["low_pct"]:
                        tr["low_pct"] = pct
                        tr["low_time"] = t
            else:
                col_str = "â€”"
            cols.append(f"{col_str:>12}")

        # VIX
        vix_data = idxs.get("^VIX", {})
        if vix_data.get("price", 0) > 0:
            cols.append(f"{vix_data['price']:.2f}".rjust(8))
        else:
            cols.append("â€”".rjust(8))

        lines.append(" | ".join(cols))

    # High/Low summary
    if idx_tracker:
        lines.append("")
        lines.append("ğŸ“ **é«˜ä½ç‚¹:**")
        name_map = {"^GSPC": "S&P500", "^IXIC": "çº³æ–¯è¾¾å…‹", "^DJI": "é“ç¼æ–¯"}
        for code in ["^GSPC", "^IXIC", "^DJI"]:
            if code in idx_tracker:
                tr = idx_tracker[code]
                lines.append(
                    f"  {name_map.get(code, code)}: "
                    f"é«˜ç‚¹({tr['high_pct']:+.2f}%) @{tr['high_time']} | "
                    f"ä½ç‚¹({tr['low_pct']:+.2f}%) @{tr['low_time']}"
                )

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 9. å¿«è®¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("å¿«è®¯")
def section_news(data: dict) -> list[str]:
    lines = ["ğŸ“° **å¿«è®¯**"]
    news_list = data.get("news", [])
    if isinstance(data, list):
        news_list = data
    if not news_list:
        return lines + ["  æš‚æ— å¿«è®¯"]

    for item in news_list[:8]:
        title = item.get("title", "")[:80]
        t = item.get("time", "")
        src = item.get("source_name") or item.get("source", "")
        if t and len(t) >= 5:
            if len(t) >= 16 and "T" in t:
                t = t[11:16]
            elif ":" in t:
                t = t[:5]
        prefix = f"[{t}]" if t else ""
        src_tag = f"({src})" if src else ""
        lines.append(f"  â€¢ {prefix} {title} {src_tag}")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 10. ğŸ§  Wendyåˆ†æï¼ˆè§„åˆ™å¼•æ“ï¼Œçº¯ç¡®å®šæ€§ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def section_analysis(
    index_data: dict,
    sector_data: dict,
    mag7_data: dict,
    adr_data: dict,
    commodity_data: dict,
    bond_data: dict,
    forex_data: dict,
) -> tuple[list[str], dict]:
    """Returns (lines, signal_data) for use in summary."""
    try:
        return _section_analysis_inner(
            index_data, sector_data, mag7_data,
            adr_data, commodity_data, bond_data, forex_data,
        )
    except Exception as e:
        return [f"âš ï¸ [Wendyåˆ†æ] è·å–å¤±è´¥: {e}"], {}


def _section_analysis_inner(
    index_data, sector_data, mag7_data,
    adr_data, commodity_data, bond_data, forex_data,
) -> tuple[list[str], dict]:

    lines = ["ğŸ§  **Wendyåˆ†æ**"]

    # â”€â”€ Extract key metrics â”€â”€
    quotes = index_data.get("quotes", [])
    quote_map = {q["symbol"]: q for q in quotes}

    sp500 = quote_map.get("^GSPC", {})
    nasdaq = quote_map.get("^IXIC", {})
    dow = quote_map.get("^DJI", {})
    ndx100 = quote_map.get("^NDX", {})
    vix_q = quote_map.get("^VIX", {})

    sp_pct = sp500.get("change_pct", 0)
    nas_pct = nasdaq.get("change_pct", 0)
    dow_pct = dow.get("change_pct", 0)
    vix_level = vix_q.get("price", 0)
    vix_pct = vix_q.get("change_pct", 0)

    mag_quotes = mag7_data.get("quotes", [])
    mag_avg = sum(q["change_pct"] for q in mag_quotes) / len(mag_quotes) if mag_quotes else 0

    adr_quotes = adr_data.get("quotes", [])
    adr_avg = sum(q["change_pct"] for q in adr_quotes) / len(adr_quotes) if adr_quotes else 0

    commodities = commodity_data.get("commodities", [])
    commodity_map = {c["symbol"]: c for c in commodities}
    gold = commodity_map.get("GC=F", {})
    gold_pct = gold.get("change_pct", 0)
    oil = commodity_map.get("CL=F", {})
    oil_pct = oil.get("change_pct", 0)
    copper = commodity_map.get("HG=F", {})
    copper_pct = copper.get("change_pct", 0)

    bonds = bond_data.get("bonds", [])
    bond_map = {b["symbol"]: b for b in bonds}
    tnx = bond_map.get("^TNX", {})
    y10 = tnx.get("price", 0)
    y10_pct = tnx.get("change_pct", 0)

    forex = forex_data.get("forex", [])
    fx_map = {f["symbol"]: f for f in forex}
    dxy = fx_map.get("DX-Y.NYB", {})
    dxy_price = dxy.get("price", 0)
    dxy_pct = dxy.get("change_pct", 0)

    sectors = sector_data.get("sectors", [])
    etf_sectors = []
    for s in sectors:
        if s.get("etf"):
            etf_sectors.append({
                "name_cn": s["name_cn"],
                "symbol": s["etf"]["symbol"],
                "pct": s["etf"]["change_pct"],
            })
    etf_sectors.sort(key=lambda x: x["pct"], reverse=True)

    # â•â•â• 10a. å¸‚åœºå®šæ€§ â•â•â•
    lines.append("")
    lines.append("**å¸‚åœºå®šæ€§:**")

    # VIX signal
    if vix_level >= 30:
        vix_signal = "ğŸ”´ æåº¦ææ…Œï¼ˆVIXâ‰¥30ï¼‰â€” å¸‚åœºå‰§çƒˆæ³¢åŠ¨"
    elif vix_level >= 25:
        vix_signal = "ğŸŸ  é«˜åº¦ææ…Œï¼ˆVIXâ‰¥25ï¼‰â€” é¿é™©æƒ…ç»ªæµ“åš"
    elif vix_level >= 20:
        vix_signal = "ğŸŸ¡ è­¦æƒ•ï¼ˆVIXâ‰¥20ï¼‰â€” æ³¢åŠ¨ç‡åé«˜"
    elif vix_level >= 15:
        vix_signal = "âš–ï¸ æ­£å¸¸ï¼ˆVIX 15-20ï¼‰â€” å¸‚åœºä¸­æ€§"
    elif vix_level > 0:
        vix_signal = "ğŸŸ¢ ä½æ³¢åŠ¨ï¼ˆVIX<15ï¼‰â€” å¸‚åœºä¹è§‚"
    else:
        vix_signal = "âšª VIXæ•°æ®æš‚æ— "
    lines.append(f"  VIX: {vix_signal}")

    # Value vs Growth
    scissor = dow_pct - nas_pct
    if scissor > 1.0:
        style_signal = "âš ï¸ ä»·å€¼>æˆé•¿ï¼ˆé“æŒ‡å¼ºã€çº³æŒ‡å¼±ï¼‰â†’ Risk OFF"
    elif scissor < -1.0:
        style_signal = "ğŸš€ æˆé•¿>ä»·å€¼ï¼ˆçº³æŒ‡å¼ºã€é“æŒ‡å¼±ï¼‰â†’ Risk ON"
    elif sp_pct > 0.5 and nas_pct > 0.5:
        style_signal = "ğŸŸ¢ æ™®æ¶¨è¡Œæƒ…"
    elif sp_pct < -0.5 and nas_pct < -0.5:
        style_signal = "ğŸ”´ æ™®è·Œè¡Œæƒ…"
    else:
        style_signal = "âš–ï¸ ä¸­æ€§éœ‡è¡"
    lines.append(f"  é£æ ¼: {style_signal}")
    lines.append(f"  é“æŒ‡{dow_pct:+.2f}% vs çº³æŒ‡{nas_pct:+.2f}% â†’ å‰ªåˆ€å·®{scissor:+.2f}%")

    # â•â•â• 10b. èµ„é‡‘è½®åŠ¨ â•â•â•
    lines.append("")
    lines.append("**èµ„é‡‘è½®åŠ¨:**")
    if etf_sectors:
        top3 = etf_sectors[:3]
        bot3 = etf_sectors[-3:]
        in_names = " / ".join([f"{s['name_cn']}({s['pct']:+.2f}%)" for s in top3])
        out_names = " / ".join([f"{s['name_cn']}({s['pct']:+.2f}%)" for s in bot3])
        lines.append(f"  ğŸ”º èµ„é‡‘æ¶Œå…¥: {in_names}")
        lines.append(f"  ğŸ”» èµ„é‡‘æ’¤ç¦»: {out_names}")

        # Sector breadth
        up_ratio = sum(1 for s in etf_sectors if s["pct"] > 0) / len(etf_sectors) if etf_sectors else 0
        lines.append(f"  æ¿å—ä¸Šæ¶¨æ¯”: {up_ratio:.0%}ï¼ˆ{sum(1 for s in etf_sectors if s['pct'] > 0)}/{len(etf_sectors)}ï¼‰")
    else:
        lines.append("  æ•°æ®æš‚æ— ")

    # â•â•â• 10c. Mag7å¥åº·åº¦ â•â•â•
    lines.append("")
    lines.append("**Mag7 å¥åº·åº¦:**")
    if mag_quotes:
        mag_up = sum(1 for q in mag_quotes if q["change_pct"] > 0)
        mag_down = len(mag_quotes) - mag_up
        best = max(mag_quotes, key=lambda q: q["change_pct"])
        worst = min(mag_quotes, key=lambda q: q["change_pct"])
        spread = best["change_pct"] - worst["change_pct"]

        lines.append(f"  {mag_up}æ¶¨/{mag_down}è·Œ | å‡æ¶¨å¹…{mag_avg:+.2f}%")
        lines.append(
            f"  æœ€å¼º: {best.get('cn_name', best['symbol'])} {best['change_pct']:+.2f}% | "
            f"æœ€å¼±: {worst.get('cn_name', worst['symbol'])} {worst['change_pct']:+.2f}%"
        )
        if spread > 5:
            lines.append(f"  âš ï¸ å†…éƒ¨åˆ†åŒ–ä¸¥é‡ï¼ˆå·®è·{spread:.1f}%ï¼‰ï¼Œäº‹ä»¶é©±åŠ¨")
        elif mag_avg > 1:
            lines.append(f"  ğŸŸ¢ ç§‘æŠ€å·¨å¤´æ•´ä½“å¼ºåŠ¿ï¼Œé£é™©åå¥½é«˜")
        elif mag_avg < -1:
            lines.append(f"  ğŸ”´ ç§‘æŠ€å·¨å¤´æ•´ä½“ç–²å¼±ï¼Œå¤§ç›˜æ‰¿å‹")
    else:
        lines.append("  æ•°æ®æš‚æ— ")

    # â•â•â• 10d. ä¸­æ¦‚ vs å¤§ç›˜ â•â•â•
    lines.append("")
    lines.append("**ä¸­æ¦‚ vs å¤§ç›˜:**")
    if adr_quotes:
        adr_up = sum(1 for q in adr_quotes if q["change_pct"] > 0)
        adr_down = len(adr_quotes) - adr_up
        relative = adr_avg - sp_pct
        lines.append(f"  ä¸­æ¦‚å‡æ¶¨å¹…: {adr_avg:+.2f}% vs S&P500: {sp_pct:+.2f}%")
        lines.append(f"  ç›¸å¯¹å¼ºå¼±: {relative:+.2f}% ({adr_up}æ¶¨/{adr_down}è·Œ)")
        if relative > 2:
            lines.append(f"  ğŸŸ¢ ä¸­æ¦‚æ˜¾è‘—è·‘èµ¢å¤§ç›˜ï¼Œä¸­å›½èµ„äº§å—è¿½æ§")
        elif relative < -2:
            lines.append(f"  ğŸ”´ ä¸­æ¦‚æ˜¾è‘—è·‘è¾“å¤§ç›˜ï¼Œåœ°ç¼˜/æ”¿ç­–é£é™©æº¢ä»·")
        elif adr_avg > 0 and sp_pct < 0:
            lines.append(f"  ğŸŸ¢ ä¸­æ¦‚é€†åŠ¿èµ°å¼ºï¼Œç‹¬ç«‹è¡Œæƒ…")
        elif adr_avg < 0 and sp_pct > 0:
            lines.append(f"  ğŸ”´ ä¸­æ¦‚é€†åŠ¿èµ°å¼±ï¼Œèµ„é‡‘å›é¿ä¸­å›½èµ„äº§")
        else:
            lines.append(f"  âš–ï¸ ä¸­æ¦‚è·Ÿéšå¤§ç›˜")
    else:
        lines.append("  æ•°æ®æš‚æ— ")

    # â•â•â• 10e. ğŸ›¡ï¸ é¿é™©ä¿¡å·ç»„åˆï¼ˆç±»ä¼¼Aè‚¡æŠ¤ç›˜æŒ‡æ ‡ï¼‰ â•â•â•
    lines.append("")
    lines.append("**ğŸ›¡ï¸ é¿é™©ä¿¡å·ç»„åˆ:**")
    safe_haven_signals = 0
    safe_haven_total = 0

    # Signal 1: VIX spike
    if vix_level >= 20:
        safe_haven_signals += 1
        lines.append(f"  ğŸ”´ VIX={vix_level:.2f}({vix_pct:+.2f}%) â†’ ææ…Œå‡æ¸©")
    elif vix_level >= 15:
        lines.append(f"  ğŸŸ¡ VIX={vix_level:.2f}({vix_pct:+.2f}%) â†’ æ­£å¸¸åé«˜")
    else:
        lines.append(f"  ğŸŸ¢ VIX={vix_level:.2f}({vix_pct:+.2f}%) â†’ å¸‚åœºå¹³é™")

    # Signal 2: Gold rally
    if gold_pct > 1.5:
        safe_haven_signals += 1
        lines.append(f"  ğŸ”´ é»„é‡‘{gold_pct:+.2f}% â†’ é¿é™©éœ€æ±‚å¼ºåŠ²")
    elif gold_pct < -1:
        lines.append(f"  ğŸŸ¢ é»„é‡‘{gold_pct:+.2f}% â†’ æ— é¿é™©éœ€æ±‚")
    else:
        lines.append(f"  âš–ï¸ é»„é‡‘{gold_pct:+.2f}% â†’ ä¸­æ€§")

    # Signal 3: Bond yield drop (flight to safety)
    if y10_pct < -2:
        safe_haven_signals += 1
        lines.append(f"  ğŸ”´ 10Yç¾å€ºæ”¶ç›Šç‡{y10_pct:+.2f}%å¤§è·Œ â†’ èµ„é‡‘æ¶Œå…¥å›½å€ºé¿é™©")
    elif y10_pct > 2:
        lines.append(f"  ğŸŸ¡ 10Yç¾å€ºæ”¶ç›Šç‡{y10_pct:+.2f}%å¤§æ¶¨ â†’ é€šèƒ€/ç´§ç¼©é¢„æœŸ")
    else:
        lines.append(f"  âš–ï¸ 10Yç¾å€ºæ”¶ç›Šç‡{y10_pct:+.2f}% â†’ ä¸­æ€§")

    # Signal 4: Defensive sectors outperforming
    defensive_names = {"å…¬ç”¨äº‹ä¸š", "å¿…éœ€æ¶ˆè´¹", "åŒ»ç–—å¥åº·", "æˆ¿åœ°äº§"}
    offensive_names = {"åŠå¯¼ä½“", "å¯é€‰æ¶ˆè´¹", "é€šä¿¡æœåŠ¡"}
    def_pcts = [s["pct"] for s in etf_sectors if s["name_cn"] in defensive_names]
    off_pcts = [s["pct"] for s in etf_sectors if s["name_cn"] in offensive_names]
    if def_pcts and off_pcts:
        def_avg = sum(def_pcts) / len(def_pcts)
        off_avg = sum(off_pcts) / len(off_pcts)
        if def_avg > off_avg + 1:
            safe_haven_signals += 1
            lines.append(f"  ğŸ”´ é˜²å¾¡æ¿å—é¢†æ¶¨({def_avg:+.2f}% vs è¿›æ”»{off_avg:+.2f}%) â†’ é¿é™©è½®åŠ¨")
        elif off_avg > def_avg + 1:
            lines.append(f"  ğŸŸ¢ è¿›æ”»æ¿å—é¢†æ¶¨({off_avg:+.2f}% vs é˜²å¾¡{def_avg:+.2f}%) â†’ é£é™©åå¥½")
        else:
            lines.append(f"  âš–ï¸ æ”»é˜²å‡è¡¡ï¼ˆè¿›æ”»{off_avg:+.2f}% / é˜²å¾¡{def_avg:+.2f}%ï¼‰")

    # Combined verdict
    if safe_haven_signals >= 3:
        lines.append(f"  ğŸš¨ {safe_haven_signals}/4é¿é™©ä¿¡å·äº®ç¯ â†’ **å…¨é¢é¿é™©æ¨¡å¼**ï¼Œç§‘æŠ€/æˆé•¿æ‰¿å‹ä¸¥é‡")
    elif safe_haven_signals >= 2:
        lines.append(f"  âš ï¸ {safe_haven_signals}/4é¿é™©ä¿¡å· â†’ é¿é™©æƒ…ç»ªåæµ“ï¼Œè°¨æ…æ“ä½œ")
    elif safe_haven_signals >= 1:
        lines.append(f"  ğŸŸ¡ {safe_haven_signals}/4é¿é™©ä¿¡å· â†’ è½»å¾®é¿é™©ï¼Œä½†ä¸æ„æˆç³»ç»Ÿé£é™©")
    else:
        lines.append(f"  ğŸŸ¢ 0/4é¿é™©ä¿¡å· â†’ å¸‚åœºæƒ…ç»ªæ­£å¸¸ï¼Œæ— éœ€è¿‡åº¦é˜²å¾¡")

    # â•â•â• 10f. ğŸ“ è¶‹åŠ¿å¼ºåº¦æ ‡å°º â•â•â•
    lines.append("")
    lines.append("**ğŸ“ è¶‹åŠ¿å¼ºåº¦:**")
    if etf_sectors:
        best_sector = etf_sectors[0]
        worst_sector = etf_sectors[-1]
        sector_spread = best_sector["pct"] - worst_sector["pct"]

        lines.append(
            f"  #1 {best_sector['name_cn']}({best_sector['symbol']}): {best_sector['pct']:+.2f}%"
        )

        if sector_spread > 5:
            trend_strength = "ğŸ”¥ å¼ºåˆ†åŒ–"
            trend_desc = "èµ„é‡‘æ–¹å‘æ˜ç¡®ï¼Œåšå¤šæœ‰æ–¹å‘æ„Ÿ"
        elif sector_spread > 3:
            trend_strength = "ğŸ“Š ä¸­ç­‰åˆ†åŒ–"
            trend_desc = "æœ‰é€‰æ‹©æ€§è¿›æ”»ï¼Œä½†åŠ›åº¦ä¸€èˆ¬"
        elif sector_spread > 1:
            trend_strength = "âš–ï¸ å¼±åˆ†åŒ–"
            trend_desc = "æ¿å—é½æ¶¨é½è·Œï¼Œç¼ºä¹ä¸»çº¿"
        else:
            trend_strength = "ğŸ˜¶ æ— æ–¹å‘"
            trend_desc = "æåº¦çª„å¹…ï¼Œè§‚æœ›ä¸ºä¸»"

        lines.append(f"  æ¿å—ç¦»æ•£åº¦: {sector_spread:.2f}% â†’ {trend_strength}ï¼ˆ{trend_desc}ï¼‰")

        # Check if tech-heavy
        tech_sectors = {"åŠå¯¼ä½“", "é€šä¿¡æœåŠ¡", "å¯é€‰æ¶ˆè´¹"}
        tech_in_top3 = sum(1 for s in etf_sectors[:3] if s["name_cn"] in tech_sectors)
        if tech_in_top3 >= 2:
            lines.append(f"  ğŸš€ TOP3ä¸­{tech_in_top3}ä¸ªç§‘æŠ€/æˆé•¿æ¿å— â†’ ç§‘æŠ€ä¸»çº¿æ—¥")
        value_sectors = {"é‡‘è", "èƒ½æº", "ææ–™", "å·¥ä¸š"}
        value_in_top3 = sum(1 for s in etf_sectors[:3] if s["name_cn"] in value_sectors)
        if value_in_top3 >= 2:
            lines.append(f"  ğŸ›ï¸ TOP3ä¸­{value_in_top3}ä¸ªä»·å€¼/å‘¨æœŸæ¿å— â†’ ä»·å€¼è½®åŠ¨æ—¥")
    else:
        lines.append("  æ•°æ®æš‚æ— ")

    # â•â•â• 10g. å•†å“/åˆ©ç‡/æ±‡ç‡è”åŠ¨ä¿¡å· â•â•â•
    lines.append("")
    lines.append("**å…³é”®è”åŠ¨ä¿¡å·:**")

    signals_list = []

    # Gold + VIX combo
    if gold_pct > 1.5 and vix_level >= 20:
        signals_list.append("ğŸš¨ é»„é‡‘+VIXåŒæ¶¨ â†’ å¸‚åœºææ…Œæ¨¡å¼")
    elif gold_pct > 1.5 and vix_level < 15:
        signals_list.append("ğŸ¤” é»„é‡‘æ¶¨ä½†VIXä½ â†’ å¯èƒ½æ˜¯é€šèƒ€äº¤æ˜“è€Œéé¿é™©")

    # Oil + copper combo (economic signal)
    if oil_pct < -3 and copper_pct < -2:
        signals_list.append("âš ï¸ åŸæ²¹+é“œåŒè·Œ â†’ å…¨çƒç»æµè¡°é€€é¢„æœŸ")
    elif oil_pct > 3 and copper_pct > 2:
        signals_list.append("ğŸŸ¢ åŸæ²¹+é“œåŒæ¶¨ â†’ å…¨çƒç»æµå¤è‹é¢„æœŸ")

    # Yield + dollar combo
    if y10_pct > 2 and dxy_pct > 0.3:
        signals_list.append("âš ï¸ åˆ©ç‡ä¸Šè¡Œ+ç¾å…ƒèµ°å¼º â†’ é‡‘èæ¡ä»¶æ”¶ç´§")
    elif y10_pct < -2 and dxy_pct < -0.3:
        signals_list.append("ğŸŸ¢ åˆ©ç‡ä¸‹è¡Œ+ç¾å…ƒèµ°å¼± â†’ é‡‘èæ¡ä»¶å®½æ¾")

    # Mag7 vs market
    if mag_avg < -2 and sp_pct > -0.5:
        signals_list.append("âš ï¸ å·¨å¤´å¤§è·Œä½†å¤§ç›˜ç¨³ â†’ æƒé‡è½®åŠ¨ï¼Œéç³»ç»Ÿé£é™©")
    elif mag_avg > 2 and sp_pct < 0.5:
        signals_list.append("ğŸ¤” å·¨å¤´å¤§æ¶¨ä½†å¤§ç›˜å¼± â†’ èµ„é‡‘é›†ä¸­å¤´éƒ¨ï¼Œä¸­å°ç›˜æ‰¿å‹")

    # ADR vs A-share anticipation
    if adr_avg > 2:
        signals_list.append("ğŸŸ¢ ä¸­æ¦‚è‚¡å¤§æ¶¨ â†’ æ˜æ—¥Aè‚¡ç›¸å…³æ ‡çš„æœ‰æœ›å—ç›Š")
    elif adr_avg < -3:
        signals_list.append("ğŸ”´ ä¸­æ¦‚è‚¡å¤§è·Œ â†’ æ˜æ—¥Aè‚¡æƒ…ç»ªå¯èƒ½å—æ‹–ç´¯")

    if signals_list:
        for s in signals_list:
            lines.append(f"  {s}")
    else:
        lines.append("  âš–ï¸ å„èµ„äº§ç±»åˆ«è”åŠ¨æ­£å¸¸ï¼Œæ— å¼‚å¸¸ä¿¡å·")

    # â•â•â• 10h. ç»¼åˆè¯„åˆ† & æ“ä½œå»ºè®® â•â•â•
    lines.append("")
    lines.append("**ğŸ“ ç»¼åˆè¯„åˆ†:**")

    bullish = 0
    bearish = 0

    # Index direction
    if sp_pct > 0.3: bullish += 1
    elif sp_pct < -0.3: bearish += 1
    if nas_pct > 0.3: bullish += 1
    elif nas_pct < -0.3: bearish += 1

    # VIX
    if vix_level < 15: bullish += 1
    elif vix_level >= 25: bearish += 2
    elif vix_level >= 20: bearish += 1

    # Mag7
    if mag_avg > 0.5: bullish += 1
    elif mag_avg < -0.5: bearish += 1

    # Gold (inverse)
    if gold_pct > 2: bearish += 1
    elif gold_pct < -1: bullish += 1

    # Bond yield direction
    if y10_pct > 2: bearish += 1
    elif y10_pct < -2: bullish += 1

    # Sector breadth
    if etf_sectors:
        up_ratio = sum(1 for s in etf_sectors if s["pct"] > 0) / len(etf_sectors)
        if up_ratio > 0.7: bullish += 1
        elif up_ratio < 0.3: bearish += 1

    # Safe haven count
    if safe_haven_signals >= 3: bearish += 2
    elif safe_haven_signals >= 2: bearish += 1

    # Scissor
    if scissor > 1.5: bearish += 1  # Extreme value > growth = risk-off
    elif scissor < -1.5: bullish += 1  # Extreme growth = risk-on

    total_score = bullish - bearish
    if total_score >= 4:
        advice = "âœ… å¤šå¤´ä¸»å¯¼ â€” å¸‚åœºé£é™©åå¥½é«˜ï¼Œç§¯æå‚ä¸"
    elif total_score >= 2:
        advice = "ğŸŸ¢ åå¤š â€” æ¸©å’Œçœ‹æ¶¨ï¼Œå…³æ³¨ä¸»çº¿æ¿å—"
    elif total_score <= -4:
        advice = "ğŸ›‘ ç©ºå¤´ä¸»å¯¼ â€” é¿é™©ä¸ºä¸»ï¼Œå‡ä»“è§‚æœ›"
    elif total_score <= -2:
        advice = "ğŸŸ¡ åç©º â€” è°¨æ…æ“ä½œï¼Œæ§åˆ¶ä»“ä½"
    elif abs(scissor) > 1.5:
        advice = "âš ï¸ é£æ ¼æç«¯åˆ†åŒ– â€” è·Ÿéšå¼ºåŠ¿é£æ ¼ï¼Œå›é¿å¼±åŠ¿"
    else:
        advice = "âš–ï¸ ä¸­æ€§éœ‡è¡ â€” è½»ä»“çµæ´»åº”å¯¹"

    lines.append(f"  å¤šå¤´ä¿¡å·: {bullish} | ç©ºå¤´ä¿¡å·: {bearish} | å‡€å€¼: {total_score:+d}")
    lines.append(f"  {advice}")

    # Collect signal data for summary
    signal_data = {
        "sp_pct": sp_pct,
        "nas_pct": nas_pct,
        "dow_pct": dow_pct,
        "scissor": scissor,
        "style_signal": style_signal,
        "vix_level": vix_level,
        "vix_pct": vix_pct,
        "mag_avg": mag_avg,
        "mag_quotes": mag_quotes,
        "adr_avg": adr_avg,
        "adr_quotes": adr_quotes,
        "gold_pct": gold_pct,
        "oil_pct": oil_pct,
        "copper_pct": copper_pct,
        "y10": y10,
        "y10_pct": y10_pct,
        "dxy_price": dxy_price,
        "dxy_pct": dxy_pct,
        "safe_haven_signals": safe_haven_signals,
        "etf_sectors": etf_sectors,
        "bullish": bullish,
        "bearish": bearish,
        "total_score": total_score,
        "advice": advice,
    }

    return lines, signal_data


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 11. ğŸ“ ç›˜åæ€»ç»“ï¼ˆæ¨¡æ¿åŒ–å™äº‹ï¼Œç±»ä¼¼Aè‚¡ç‰ˆï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ç›˜åæ€»ç»“")
def section_summary(signal_data: dict) -> list[str]:
    if not signal_data:
        return []

    sp_pct = signal_data.get("sp_pct", 0)
    nas_pct = signal_data.get("nas_pct", 0)
    dow_pct = signal_data.get("dow_pct", 0)
    scissor = signal_data.get("scissor", 0)
    vix_level = signal_data.get("vix_level", 0)
    mag_avg = signal_data.get("mag_avg", 0)
    mag_quotes = signal_data.get("mag_quotes", [])
    adr_avg = signal_data.get("adr_avg", 0)
    gold_pct = signal_data.get("gold_pct", 0)
    y10 = signal_data.get("y10", 0)
    y10_pct = signal_data.get("y10_pct", 0)
    safe_haven = signal_data.get("safe_haven_signals", 0)
    etf_sectors = signal_data.get("etf_sectors", [])
    bullish = signal_data.get("bullish", 0)
    bearish = signal_data.get("bearish", 0)

    lines = ["â•â•â• ğŸ“ æ€»ç»“ â•â•â•", ""]

    # â”€â”€ Determine day type â”€â”€
    if safe_haven >= 3 and nas_pct < -1:
        day_type = "extreme_risk_off"
    elif safe_haven >= 2:
        day_type = "risk_off"
    elif bullish >= 5:
        day_type = "strong_bull"
    elif bearish >= 5:
        day_type = "strong_bear"
    elif scissor > 1.5:
        day_type = "value_rotation"
    elif scissor < -1.5:
        day_type = "growth_chase"
    elif sp_pct > 0.5 and nas_pct > 0.5:
        day_type = "broad_rally"
    elif sp_pct < -0.5 and nas_pct < -0.5:
        day_type = "broad_selloff"
    else:
        day_type = "mixed"

    # â”€â”€ Headline â”€â”€
    sp_dir = "æ¶¨" if sp_pct >= 0 else "è·Œ"
    nas_dir = "æ¶¨" if nas_pct >= 0 else "è·Œ"

    if day_type == "extreme_risk_off":
        lines.append(
            f"ä»Šå¤©ä¸‰å¤§é¿é™©ä¿¡å·é½äº®ï¼Œçº³æŒ‡{nas_dir}{abs(nas_pct):.2f}%ï¼š**å…¨é¢é¿é™©æ—¥**ã€‚"
        )
    elif day_type == "risk_off":
        lines.append(
            f"S&P {sp_dir}{abs(sp_pct):.2f}%ï¼Œçº³æŒ‡{nas_dir}{abs(nas_pct):.2f}%ã€‚"
            f"èµ„é‡‘åé˜²å¾¡ï¼Œé¿é™©æƒ…ç»ªå‡æ¸©ã€‚"
        )
    elif day_type == "strong_bull":
        lines.append(f"å¤šå¤´å…¨é¢å‘åŠ›ï¼ŒS&P {sp_dir}{abs(sp_pct):.2f}%ï¼Œå¸‚åœºæƒ…ç»ªæåº¦ä¹è§‚ã€‚")
    elif day_type == "strong_bear":
        lines.append(f"ç©ºå¤´å æ®ç»å¯¹ä¼˜åŠ¿ï¼ŒS&P {sp_dir}{abs(sp_pct):.2f}%ï¼Œå…¨é¢æ‰¿å‹ã€‚")
    elif day_type == "value_rotation":
        lines.append(
            f"å…¸å‹çš„ä»·å€¼è½®åŠ¨æ—¥ï¼šé“æŒ‡+{abs(dow_pct):.2f}%è·‘èµ¢çº³æŒ‡{nas_pct:+.2f}%ï¼Œ"
            f"å‰ªåˆ€å·®{scissor:+.2f}%ã€‚èµ„é‡‘ä»æˆé•¿åˆ‡æ¢åˆ°ä»·å€¼ã€‚"
        )
    elif day_type == "growth_chase":
        lines.append(
            f"æˆé•¿è‚¡å¼ºåŠ¿æ—¥ï¼šçº³æŒ‡{nas_dir}{abs(nas_pct):.2f}%é¢†æ¶¨ï¼Œ"
            f"ç§‘æŠ€ä¸»çº¿æ˜ç¡®ã€‚"
        )
    elif day_type == "broad_rally":
        lines.append(f"ä¸‰å¤§æŒ‡æ•°å…¨é¢ä¸Šæ¶¨ï¼ŒS&P {sp_pct:+.2f}%ï¼Œæ™®æ¶¨æ ¼å±€ã€‚")
    elif day_type == "broad_selloff":
        lines.append(f"ä¸‰å¤§æŒ‡æ•°å…¨é¢ä¸‹è·Œï¼ŒS&P {sp_pct:+.2f}%ï¼Œæ™®è·Œæ ¼å±€ã€‚")
    else:
        lines.append(
            f"S&P {sp_dir}{abs(sp_pct):.2f}%ï¼Œçº³æŒ‡{nas_dir}{abs(nas_pct):.2f}%ï¼Œ"
            f"æ–¹å‘ä¸æ˜æœ—ã€‚"
        )

    lines.append("")

    # â”€â”€ Three signals (like A-share) â”€â”€
    # 1. é¿é™©ä¿¡å·
    if safe_haven >= 3:
        lines.append(f"1. é¿é™©ä¿¡å·{safe_haven}/4ç¯å…¨äº® â†’ å¸‚åœºæåº¦ææ…Œ")
    elif safe_haven >= 2:
        lines.append(f"1. é¿é™©ä¿¡å·{safe_haven}/4ç¯ â†’ é¿é™©æƒ…ç»ªåæµ“")
    elif safe_haven == 1:
        lines.append(f"1. é¿é™©ä¿¡å·1/4ç¯ â†’ è½»å¾®æ‹…å¿§ä½†å¯æ§")
    else:
        lines.append(f"1. é¿é™©ä¿¡å·0/4ç¯ â†’ å¸‚åœºæƒ…ç»ªæ­£å¸¸")

    # 2. Mag7 health (like A-share trend strength)
    best_mag = max(mag_quotes, key=lambda q: q["change_pct"]) if mag_quotes else {}
    worst_mag = min(mag_quotes, key=lambda q: q["change_pct"]) if mag_quotes else {}
    if mag_avg > 1:
        lines.append(f"2. Mag7å‡æ¶¨{mag_avg:+.2f}% â†’ ç§‘æŠ€ç‰›å¸‚åŸºè°ƒï¼Œå¯è·Ÿ")
    elif mag_avg < -1:
        lines.append(
            f"2. Mag7å‡è·Œ{mag_avg:+.2f}% â†’ å·¨å¤´æ‰¿å‹"
            + (f"ï¼ˆ{worst_mag.get('cn_name', '')} {worst_mag.get('change_pct', 0):+.2f}%é¢†è·Œï¼‰" if worst_mag else "")
        )
    else:
        lines.append(f"2. Mag7å‡æ¶¨å¹…{mag_avg:+.2f}% â†’ å·¨å¤´è¡¨ç°ä¸­æ€§")

    # 3. Style signal
    if scissor > 1.5:
        lines.append(f"3. é“/çº³å‰ªåˆ€å·®{scissor:+.2f}% â†’ æç«¯ä»·å€¼åå¥½ï¼Œæˆé•¿è‚¡èµ„é‡‘å¤–æµ")
    elif scissor < -1.5:
        lines.append(f"3. é“/çº³å‰ªåˆ€å·®{scissor:+.2f}% â†’ æç«¯æˆé•¿åå¥½ï¼Œç§‘æŠ€ä¸»å¯¼")
    elif scissor > 0.5:
        lines.append(f"3. é“/çº³å‰ªåˆ€å·®{scissor:+.2f}% â†’ åä»·å€¼é£æ ¼")
    elif scissor < -0.5:
        lines.append(f"3. é“/çº³å‰ªåˆ€å·®{scissor:+.2f}% â†’ åæˆé•¿é£æ ¼")
    else:
        lines.append(f"3. é“/çº³å‰ªåˆ€å·®{scissor:+.2f}% â†’ é£æ ¼ä¸­æ€§")

    lines.append("")

    # â”€â”€ Notable moves â”€â”€
    if etf_sectors:
        best_s = etf_sectors[0]
        worst_s = etf_sectors[-1]
        spread = best_s["pct"] - worst_s["pct"]
        if spread > 3:
            lines.append(
                f"æ¿å—åˆ†åŒ–æ˜æ˜¾ï¼š{best_s['name_cn']}{best_s['pct']:+.2f}%é¢†æ¶¨ï¼Œ"
                f"{worst_s['name_cn']}{worst_s['pct']:+.2f}%é¢†è·Œï¼Œ"
                f"ç¦»æ•£åº¦{spread:.2f}%ã€‚"
            )

    # ADR impact on A-share
    if abs(adr_avg) > 2:
        adr_dir = "å¤§æ¶¨" if adr_avg > 0 else "å¤§è·Œ"
        impact = "æ­£é¢ææŒ¯" if adr_avg > 0 else "è´Ÿé¢æ‹–ç´¯"
        lines.append(f"ä¸­æ¦‚è‚¡{adr_dir}({adr_avg:+.2f}%)ï¼Œå¯¹æ˜æ—¥Aè‚¡ä¸­æ¦‚ç›¸å…³æ ‡çš„{impact}ã€‚")

    lines.append("")

    # â”€â”€ æ˜æ—¥å…³æ³¨ â”€â”€
    lines.append("**æ˜æ—¥å…³æ³¨ï¼š**")
    focus = []

    if safe_haven >= 2:
        focus.append("é¿é™©ä¿¡å·èƒ½å¦ç¼“è§£ã€VIXèƒ½å¦å›è½20ä»¥ä¸‹")
    if abs(mag_avg) > 2:
        focus.append(f"Mag7{'åå¼¹' if mag_avg < 0 else 'æŒç»­æ€§'}ï¼Œå…³æ³¨æ˜¯å¦æœ‰è´¢æŠ¥/äº‹ä»¶å‚¬åŒ–")
    if abs(scissor) > 1.5:
        focus.append("é“/çº³å‰ªåˆ€å·®èƒ½å¦æ”¶çª„ã€é£æ ¼åˆ‡æ¢ä¿¡å·")
    if y10 > 4.5:
        focus.append(f"10Yç¾å€º{y10:.3f}%åé«˜ï¼Œå…³æ³¨åç»­é€šèƒ€æ•°æ®å½±å“")
    if abs(adr_avg) > 3:
        focus.append("ä¸­æ¦‚è‚¡è¡¨ç°å¯¹Aè‚¡å¼€ç›˜å½±å“")

    if not focus:
        focus.append("ç»§ç»­è§‚å¯Ÿä¸»çº¿æ–¹å‘ä¸èµ„é‡‘æµå‘å˜åŒ–")

    for fp in focus:
        lines.append(f"  â€¢ {fp}")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 12. ç»æµæ—¥å†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@safe_section("ç»æµæ—¥å†")
def section_calendar() -> list[str]:
    data = fetch("/api/us-stock/calendar")
    events = data.get("events", data.get("data", []))
    if not events:
        return []

    lines = ["ğŸ“… **ç»æµæ—¥å†**"]
    for e in events[:5]:
        date = e.get("date", "")
        event = e.get("event", e.get("name", ""))
        actual = e.get("actual", "")
        forecast = e.get("forecast", "")
        extra = ""
        if actual:
            extra += f" å®é™…:{actual}"
        if forecast:
            extra += f" é¢„æœŸ:{forecast}"
        lines.append(f"  â€¢ {date} {event}{extra}")

    return lines


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main: Assemble all sections
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def format_briefing(show_time: bool = False) -> str:
    now = datetime.now()
    time_label = now.strftime("%Y-%m-%d %H:%M")
    weekday_cn = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][now.weekday()]

    output = []
    output.append(f"{'â•' * 50}")
    output.append(f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡ç®€æŠ¥** ({time_label} {weekday_cn})")
    output.append(f"{'â•' * 50}")

    if show_time:
        output.append(f"â± ç”Ÿæˆæ—¶é—´æˆ³: {now.strftime('%Y-%m-%d %H:%M:%S')}")
        output.append("")

    # â”€â”€ Fetch all data concurrently â”€â”€
    endpoints = {
        "index": "/api/us-stock/indexes",
        "sector": "/api/us-stock/sectors",
        "mag7": "/api/us-stock/mag7",
        "adr": "/api/us-stock/china-adr",
        "commodity": "/api/us-stock/commodities",
        "bond": "/api/us-stock/bonds",
        "forex": "/api/us-stock/forex",
        "news": "/api/news/latest?limit=8",
    }
    results = {}
    with ThreadPoolExecutor(max_workers=4) as executor:  # Reduced from 8 to avoid overwhelming API
        futures = {executor.submit(fetch, ep): key for key, ep in endpoints.items()}
        for future in as_completed(futures):
            key = futures[future]
            results[key] = future.result()

    index_data = results.get("index", {})
    sector_data = results.get("sector", {})
    mag7_data = results.get("mag7", {})
    adr_data = results.get("adr", {})
    commodity_data = results.get("commodity", {})
    bond_data = results.get("bond", {})
    forex_data = results.get("forex", {})
    news_data = results.get("news", {})

    # Save index snapshot
    index_quotes = index_data.get("quotes", [])
    if index_quotes:
        save_index_snapshot(index_quotes)

    # â”€â”€ Assemble sections â”€â”€

    # 1-7: Data sections
    output.extend(section_indexes(index_data))
    output.append("")
    output.extend(section_sectors(sector_data))
    output.append("")
    output.extend(section_mag7(mag7_data))
    output.append("")
    output.extend(section_china_adr(adr_data))
    output.append("")
    output.extend(section_commodities(commodity_data))
    output.append("")
    output.extend(section_bonds(bond_data))
    output.append("")
    output.extend(section_forex(forex_data))
    output.append("")

    # 8: Intraday timeline
    intraday = section_intraday_table()
    if intraday:
        output.extend(intraday)
        output.append("")

    # 9: News
    output.extend(section_news(news_data))
    output.append("")

    # 10: Analysis
    analysis_result = section_analysis(
        index_data, sector_data, mag7_data,
        adr_data, commodity_data, bond_data, forex_data,
    )
    signal_data = {}
    if isinstance(analysis_result, tuple):
        analysis_lines, signal_data = analysis_result
        output.extend(analysis_lines)
    else:
        output.extend(analysis_result)
    output.append("")

    # 11: Summary (narrative)
    summary = section_summary(signal_data)
    if summary:
        output.extend(summary)
        output.append("")

    # 12: Calendar
    cal = section_calendar()
    if cal:
        output.extend(cal)
        output.append("")

    output.append(f"{'â•' * 50}")
    output.append(f"â± ç”Ÿæˆ: {datetime.now().strftime('%H:%M:%S')} | æ•°æ®ä»…ä¾›å‚è€ƒ")

    return "\n".join(output)


def main():
    parser = argparse.ArgumentParser(description="ç¾è‚¡ç®€æŠ¥ v3")
    parser.add_argument("--time", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†æ—¶é—´æˆ³")
    args = parser.parse_args()

    print(format_briefing(show_time=args.time))


if __name__ == "__main__":
    main()
